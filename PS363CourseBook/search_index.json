[
["index.html", "Quantitative Political Methods Coursebook 1 Class Overview 1.1 Learning objective #1: What is the point of all of this group work? 1.2 Learning object #2: What is the point of all of these online activites? 1.3 Learning objective #3: How is this going to work?", " Quantitative Political Methods Coursebook Jacob Montgomery 1 Class Overview 1.1 Learning objective #1: What is the point of all of this group work? This year, this course has been revised to incorporate some elements of Team Based Learning. This is an approach to creating permanent groups to work on problems in class, in lab, and out of class throughout the semester. We are not going to follow the TBL approach strictly. But we are going to have fewer lectures and more structured group activities. Learn more about Team Based Learning by watching this video. 1.2 Learning object #2: What is the point of all of these online activites? A better question would be what is the point of sitting in a room and watching a professor talk? It’s 2017! Moving an increasing amount of teaching resources online is a big trend in education at all levels. But this isn’t just trendy, it appears to be very effective. Preliminary research shows that online learning paired with in-class interactions with faculty is a much more effective than the traditional lecture format. Watch this short TED talk by Peter Norvig to learn more: 1.3 Learning objective #3: How is this going to work? The approach I am trying to adopt for this class is to help you learn in four basic steps. Initial exposure to materials through self-study. Repeated exposure to materials in short lectures. Use your new knowledge in a collaborative environment where assistance is readily available. Use your new knowledge on your own. The goal is for you to see and use information in multiple ways to improve learning outcomes. Experience (and research) shows that this approach is far superior to simple lectures in helping you learn more and retain it longer. To help you along this process, each learning component will be broken down as follows. You will read your book and review online materials. Regular online quizzes will help motivate you to stay current. I will begin most classes with a short lecture where I will cover the materials again and answer questions. You will apply your knowledge during in-class team assignments. If you have any questions or run into problems, I will be right there to give you help. To keep the team motivated, these assignments will be graded. You will apply your knowledge on your own (or with friends) in your problem sets. "],
["measurement-error.html", "2 Measurement Error 2.1 Learning Objectives 2.2 Learning Objective 1: Types of Biases asdf 2.3 What’s the takeaway?", " 2 Measurement Error 2.1 Learning Objectives Learn to define the following types of errors: sampling bias, response bias, non-response bias 2.2 Learning Objective 1: Types of Biases asdf If the goal of a survey is to be representative, then anything that causes a survey to deviate from the population is a major problem. Something that causes a survey result to deviate from the population is referred to as bias. Bias can be introduced in a number of ways. We will divide biases into three categories: sampling bias, response bias, and non-response bias. 2.2.1 Sampling bias Sampling bias occurs when there is a problem in the sampling process. Sometimes, the sample is poorly conducted. For example, in a survey of WashU undergraduates, if we put together a stratified sample, based on residential area, and then selected 50% of our subjects from Shepley Hall, then our survey would not be reflective of the general WashU undergraduate population, because 50% of WashU students do not live in Shepley hall. This is a sampling error. To give a political example, in telephone surveys, sometimes people do not pick up their phone. In this situation, most polling firms will try calling back later. If a firm does not try to call back when people are out, then they run the risk of introducing sampling error, because younger people are more likely to be out than older people, and younger people are more likely to be liberal. Other times, a sample simply isn’t random. Certain groups are systematically left out of a sample. This is called a selection bias, or selection effect. In this case, the sample will fail to reflect the population as a whole. Although this may sound like an obvious problem, this happens all the time. For example, hosts at various cable news shows sometimes ask viewers to text in what they think about a certain policy, and then display the results as if they are reflective of the general population. But just because 93% of people who texted in think that the President should be re-elected does not mean that the population as a whole agrees. Since it is not a randome sample, it doesn’t even mean that 93% of viewers agree! A common situation where sampling error occurs involves phone lines. People without phone lines are excluded from most surveys. That may not be too big of an issue in a country like the United States, where there may not be a substantial difference between people with phone lines, and people without them. But in a country like Afghanistan relying on phone calls to conduct a survey would be a very big problem since phones are only owned by (relatively) wealthy individuals and some areas have no service at all! Another example is Geico commercials, where they say that people who switch to Geico on average save money. This is a selection bias, because only people who are offered a cheaper rate will switch. If people were randomly selected and forced to switch to Geico, then they would not be saving 30% or more. 2.2.2 Response bias In some surveys, the questions may be poorly worded. The language may be ambiguous, or may be open to different interpretations. So the process of answering the questions may lead to some bias in how the questions are answered. In some surveys, something about the survey itself causes subjects to respond differently than they would in real life. For example, if someone is being surveyed on how often they volunteer, and (s)he rarely volunteers, (s)he may feel embarrassed or guilty about this fact, and tell the interviewer that (s)he volunteers frequently. This is called the social desirability effect. For example, if a survey asks someone if they voted in the last election, and they had not, that person may be more inclined to answer untruthfully, because failing to vote is frowned upon. Other times, the ordering of questions might affect responses. For example, if a survey begins by asking subjects numerous questions about terrorism, and then asks them to list the issues most important to them, more subjects might list terrorism than would be the case if the survey had not first asked numerous questions about it. This is referred to as order effect. An example of order effect occurred in a survey in 1948 that asked, Q1: Do you think the US should let Communist newspaper reporters from other countries come in here and send back to their papers the news as they see it? But half of the people were first asked, Q2: Do you think a communist country like Russia should let American newspaper reporters come in and send back to America the news as they see it? Among people who were first asked the question about American reporters (Q2), 73.1% said yes to Q1. But, among people who did not first answer Q2, only 36.5% said yes to Q1. 2.2.3 Non-response bias People don’t always respond to surveys. When people who do not respond to surveys differ in some systematic way from people who do respond, then the sample fails to be representative of the general population. For example, students who submit course evaluations tend to do so because they either disliked their professor, or loved their professor. In a class, students who do not have strong feelings one way or another are less likely to submit an evaluation, so the evaluation results are likely to indicate that the class is more polarized than it actually is. Note: Non-response bias is not the same as selection bias. Selection bias has to do with how the sample was constructed by the researcher. Non-response bias has to do with how individuals chosen to be in the sample behave. 2.3 What’s the takeaway? There are several different ways that a survey can fail to reflect the population. The sample itself could not be reflective of the population, which would be a sampling bias. Sometimes, something about the survey could prompt people to give answers that don’t reflect what they actually believe or do, which is a response bias. Other times, the people who are selected, but don’t respond differ in an important way from people who do respond, causing the results of the survey to be skewed. This is called a non-response bias. "],
["scales-of-measurement.html", "3 Scales of Measurement 3.1 Learning Objectives: 3.2 Learning Objective 1: Scales 3.3 Summary: 3.4 Learning Objective 2: Granularity 3.5 What is granularity? 3.6 What are the takeaways?", " 3 Scales of Measurement 3.1 Learning Objectives: Learn what ordinal, nominal, and interval scales are. Be able to distinguish between them. Learn what “granularity” means, learn what the two types of granularity, continuous and discrete, mean, and learn how to distinguish them 3.2 Learning Objective 1: Scales 3.2.1 First of all, what do we mean by scales? A “scale” is just the way we measure or quantify a variable. There are three different scales with which data can be measured: nominal, ordinal, or interval. 3.2.2 Nominal Scale Variables measured on a nominal scale can be separated into different categories, but they have no natural ordering. We can’t say that one data point is “more something” than another point. One example is conenent. It is possible to put countries into different categories based on the continent they’re in. The reason that continent is a nominal variable is that, while we can put countries into different categories, there is no universal, objective way of putting them along a dimension. Note: Sometimes variables measured on a nominal scale are called “categorical” data. 3.2.3 Ordinal Scale: Variables measured on an ordinal scale have a natural ordering, but no natural distances between them. We can put the data points in a conceptual line, but there isn’t a precise (or meaningful) distance between observed values. Many survey questions measure opinion on an ordinal scale. For example, in 2012 The Pew research Center asked: Is your overall opinion of Barack Obama very favorable, mostly favorable, mostly unfavorable, or very unfavorable? We can be pretty sure that people who respondend “very unfavorable” approved less of President Obama than people who responded “mostly unfavorable.” But how much less? We don’t know exactly, which is why this variable is measured on an ordinal scale. (You can see many more examples of question wordings to measure approval Preisdent Obama here.) 3.2.4 Interval Scale: Variables measured on an interval scale have both a clear ordering and the difference between numbers has a clear meaning. We can not only put data points in a line, we can also position them within precise distances from each other. An easy example is height. We can order everyone in QPM in a line, from tallest to shortest, and we can say precisely how much taller (or shorter) one person is than the others. 3.2.5 Ratio scale: Ratio scale is a subset of Interval data. In a ratio scale, the zero value signifies that there is none of that variable. Most scales in social science are ratio scales. For example, if we were to measure the proportion of the time a legislator votes with the leadership of a certain party, then a score of 0% means that that legislator cast no votes with the party leadership. An example of a scale that is not measured on a ratio scale is temperature measured in Fahrenheit or Celsius. If a room is 0 degrees Fahrenheit or Celsius, that does not mean that there is no warmth. 3.2.6 Focus on the measurement and not the concept Certain variables, when measured in different ways, can be measured with different scales. For example, think about political ideology. One way to measure the ideology of a member of Congress would be to ask them if they are “Very liberal, somewhat liberal, somewhat conservative, or very conservative.” This would have an ordinal scale. However, there are other ways to measure ideology. For example, we could measure the proportion of votes each member cast that were consistent with the Republican leadership. This would allow us to make a scale of ideology that is interval. (We might find that Nancy Pelosi’s voting record is 70.2% more liberal than John Boehner’s.) Below is the link to Congressional rankings released by Americans for Democratic Action, a left-wing political group, and rankings released by the Club for Growth, and right-wing political group. http://www.adaction.org/media/votingrecords/2010.pdf http://www.clubforgrowth.org/projects/ 3.3 Summary: Watch this video for a very nice summary of these concepts and some thoughts on how best to plot them. 3.4 Learning Objective 2: Granularity 3.5 What is granularity? Granularity refers to how answers fit on a scale. If a variable can take on any value along a scale, it is continuous. An example of a continuous variable is the proportion of the vote a candidate receives in an election. A candidate can receive 0%, 100%, or any value in between. If a variable can only take on certain (countable) values, it is discrete. All nominal data are discrete. Consider the following survey question, asked in a poll by Rusmussen Reports (full survey here): A proposal has been made to repeal the health care law and stop it from going into effect. Do you strongly favor, somewhat favor, somewhat oppose or strongly oppose a proposal to repeal the health care law? In the above question, the results would be discrete, because there are only 5 possible answers. Respondents can strongly favor, somewhat favor, some oppose, or strongly oppose the proposal. There is no possible answer between strongly favor or somewhat favor, for example. Here is a video that can help you tell the difference between discrete and continuous data. 3.6 What are the takeaways? Based on whether data have a natural order or natural distance, they can be measured on a nominal, ordinal, or interval scale. A specific type of interval scale is a ratio scale. Some variables, measured in different ways, can potentially be measured on several types of scales. Based on the space between answers, or granularity, scales can either be continuous, if variables can take on any value on the scale, or discrete, if they can only take on certain values. This video will help you keep this all straight. "],
["random-samples.html", "4 Random Samples 4.1 Learning Objectives 4.2 Learning Objective 1: Random Samples 4.3 Learning Objective 2: Types of Random Samples 4.4 What are the takeaways?", " 4 Random Samples 4.1 Learning Objectives 1)Understand what a random sample is, and why random samples are important. 2)Identify simple random samples, systematic random samples, stratified random samples, cluster samples, and multi-stage sampling, and understand why scientists use them. 4.2 Learning Objective 1: Random Samples 4.2.1 What is a random sample? A random sample is a sample where every subject in the population in question has an equal chance of being selected. If there are 6,000 undergrads at WashU, and I want to select 600 to be in my sample, then if my method of selecting subject is random, each undergrad has the same chance of being selected, 10%. 4.2.2 Why do we care if a sample is random? We want our samples to be representative. In other words, we want our sample to look like the population we’re drawing from, just smaller. If we are conducting a study on how happy they are with their dorm, and 10% of WashU undergrads live in a “traditional” dorm on the South 40, then we want 10% of our sample to be comprised of students living in a traditional dorm on the South 40. More technically, random samples are representative in expectation. That means that if we took a lot of different random samples, on average they would be representative. So while any one random sample might be off just a bit, random samples in general will be representative. 4.2.3 Real-life application: Don’t look ignorant in your newspaper column Below is the link to an article by Rodger Simon, Politico’s chief political columnist. In this article, he dismisses polls because they ask so few people what they think. This is a perfectly reasonable argument to make if one has had no background in statistics. What Roger Simon failed to grasp, and the reason why polls work, even though they ask such few people, is that, when they are done well, they are representative of the population as a whole. http://www.politico.com/news/stories/1211/70717.html 4.3 Learning Objective 2: Types of Random Samples There are several different types of random samples. In each of these samples, every subject in the population has the same probability of being selected, but the subjects are selected in different ways. 4.3.1 Simple Random Sample: This is the most basic method of sampling. A certain number of subjects are chosen randomly out of a population. An example of this is lotteries. In a lottery, each number has the same chance of being selected. Here’s a helpful video that explains simple random samples: If simple random samples are representative, why not just use them for all samples? The problem is that it is extremely difficult, if not impossible, to put together a simple random sample for large populations. One challenge is that certain groups have different response rates than other groups. In this case, if we just do a simple random sample, then groups that have a higher response rate will be over-represented. Another challenge is that there is no directory with the names and contact information of every single person, so it can be difficult to put together a sample in the first place. Scientists employ more complex sampling methods to remedy these problems. 4.3.2 Systematic Random Sample: In a systematic sample, subjects are selected through some sort of system. For example, I might collect the student id numbers of all WashU undergrads, order them from least to greatest, and then start with the 8th number, and sample every 10th person. This is still a random sample, because each person has the same chance of being selected. It’s not, however, a simple random sample, because instead of being selected entirely randomly in no order, there was a system to choosing the people. In a simple random sample, every set of people has the same chance of being in the sample. In a systematic random sample, that’s not true. For example, if my student ID number is 1 higher than my roommate’s, then the in a simple random sample it’s possible that both my roommate and I will be in the sample. In the systematic random sample I just described, however, it is impossible that my roommate and I will be in the same sample. Everyone in the sample has a student id number that’s 10 apart. Here’s a helpful video that explains systematic random samples: 4.3.3 Stratified Random Sample: In a Stratified Random Sample, we first split the population into different groups, or strata. We then select a set number of subjects from each group. The goal is to set up the samples such that the proportion of subjects in the sample from each strata match the proportion of subjects from each strata in the population. To return to the example of sampling the undergraduate population of WashU, we might divide undergrads into different strata based on their residential area. If 5% of all WashU undergrads live in Mudd Hall, and we want our sample to be 600 people, then 5% of those 600 people, or 30 people, will be from Mudd Hall. To achieve this, we would do a simple random sample of Mudd residents, choosing 30 subjects. And we would do this for each residential area. Here’s a helpful video that explains stratified random sampling: What are the advantages of a stratified random sample? Stratified Random Samples can be used to remedy problems of over-sampling, or under-sampling. If different groups have different rates of response, then we can select more subjects from those groups, so the set of people who respond are representative. For example, if freshmen respond much less to surveys than upper-classmen, then we might use a stratified random sample, and over-sample freshmen, to correct for this. 4.3.4 Cluster Samples: In a cluster sample, the population is divided into different clusters. These are organic groupings of people. A simple random sample is run to select several clusters, and then everyone in each selected cluster is surveyed. For example, in the WashU undergrad survey, we might “cluster” students by floor. Wheeler 1 would be a cluster, Lopata 3 another, and so on. We would randomly select a few floors, and interview everyone on each floor. Here’s a helpful video that explains cluster sampling: What are the advantages of a cluster sample? In some ways, cluster samples are easier to execute. If many of the people we are interviewing live close together, it might be easier to reach them. Of course, cluster sampling is not without its drawbacks. Because subjects in the same cluster tend to be similar in certain systematic ways, the cluster sampling can lead to over-sampling of certain types of people. 4.3.5 Multi-Stage Sampling: A multi-stage sample employs several types of random samples. For example, for the undergrad survey, we might first stratify WashU undergrad by whether they live on the South 40, in the Village, or off campus. We might then do a cluster sample within each strata. We could choose 4 floors from each strata, and interview each person on that floor. 4.4 What are the takeaways? Random sampling is the way scientists develop representative samples. There are several different ways of putting together random samples. These include cluster samples, stratified random samples, systematic samples, and multi-stage samples, which combine aspects of different sampling methods. "],
["installing-r-and-r-studio.html", "5 Installing R and R Studio 5.1 Installing R and R Studio on a Mac (would also work for other platforms) 5.2 Installing R and R Studio on Windows", " 5 Installing R and R Studio 5.1 Installing R and R Studio on a Mac (would also work for other platforms) 5.2 Installing R and R Studio on Windows "],
["a-brief-introduction-to-r.html", "6 A Brief Introduction to R", " 6 A Brief Introduction to R Learning objectives: 1)Learn how to assign a value to an object in R. 2)Learn your way around R (using R Studio). 3)Learn how to do simple arithmetic in R. "],
["importing-data-into-r.html", "7 Importing data into R 7.1 Learning Objectives: 7.2 Importing Data 7.3 Let’s go through that all again 7.4 Now let’s practice a bit", " 7 Importing data into R 7.1 Learning Objectives: Learn how to import data into R. Learn how to look at the data. 7.2 Importing Data There are many different kinds of data: there are comma-separated-value files (.csv), text files (.txt), STATA files (.dta), SPSS files (.spss), and some others. We will work primarily with .csv files and some .dta files in this course. In order to import data, we need to make sure we set the correct working directory. After downloading the data, make sure the R working directory is set to the location you saved the data. Then once you are working in the correct directory, we can read csv files in by using the “read.csv” function. We’ll try this with some energy data. Go to: (https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/ARKOTI) and download PESenergy.csv. This is data on TV news coverage about energy policy used in this study. 7.2.1 Telling R where to look The first thing you need to do, is make sure R is looking in the right place for the file. We can use the getwd This shows you R’s current working directory getwd() The output from this command always tells you what directory R is looking in for files. To change where R is looking, we will use the setwd command. setwd(&quot;/Users/yourname/Downloads&quot;) You will have to change the argument inside the parentheses to point to the right folder on your computer. You can use the dir to list out all of the files in your working directory. dir() 7.2.2 Reading in your first data file Once you have got R looking in the right place, now you can load the data using the read.csv command. data &lt;- read.csv(&quot;PESenergy.csv&quot;) This imports PESenergy.csv into a data frame in R. Once we have the data in R, we can manipulate in a number of ways. Experiment with the code below: head(energyData) tail(energyData) summary(energyData) table(energyData$Energy) energyData[c(10:20),c(&quot;Date&quot;,&quot;Energy&quot;,&quot;rmn1173&quot;)] 7.2.3 Summarizing the variables in your dataset The function summary creates a summary table but for all of the variables. summary(energyData) The function summary creates a summary table but for all of the variables. We can also look at just one variable by specifing the column name of a variable like this: summary(energyData$Approval) 7.2.4 Adding a variable to your data Let’s creates a new variable, which is exactly 0.01 times the Approval variable. energyData$approvalProp &lt;- energyData$Approval*0.01 We can see this more clearly if we run the summary of our new variable, the output should be exactly 0.01 times the ouptut of the previous summary table: summary(energyData$approvalProp) 7.3 Let’s go through that all again 7.4 Now let’s practice a bit Follow this link to datacamp.com.. You just need to complete the “Read TXT” and “Read CSV” files. But note that there is also a lesson using the XLConnect package for reading in Excel files. Students who prefer working with data in Excel will want to review this material. "],
["visualizing-data-in-r.html", "8 Visualizing Data in R 8.1 Let’s start with a couple of good videos 8.2 Basic visulualization 8.3 Try a bit more on your own.", " 8 Visualizing Data in R Learning Objectives: Learn how to create simple plots in R. Learn how to interpret the results. 8.1 Let’s start with a couple of good videos 8.2 Basic visulualization Now go back to the PSenergy data we used in the last chapter. Follow those instructions to open the data as an object called energyData. 8.2.1 Making your first plots We use R to create many different kinds of plots: hist(energyData$Energy, xlab=&quot;Television Stories&quot;, main=&quot;Title&quot;) boxplot(energyData$Energy, ylab=&quot;Television Stories&quot;, main=&quot;Title&quot;) plot(y=energyData$Energy, x=energyData$Approval,ylab=&quot;Television Stories&quot;,xlab=&quot;Presidential Approval&quot;) plot(x=energyData$Energy, ylab=&quot;Television Stories&quot;,xlab=&quot;Month-Year&quot;,type=&quot;l&quot;) 8.2.2 Saving your plot You can save your plot by re-creating it within a “pdf device.” In essence, R will create the plot as a new file rather than on your screen. library(lattice) getwd() pdf(&quot;stories_over_time.pdf&quot;) densityplot(energyData$Energy, xlab=&quot;Television Stories&quot;) dev.off() Do not forget the dev.off or the file will never be rendered. 8.3 Try a bit more on your own. Complete chapter 1 of the datacamp course on data visualization in R. "],
["measures-of-position.html", "9 Measures of Position 9.1 Percentile 9.2 Interquartile Range 9.3 Outliers 9.4 Skew", " 9 Measures of Position Learning Objectives: Understand and the terms percentale, interquartile range, outliers and skew. 9.1 Percentile The nth percentile means that n% of observations fall below (or are equal to) n, and (100-n)% fall above n. For example, if you score in the 90th percentile on a test, that means that 90% of students who took the test earned the same or a lower score than you, and 10% scored higher than you. The percentile tells us a lot about a specific observation within a data set because it gives us its relative position. The median is the 50th percentile because exactly 50% of observations fall above the median, and 50% of observations fall below the median. 9.2 Interquartile Range This way of looking at data splits observations into four parts (four quarters). The Interquartile Range (IQR) determines the middle 50% of the data (the middle two quarters). IQR= (75th percentile-25th percentile) The 25th percentile is the lower quartile (25% of data falls below the 25th percentile) and the 75th percentile is the upper quartile (25% of data falls above the 75th percentile). A good way of finding these observations in an ordered set of data is to determine the median, then find the median from the highest data point to the median, and the lowest data point to the median. For example, if you had the data 1 2 3 4 5, you could determine by counting in 3 numbers from each side that the median is 3. You could then find the median of 1 2 3 and of 3 4 5. That will tell you that 2 is the value of the lower quartile, and 4 is the value of the upper quartile. 4-2= 2, which means that the IQR= 2. 9.3 Outliers An outlier is an observation whose value is so much greater or lesser than the other observations that it can be considered an extreme. For example, if you had the data 1 2 3 4 8000, you can easily tell that 8000 is an outlier because it is so much larger than the other values. Although there are many definitions, one common definition of an outlier is any observation that falls 1.5(IQR) above the upper quartile, or 1.5(IQR) below the lower quartile. In our above data set, we can determine that the IQR=2. 1.5(2)=3. This means that any value less than -1 or greater than 7 is an outlier, so 8000 is clearly an outlier. 9.4 Skew The skew tells us the tendency of the data. To determine skew, you can look at a histogram of the data, or compare the median and the mean of a set of data. If the longer tail of the data is to the left of the mode, the data is skewed to the left. We call this a negative skew. If that longer tail of the data is to the right, the data is skewed to the right; a positive skew. In comparing the median and the mean, if the mean is greater than the median, the data is positively skewed, and if the mean is smaller than the median, the data is negatively skewed. We can compare these two measures of center because the mean is more sensitive to outliers than the median. For an easy way to remember skew, check out this video. You’ll never forget it again. "],
["measures-of-central-tendency.html", "10 Measures of Central Tendency 10.1 Learning objective 1: Mean 10.2 Learning objective 2: Median 10.3 Learning objective 3: Mode 10.4 Another look:", " 10 Measures of Central Tendency Learning Objectives: Learn what a mean is and how to calculate one. Learn what a median is and how to calculate one. Learn what a mode is and how to calculate one. Understand how all of alternative measures differ and why. 10.1 Learning objective 1: Mean $x_1 $ indicates a single observation, or data point. \\(\\bar{x}\\) represents the mean of all the observations, which is taken by adding up all the observations and dividing them by the number of observations. We call this the arithmetic mean, or average. More formally, the equation for the mean is: \\[\\bar{x} = \\frac{\\sum_i^n x_i }{n} \\] The mean is used only for quantitative data and interval data. (For example, if you were to ask respondents on a survey to circle their preferred baseball team, the Cardinals, Cubs, Reds, or Pirates, you couldn’t then add up the teams and divide by four.) The mean is highly influenced by outliers, which means that for skewed distributions of data, the mean lies in the direction of the skew. The trimmed mean is a way of correcting for the effect of outliers on the mean. It involves cutting out a certain percentage of the data from both extremes. For example, a 10% trimmed mean involves throwing out the top 10% and bottom 10% of findings, then calculating the mean from the remaining middle 80% of the data. 10.2 Learning objective 2: Median The median is a measure of central tendency found by determining the middle value of a set of data. The value of the median is the 50th percentile because 50% of observations fall above the value of the median, and 50% of observations fall below the median. The median it is the middle of an ordered sequence. For example, if we look at the numbers 1 2 3 4 5, the middle of that ordered sequence is 3. If we have an even number of observations, say 1 2 3 4 5 6, we take the mean of the two middle numbers. So the median here is equal to 3.5. The median is used for quantitative, ordinal or interval data. For symmetric distributions (e.g., a normal bell curve), the mean and the median are identical. However, the median is not affected by outliers like the mean is, so if a distribution of data is highly skewed, the median tends to be the preferred measure of center over the mean. This image shows three graphs two skewed and one symmetrical bell curve. Note the way the mean is easily influenced by the skew of the graph, how it is pulled towards the longer tail of a distribution. Comparing the mean and the median is a good way to determine the skew of data without actually making a histogram. Source: http://experimentaltheology.blogspot.com/2012/03/central-tendency-in-skewed.html 10.3 Learning objective 3: Mode The mode is a measure of central tendency that is the value that occurs most frequently. The mode is the most common data point. For example, if you collected the data 1 2 2 3 4, the mode is the number 2. Imagine a bar graph of the data. The mode is whichever bar is the tallest. For symmetric distributions, the mean, median, and mode are all the same value. When data is bimodal, which means that there are two distinct values that tend to occur more frequently (in a histogram, this would mean there are two lumps in the graph), it can indicate polarization around two extremes. An example of a bimodal distribution is shown bewlow. This histogram shows the change in polarization in the public between 1993 and 2014 10.4 Another look: For more information about measures of center, check out this video: "],
["measures-of-dispersion.html", "11 Measures of Dispersion 11.1 Learning objective 1: Range 11.2 Learning objective 2: Deviations 11.3 Learning objective 3: Variance 11.4 Learning objective 4: Standard deviation 11.5 Learning objective 5: The Empirical Rule 11.6 Review that all again", " 11 Measures of Dispersion Learning Objectives: Understand how to calculate the range of a variable and how to calculate it. Understand and be able to calculate the deviation of specific data point. Understand how to calculate the variance of variable. Understand how to calculate the standard deviation of a variable, and its relationship to the variance. Understand the “Empirical Rule” and how it is related to the standard deviation. 11.1 Learning objective 1: Range The range is a simple measure of variability that shows how spread out the observations in a data set are. Range= (largest observation - smallest observation). Because the range is a measure of distance, the value of the range is always positive. The range really doesn’t tell us anything much that is useful. 11.2 Learning objective 2: Deviations A deviation is a measure of distance from a measure of center, \\(|x_1 - \\bar{x}|\\). The observation may be greater or lesser than the value of the center, but because deviation is a measure of distance, its value is always positive. 11.3 Learning objective 3: Variance Variance is the average of squared deviations. The value of the variance is a squared value (for instance, inches squared, percentage squared, children squared) which does not necessarily tell us very clearly about how spread out the data is from the mean. Variance is calculated by dividing the sum of squared deviations from the value of the population by \\(n-1\\). This is the equation: \\[s^2=\\frac{\\sum_i^n (x_i - \\bar{x})^2}{n-1} \\] When variance increases it means the observations are more spread out from the mean. 11.4 Learning objective 4: Standard deviation The standard deviation is the square root of the variance. \\[s=\\sqrt{s^2}=\\sqrt{\\frac{\\sum_i^n (x_i -\\bar{x})^2}{n-1}}\\] Like the variance, the standard deviation is always a positive number because it represents a distance from the mean. When x is a constant (for example, you have the observations 3 3 3 3 3), the standard deviation is 0 because there is no deviation from the mean. The standard deviation increases as variability increases around the mean. NOTE: The standard deviation is greatly affected by outliers. 11.5 Learning objective 5: The Empirical Rule The Empirical Rule is the distribution of observations is the histogram of the data is approximately bell shaped; if it is a normal, symmetrical distribution. The Rule says that about 68% of observations ball between \\(\\bar{x}-s\\) and \\(\\bar{x}+s\\); that about 95% of observations fall between \\(\\bar{x}-2s\\) and \\(\\bar{x}+2s\\); and that nearly all the data in a normal distribution will fall between \\(\\bar{x}-3s\\) and \\(\\bar{x}+3s\\). The Empirical Rule only works if the data is approximately bell shaped. It does not apply to data that is skewed. 11.6 Review that all again For more information about measures of dispersion, check out this video: "],
["frequency-and-probability-distributions.html", "12 Frequency and Probability Distributions 12.1 Learning objectives 12.2 What is a probability? 12.3 Frequency distribution", " 12 Frequency and Probability Distributions 12.1 Learning objectives Learning Objectives: Define probability. Understand the basic properties of a probability. Understand the meaning of “frequency distribution.” 12.2 What is a probability? There are many definitions of a probability, but here is one that is easy to understand and that is pretty useful for this class is the frequency interpretation of probability. In essence, we imagine doing something (flipping a coin, rolling a dice, taking a random sample). Probability (frequency interpretation) The relative frequency of occurrence for some particular outcome if a process is repeated a large number of times under similar conditions. Probabilities help us answer questions like: If I flip a coin three times, what is the probability that I will get exactly two heads? If I roll two dice, what is the probability of getting a two? If I take a random sample of 100 Wash U students, what is the probability that less than 40% of the sample will be male? If you are asked to find the probability that the variable \\(Y\\) will take on a specific value such as 3, probabilities can be written in several ways. \\[Pr(Y=3) \\mbox{ or }P(Y=3)\\mbox{ or } P(3)\\mbox{ or } Pr(3)\\] All of these are asking you to figure out the probability that the variable \\(Y\\) will take on the value of 3. In other cases you may see a probability written a more generic form, where the specific data point is replaced by a letter. Often this will be written in one of several ways depending on the math book you are looking at. \\[Pr(Y=y), Pr(Y), P(Y=y), \\mbox{ or } P(Y)\\] This is asking you to figure out how to calculate the probability for all possible 12.3 Frequency distribution A probability distribution of a discrete variable, Y, assigns a probability to each possible outcome. As an example, we can write out the frequency distribution for all possible outcomes of flipping two coints. Outcome #Heads Probability TT 0 \\(\\frac{1}{4}\\) TH 1 \\(\\frac{1}{4}\\) HT 1 \\(\\frac{1}{4}\\) HH 2 \\(\\frac{1}{4}\\) In the left column, is the outcome. In the right column is the probability of observing that outcome. So, if we want to represent the probability of getting zero heads, one head, or two heads, we would end up with the frequency distribution: Y Probability 0 \\(\\frac{1}{4}\\) 1 \\(\\frac{1}{2}\\) 2 \\(\\frac{1}{4}\\) Here \\(Y\\) is the random variable of interest. We can think of this table a mapping between inputs (Y) and outputs (probabilities). In more formal notation, this table represents a function, which we can call \\(P(Y=y)\\) or just \\(P(y)\\). This function is what we call a frequency distribution. 12.3.1 Probability and sets We are going to formalize this kind of thinking another step and define something callled a set, \\(S= \\{y_1, y_2, \\ldots, y_k\\}\\), which means that S represents the set of all possible outcomes. In our example, the set of possible outcomes is \\(S=\\{0,1,2\\}\\). 12.3.2 What makes a frequency distribution special? We have defined our frequency distribution \\(P(Y)\\) and the set of possible outcomes \\(S\\). Now we can turn to thinking about what makes a frequency distribution special. First, for all possible outcomes \\(0 \\le P(y \\in S) \\le 1\\). This looks complicated, but just means that the probability of something happen can’t be negative and can’t be greater than 1. It makes no sense to say that something is 110% likely to happen and it makes no sense to say that something has a negative chance of happening. Second, (remembering from above that \\(S= \\{y_1, y_2, \\ldots, y_k\\}\\) \\[\\sum_{k=1}^K p(y_k )=1.\\] This means that the sum of all the probabilities that an event will occur equals 1. 12.3.3 External resources Here are some videos to help: This last video walks you through the construction of a probability density function. "]
]
