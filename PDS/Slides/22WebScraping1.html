<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Introduction to webscraping</title>
    <meta charset="utf-8" />
    <meta name="date" content="2020-01-01" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Introduction to webscraping
### <p>Jacob M. Montgomery<br />
<em>Washington University in St. Louis</em><br />
<em>Department of Political Science</em></p>
### 2020

---


&lt;style type="text/css"&gt;
body, td {
   font-size: 14px;
}
code.r{
  font-size: 14px;
}
pre {
  font-size: 4px;
}
&lt;/style&gt;


## Orientation for this component

First half



1. Basic programming
2. Data management/creation

--

Then

1. Some machine learning
2. Special focus on causal inference


--

Now

1. Getting data from the web (basics)
2. Getting data from the web (more tips)
3. Getting data from APIs

--

Finally

1. Making html documents
2. R Shiny




---
## How does the Internet work?: Markup

- Let's jump over to politicaldatascience.com to find out

--

- html 

![](./Images/html1.png)

---


![](./Images/xml1.png)


- Note that these tags can be more flexible and made up
- Not always consistent across websites, but often consistent across pages on the same website.


---

## How does the Internet work?: Structure

A second fact is that websites aren't usually written by people, but by algorithms.

- Urls are often relatively easy to navigate.

https://www.cnn.com/election/2018/results/nevada/senate
https://www.cnn.com/election/2018/results/tennessee/senate
https://www.cnn.com/election/2018/results/tennessee/house

---

- The website does not exist, but is often constructed:

https://news.google.com/search?q=wisconsin+elections&amp;hl=en-US&amp;gl=US&amp;ceid=US:en
https://www.facebook.com/DonaldTrump/
https://www.facebook.com/pg/DonaldTrump/posts/

---

So if we:

- Know the basic structure of the html content of a page ...
- and unerstand how the urls are set up to navigate ...
- we can pretty easily write a script to tear down large parts of a website.

---
## The devil is in the details

- This can be shockingly easy for the simplest websites.
- And if you have a pre-defined set of urls (or urls implied by specific search combinations) can be pretty easy.
- The hard parts are (or .. begin with):
    1. sometimes actually extracting out the data you want is not straightforward.
    2. sometimes the information you need to construct the urls has to itself be extracted
    3. sometimes what you want is burried not in the html but in javascript (or something else)
    4. sometimes they only want you (or allow you) to pull data from their API.


---
## A task for today

- For today, we are just going to get you as far as building code to scrape a limited number of pages for the data you want.

- Then we'll move onto parsing backend databases (and maybe a little on free-formed crawling) 

- Then onto APIs

--

- But first you need some tools:
    - You will want to install Google Chrome
    - And you will want to install the "Inspector Gadget" Chrome extension I linked to in the slack thread for this class.


---
## Do, Re, Mi...

https://ballotpedia.org/United_States_Senate_elections_in_Arkansas,_2014

- We are going to look at the page.
- And practice using our using our Chrome tools.


---


## let's get started


```r
library(tidyverse)
library(rvest)
arkansas_url&lt;-"https://ballotpedia.org/United_States_Senate_elections_in_Arkansas,_2014"
arkansas_page&lt;-read_html(arkansas_url)
```

- Take a moment to run that and look at object
- You can try to run `html_structure(arkansas_page)` on that

---

Let's start by looking at how to pull out the main text.


```r
mainText&lt;-arkansas_page %&gt;%
  html_nodes('p') %&gt;%
  html_text()
mainText[83:91]
```

```
## [1] "The Club for Growth released the following two ads attacking Pryor for supporting Obamacare and being too liberal.\n"                                                                                                           
## [2] "Reclaim America PAC released the following ad touting Cotton's military record.\n"                                                                                                                                              
## [3] "Americans for Prosperity released the following three ads attacking Pryor for supporting Obamacare, causing insurance policies to be cancelled despite the promise that people would be able to keep their current insurance.\n"
## [4] "Government Integrity Fund Action Network released the following ad supporting Cotton for fighting for America.\n"                                                                                                               
## [5] "American Crossroads released the following ad attacking Pryor for supporting Barack Obama and Obamacare.\n"                                                                                                                     
## [6] "Concerned Veterans for America released the following ad supporting Cotton for his voting record supporting veterans.\n"                                                                                                        
## [7] "On November 2, 2010, John Boozman won election to the United States Senate. He defeated incumbent Blanche L. Lincoln (D), Trevor Drown (I) and John Laney Gray, III (G) in the general election.[92]"                           
## [8] "On November 4, 2008, Mark Pryor won re-election to the United States Senate. He defeated Rebekah Kennedy (G) in the general election.[93]"                                                                                      
## [9] "\n\nif(document.getElementsByClassName(\"reference\").length==0) if(document.getElementById('Footnotes')!==null) document.getElementById('Footnotes').parentNode.style.display = 'none';\n"
```

---

Now maybe just that top table?


```r
table1&lt;-arkansas_page %&gt;%
  html_nodes('center table') %&gt;%
  html_table(header=TRUE)
table1[[1]][,2:5]
```

```
##   U.S. Senate, Arkansas General Election, 2014
## 1                                        Party
## 2                                   Republican
## 3                                   Democratic
## 4                                  Libertarian
## 5                                        Green
## 6                                  Total Votes
## 7          Source: Arkansas Secretary of State
##   U.S. Senate, Arkansas General Election, 2014.1
## 1                                      Candidate
## 2                                     Tom Cotton
## 3                           Mark Pryor Incumbent
## 4                                Nathan LaFrance
## 5                                    Mark Swaney
## 6                                    Total Votes
## 7            Source: Arkansas Secretary of State
##   U.S. Senate, Arkansas General Election, 2014.2
## 1                                         Vote %
## 2                                          56.5%
## 3                                          39.5%
## 4                                             2%
## 5                                             2%
## 6                                    Total Votes
## 7            Source: Arkansas Secretary of State
##   U.S. Senate, Arkansas General Election, 2014.3
## 1                                          Votes
## 2                                        478,819
## 3                                        334,174
## 4                                         17,210
## 5                                         16,797
## 6                                        847,000
## 7            Source: Arkansas Secretary of State
```


---

Another version of that


```r
table1&lt;-arkansas_page %&gt;%
  html_nodes('table.collapsible') %&gt;%
  html_table(fill=TRUE)
table1[[1]][,2:5]
```

```
##   U.S. Senate, Arkansas General Election, 2014
## 1                                        Party
## 2                                   Republican
## 3                                   Democratic
## 4                                  Libertarian
## 5                                        Green
## 6                                  Total Votes
## 7          Source: Arkansas Secretary of State
##   U.S. Senate, Arkansas General Election, 2014.1
## 1                                      Candidate
## 2                                     Tom Cotton
## 3                           Mark Pryor Incumbent
## 4                                Nathan LaFrance
## 5                                    Mark Swaney
## 6                                    Total Votes
## 7            Source: Arkansas Secretary of State
##   U.S. Senate, Arkansas General Election, 2014.2
## 1                                         Vote %
## 2                                          56.5%
## 3                                          39.5%
## 4                                             2%
## 5                                             2%
## 6                                    Total Votes
## 7            Source: Arkansas Secretary of State
##   U.S. Senate, Arkansas General Election, 2014.3
## 1                                          Votes
## 2                                        478,819
## 3                                        334,174
## 4                                         17,210
## 5                                         16,797
## 6                                        847,000
## 7            Source: Arkansas Secretary of State
```

---

Let's look at that smaller table

--


```r
table2&lt;-arkansas_page %&gt;%
  html_nodes('table.wikitable') %&gt;%
  html_table()
table2
```

```
## [[1]]
##   Candidate Filing Deadline Primary Election General Election
## 1             March 3, 2014     May 20, 2014 November 4, 2014
## 
## [[2]]
##                                        X1
## 1 Pryor for Senate - "Emergency Response"
## 
## [[3]]
##                                                    X1
## 1 August 2013 ad attacking Tom Cotton's voting record
## 
## [[4]]
##                                                                 X1
## 1 Ad attacking Tom Cotton for campaigning instead of doing his job
## 
## [[5]]
##                                                      X1
## 1 Pryor for Senate campaign ad focused on Pryor's faith
## 
## [[6]]
##                                         X1
## 1 Ad attacking Cotton's record on Medicare
## 
## [[7]]
##                                         X1
## 1 Ad attacking Cotton's record on Medicare
## 
## [[8]]
##                                        X1
## 1 Ad defending Pryor's vote for Obamacare
## 
## [[9]]
##   X1
## 1 NA
## 
## [[10]]
##                                                                  X1
## 1 Ad attacking Cotton's voting record on the Farm Bill and Medicare
## 
## [[11]]
##                                                                       X1
## 1 Ad attacking Cotton for supporting corporate interests over Arkansans'
## 
## [[12]]
##                                                                                            X1
## 1 Senate Majority PAC ad attacking Tom Cotton for supporting corporate interests over seniors
## 
## [[13]]
##                                                                        X1
## 1 Senate Majority PAC ad attacking Tom Cotton's voting record on Medicare
## 
## [[14]]
##   X1
## 1 NA
## 
## [[15]]
##                                                                      X1
## 1 DSCC ad attacking Cotton for opposing funding for children's hospital
## 
## [[16]]
##                                                                           X1
## 1 Cotton response ad, saying he voted for funding and Pryor voted against it
## 
## [[17]]
##                                                                     X1
## 1 DSCC ad restating that Cotton opposed the funding and won't admit it
## 
## [[18]]
##                                                          X1
## 1 DSCC ad attacking Cotton for voting against the Farm Bill
## 
## [[19]]
##                                                  X1
## 1 October 2013 ad attacking Mark Pryor on Obamacare
## 
## [[20]]
##                                                          X1
## 1 Cotton for Senate ad focused on Cotton's military service
## 
## [[21]]
##                                                  X1
## 1 Ad defending Tom Cotton from Democratic attack ad
## 
## [[22]]
##                                        X1
## 1 Ad focused on Cotton's military service
## 
## [[23]]
##                                               X1
## 1 Ad focused on Cotton's conservative upbringing
## 
## [[24]]
##                                                             X1
## 1 Ad attacking Mark Pryor's voting record as being too liberal
## 
## [[25]]
##                                                              X1
## 1 Ad attacking Pryor for supporting the president and Obamacare
## 
## [[26]]
##                                                              X1
## 1 Marco Rubio funded ad promoting Tom Cotton's military service
## 
## [[27]]
##   X1
## 1 NA
## 
## [[28]]
##   X1
## 1 NA
## 
## [[29]]
##   X1
## 1 NA
## 
## [[30]]
##   X1
## 1 NA
## 
## [[31]]
##   X1
## 1 NA
## 
## [[32]]
##   X1
## 1 NA
```

---

Same thing but with inspector gadget

--


```r
table2&lt;-arkansas_page %&gt;%
  html_nodes('.wikitable center , .wikitable th') %&gt;%
  html_text()
table2
```

```
## [1] " Candidate Filing Deadline\n" " Primary Election\n"         
## [3] " General Election\n"          "March 3, 2014"               
## [5] "May 20, 2014"                 "November 4, 2014"
```

---

Can we get that primary date?

--
  

```r
primaryDate&lt;-arkansas_page %&gt;% 
  html_nodes('td:nth-child(2) center') %&gt;%
  html_text()
primaryDate
```

```
## [1] "May 20, 2014"
```

---

Let's just get the cooks rating 

--
  

```r
cooksScore&lt;-arkansas_page %&gt;%
  html_nodes('br~ b') %&gt;%
  html_text()
cooksScore
```

```
## [1] "Toss Up"                       "May 20, 2014, primary results"
```

---

Can also extact other elements like links

--


```r
stateLinks&lt;-arkansas_page %&gt;%
  html_nodes('small center a') %&gt;%
  html_attr('href')
stateLinks
```

```
##  [1] "/United_States_Senate_elections_in_Alabama,_2014"       
##  [2] "/United_States_Senate_elections_in_Alaska,_2014"        
##  [3] NA                                                       
##  [4] "/United_States_Senate_elections_in_Colorado,_2014"      
##  [5] "/United_States_Senate_elections_in_Delaware,_2014"      
##  [6] "/United_States_Senate_elections_in_Georgia,_2014"       
##  [7] "/United_States_Senate_elections_in_Idaho,_2014"         
##  [8] "/United_States_Senate_elections_in_Illinois,_2014"      
##  [9] "/United_States_Senate_elections_in_Iowa,_2014"          
## [10] "/United_States_Senate_elections_in_Kansas,_2014"        
## [11] "/United_States_Senate_elections_in_Kentucky,_2014"      
## [12] "/United_States_Senate_elections_in_Louisiana,_2014"     
## [13] "/United_States_Senate_elections_in_Maine,_2014"         
## [14] "/United_States_Senate_elections_in_Massachusetts,_2014" 
## [15] "/United_States_Senate_elections_in_Michigan,_2014"      
## [16] "/United_States_Senate_elections_in_Minnesota,_2014"     
## [17] "/United_States_Senate_elections_in_Mississippi,_2014"   
## [18] "/United_States_Senate_elections_in_Montana,_2014"       
## [19] "/United_States_Senate_elections_in_Nebraska,_2014"      
## [20] "/United_States_Senate_elections_in_New_Hampshire,_2014" 
## [21] "/United_States_Senate_elections_in_New_Jersey,_2014"    
## [22] "/United_States_Senate_elections_in_New_Mexico,_2014"    
## [23] "/United_States_Senate_elections_in_North_Carolina,_2014"
## [24] "/United_States_Senate_elections_in_Oklahoma,_2014"      
## [25] "/United_States_Senate_elections_in_Oregon,_2014"        
## [26] "/United_States_Senate_elections_in_Rhode_Island,_2014"  
## [27] "/United_States_Senate_elections_in_South_Carolina,_2014"
## [28] "/United_States_Senate_elections_in_South_Dakota,_2014"  
## [29] "/United_States_Senate_elections_in_Tennessee,_2014"     
## [30] "/United_States_Senate_elections_in_Texas,_2014"         
## [31] "/United_States_Senate_elections_in_Virginia,_2014"      
## [32] "/United_States_Senate_elections_in_West_Virginia,_2014" 
## [33] "/United_States_Senate_elections_in_Wyoming,_2014"
```

---
## Over to you

- Go to politicaldatascience.com
- See if you can make an object that gets all of the text under "Lectures"
- See if you can go one step further and get all of of the hyperlinks as well.
- Don't expect this to come easy.  Ask questions or put up bugs on Slack.

---
## End Part A



---
## Functionalizing and extending

- So now you have some (vague) notion of how to parse HTML.

- But webscraping really becomes powerful when you can rip through a lot of pages (or crawl through interconnected pages).

- To do this, you will need to bring to bear a lot of the other skills you have learned:
    - Functionalizing
    - Data management
    - Text parsing
  
---
## Results for the 2014 Election

- We already collected a complete set of links above in the `stateLinks` object
- Can we scrape the results out of all of them?
- We are going to need to:
    - Write a function that takes in url and then extracts the information we need.
    - Loop that function across what we are looking for
    - Be aware that not all of the pages we are going to will necessarily be constructed the same.  How will we know?

---


```r
stateLinks[3]&lt;-"/United_States_Senate_elections_in_Arkansas,_2014"
x&lt;-stateLinks[3]
thisUrl&lt;-paste0("https://ballotpedia.org", x)
thisUrl
```

```
## [1] "https://ballotpedia.org/United_States_Senate_elections_in_Arkansas,_2014"
```

```r
this_page&lt;-read_html(thisUrl)
```

---



```r
stateLinks[3]&lt;-"/United_States_Senate_elections_in_Arkansas,_2014"
x&lt;-stateLinks[3]
thisUrl&lt;-paste0("https://ballotpedia.org", x)
thisUrl
```

```
## [1] "https://ballotpedia.org/United_States_Senate_elections_in_Arkansas,_2014"
```

```r
this_page&lt;-read_html(thisUrl)
```

---


```r
table1&lt;-this_page %&gt;%
  html_nodes('center table') %&gt;%
  html_table(header=TRUE)
str(table1)
```

```
## List of 1
##  $ :'data.frame':	7 obs. of  5 variables:
##   ..$ U.S. Senate, Arkansas General Election, 2014: chr [1:7] "Party" "" "" "" ...
##   ..$ U.S. Senate, Arkansas General Election, 2014: chr [1:7] "Party" "Republican" "Democratic" "Libertarian" ...
##   ..$ U.S. Senate, Arkansas General Election, 2014: chr [1:7] "Candidate" "Tom Cotton" "Mark Pryor Incumbent" "Nathan LaFrance" ...
##   ..$ U.S. Senate, Arkansas General Election, 2014: chr [1:7] "Vote %" "56.5%" "39.5%" "2%" ...
##   ..$ U.S. Senate, Arkansas General Election, 2014: chr [1:7] "Votes" "478,819" "334,174" "17,210" ...
```


---

Let's just make that a function


```r
scrapeResults&lt;-function(x, stateLinks){
  thisUrl&lt;-paste0("https://ballotpedia.org", stateLinks[x])
  table.out&lt;-read_html(thisUrl) %&gt;%
    html_nodes('center table') %&gt;%
    html_table(header=TRUE)
  table.out
}
results1&lt;-scrapeResults(3, stateLinks=stateLinks)
str(results1)
```

```
## List of 1
##  $ :'data.frame':	7 obs. of  5 variables:
##   ..$ U.S. Senate, Arkansas General Election, 2014: chr [1:7] "Party" "" "" "" ...
##   ..$ U.S. Senate, Arkansas General Election, 2014: chr [1:7] "Party" "Republican" "Democratic" "Libertarian" ...
##   ..$ U.S. Senate, Arkansas General Election, 2014: chr [1:7] "Candidate" "Tom Cotton" "Mark Pryor Incumbent" "Nathan LaFrance" ...
##   ..$ U.S. Senate, Arkansas General Election, 2014: chr [1:7] "Vote %" "56.5%" "39.5%" "2%" ...
##   ..$ U.S. Senate, Arkansas General Election, 2014: chr [1:7] "Votes" "478,819" "334,174" "17,210" ...
```


---
## Over to you

- Now use the code I gave you above, and scrape out all of the "main text" of each of these posts.  


```r
mainText&lt;-arkansas_page %&gt;%
  html_nodes('p') %&gt;%
  html_text()
```

- Write a function (or a piped script) that allows you to scrape all of of these election pages.
- It should be organized as a list so that each element of the list corresponds with one page.
- Count the number of times that "fundraising" and "immigration" (and related terms) appear on each page.  Make a summary plot (boxplot, histogram, etc.) and put the results on slack.


---
## End part B




---
## Testing this in a new place.


Will that work all of the time?


```r
scrapeResults(1, stateLinks=stateLinks)
```

```
## list()
```



Nope!

---

Try a different node identifier?


```r
scrapeResults&lt;-function(x, stateLinks){
  thisUrl&lt;-paste0("https://ballotpedia.org", stateLinks[x])
  table.out&lt;-read_html(thisUrl) %&gt;%
    html_nodes('table.collapsible') %&gt;%
    html_table(fill=TRUE)
  table.out[[1]]
}
results1&lt;-scrapeResults(1, stateLinks=stateLinks)
str(results1)
```

```
## 'data.frame':	5 obs. of  5 variables:
##  $ U.S. Senate, Alabama General Election, 2014: chr  "Party" "" "" "Total Votes" ...
##  $ U.S. Senate, Alabama General Election, 2014: chr  "Party" "Republican" "N/A" "Total Votes" ...
##  $ U.S. Senate, Alabama General Election, 2014: chr  "Candidate" "Jeff Sessions  Incumbent" "Write-in" "Total Votes" ...
##  $ U.S. Senate, Alabama General Election, 2014: chr  "Vote %" "97.3%" "2.7%" "Total Votes" ...
##  $ U.S. Senate, Alabama General Election, 2014: chr  "Votes" "795,606" "22,484" "818,090" ...
```

---


```r
results1&lt;-scrapeResults(1, stateLinks=stateLinks)
str(results1)
```

```
## 'data.frame':	5 obs. of  5 variables:
##  $ U.S. Senate, Alabama General Election, 2014: chr  "Party" "" "" "Total Votes" ...
##  $ U.S. Senate, Alabama General Election, 2014: chr  "Party" "Republican" "N/A" "Total Votes" ...
##  $ U.S. Senate, Alabama General Election, 2014: chr  "Candidate" "Jeff Sessions  Incumbent" "Write-in" "Total Votes" ...
##  $ U.S. Senate, Alabama General Election, 2014: chr  "Vote %" "97.3%" "2.7%" "Total Votes" ...
##  $ U.S. Senate, Alabama General Election, 2014: chr  "Votes" "795,606" "22,484" "818,090" ...
```

---

So that's good?  Let's try that for all of them.


```r
library(plyr)
allResults&lt;-llply(1:length(stateLinks), scrapeResults, stateLinks=stateLinks)
names(allResults)&lt;-stateLinks
```

---

- Still not perfect but a lot of the way there
- Would need to figure out how to strip out and organize all of these together into a useful data frame.

---

## Before I turn it over to you ....

- Some of these lines of code above took me an hour to get right.
- You just have to poke around.
- Look for examples and tutorials and stackoverflow threads
- Ask questions on slack.  You are not dumb. This can be very tricky.


---
## Who studies political parties?

So let's go look at this:

https://scholar.google.com/scholar?hl=en&amp;as_sdt=7%2C26&amp;q=political+parties&amp;btnG=


---


```r
gs_url&lt;-"https://scholar.google.com/scholar?hl=en&amp;as_sdt=7%2C26&amp;q=political+parties&amp;btnG="
pg1&lt;-gs_url%&gt;%
  read_html()%&gt;%
  html_nodes(".gs_ri a , .gs_a , .gs_rt") %&gt;%
  html_text()
```

---

## Group project

1. Build a dataset of articles/books/authors under this tag.
2. Record the number of citations for each entry.
3. Give me a boxplot of the *logged* number of citations.
4. Go through multiple pages.  You might be stopped.
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
