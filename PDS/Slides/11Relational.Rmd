---
title: "Relational data"
author: |
  | Jacob M. Montgomery
  | *Washington University in St. Louis*
  | *Department of Politcal Science*
date: '2020'
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      countIncrementalSlides: false
#   beamer_presentation: default
#   slidy_presentation: default


---


## Orientation for today

**Last time**



1. Data wrangling
    + Recoding data
    + Subsetting
    + Reshaping    
<br>

--

**Today**

1. Relational data
    
    
--

**Next class**

1. Text-as-data
    

---

## Into the tidyverse

- Most complex analyses involve more than one table of data.
- Certainly most active databases are not just rectangles.
- Modern databases are relational, where we know how rows in each rectangle are related to each other.
- With some slight mind bending, we can learn how to work cleanly with such data.



---

## Running example: Mayoral tweets


Data comes from twitter.com.
- Collected Spring 2018
- Twitter data for all mayors in the US for cities greater than 30,000
- Merged in with some background data on the mayors (where available) and the city

---

- Download and unzip the following: https://github.com/jmontgomery/jmontgomery.github.io/blob/master/PDS/Datasets/Tweets.csv.zip
- Read these in using the correct file address


```{r, eval=TRUE, message=FALSE, warning=FALSE}
library(tidyverse)
mayors<-read_csv(file="https://raw.githubusercontent.com/jmontgomery/jmontgomery.github.io/master
/PDS/Datasets/Mayors.csv")
tweets<-read_csv("C:/Users/dl0ck/OneDrive/Spring2020/Political Data Science/Tweets.csv")
print(object.size(mayors), units="auto")
print(object.size(tweets), units="auto")
```


---

## The basic task

There are various ways we might want to work across levels

- *Mutating joins*, where you make a new variable constructed form matched observations in the other.  E.g., how many tweets for each mayor
- *Filtering joins*, where you filter cases based on whether they match across.  E.g., filter to mayors who have tweets.
- *Combining* the datasets in various ways to construct new databases with rows and columns that meet desired specifications.  E.g., Tweets of all moyors from Indiana.


---

```{r, eval=TRUE, message=FALSE, warning=FALSE}
mayors
```


---

```{r, eval=TRUE, message=FALSE, warning=FALSE}
tweets
```


---

This is a simple relational databset that connects tweets to mayors.

- The variable 'TwitterHandle' in the mayors dataset should match up to 'ScreenName' in the tweets data.
- But it will help you get the basics here.
- These variables will serve to link across datasets.
- Let's rename so they are the same

```{r, eval=TRUE, message=FALSE, warning=FALSE}
tweets <- rename(tweets, TwitterHandle=ScreenName)
```

---


```{r, eval=TRUE, message=FALSE, warning=FALSE}
tweets
```

---

- But each dataset will also need a `key` -- a unique identier
-Let's actually look to see if these are unique identifiers?

```{r, eval=TRUE, message=FALSE, warning=FALSE}
mayors %>% 
  count(TwitterHandle) %>%
  filter(n>1)
```

---

```{r, eval=TRUE, message=FALSE, warning=FALSE}
tweets %>% 
  count(TweetID) %>%
  filter(n>1)
```

Hmmm ... you might want to figure out these duplicats before running any analyses.

---

## Mutating join


- A mutating join adds variables to the right on your datset

```{r, eval=TRUE, message=FALSE, warning=FALSE}
tweets %>% 
  left_join(select(mayors, TwitterHandle, LastName), 
            by="TwitterHandle")
```

---

## Drill!

1. Pick three variables from the mayors data to add to the tweets data.
2. Find the number of tweets per mayor and join this to the mayors data



---

## Joins topography

- "Inner joins" produce results only where the linking variable appears on both tables
- "Outer joins" produce results with all data, and fills in missing values as necessary
  + Left join keeps only observations from the first specified data if their is no match.
  + Right join keeps only observations from the second data
  + Full join keeps everything
- Let's draw up the venn diagrams for:
  + Inner joins
  + Left joins
  + Right joins
  + Full joins
  

---

## Drill!

Go back to number 2 above, and now do this using all four possible joins.

  
  
---

## Many and one-to-many

- The join we did above was a one-to-many join, where the last name was added to all of the tweets for that mayor.
- But I did this on purpose and it can go awry when the keys are not as unique as you think they are.
- Joins when there are duplicates lead to creations of new rows for all possible combinations.
  

---
  
## Drill!

Earlier we identified a duplicat in our data with the handles `robertgarcialb` and `rodhiggins2017`. Subset both dataframes to only these mayors and re-do the joins above.  Explain what happens as a result of the duplication.
  

---

## Filtering joins

- `semi_join(x, y)` keeps all observations in x that have a match in y.
- `anti_join(x, y)` drops all observations in x that have a match in y.

--

- The latter is very useful for figuring out why your joins are not working as you expect.  
- For important data merges, you should always run these to be sure that these are returning the values and numbers you expect.


---

### Drill

- Use `semi_join` to append to the mayors data the number of total tweets each had.
- Do the same with `anti_join`.  What does the resulting dataset represent?




---

## Set operations

Tidy also includes functions where it expects datasets with the same columns.

- `intersect(x, y)` will return only observations in both x and y.
- `union(x, y)` will return unique observations in both x and y.
- `setdiff(x, y)` will return observations in x, but not in y.

This is useful for deduplication tasks and also for identifying problems from specific merge commands.


---

## Class exercise

We are going to add a third set of data --- mentions

```{r, eval=TRUE, message=FALSE, warning=FALSE}
mentions <-read_csv(file="https://raw.githubusercontent.com/jmontgomery/jmontgomery.github.io/master/PDS/Datasets/TwitterMentions.csv")
```


1. For each mayor, calculate the number of times they were mentioned
2. Add to the mentions datset the number of times each mayor tweeted.
3. Create a combined dataset of all tweets from the tweets and mentions data.  Subset down to overlapping columns (and rename where needed) to make this easy.
4. Are there any tweets in the mentions dataset from mayors?
