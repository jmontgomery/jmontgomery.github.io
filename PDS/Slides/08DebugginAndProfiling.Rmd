---
title: "Debugging and Profiling"
author: |
  | Jacob M. Montgomery
  | *Washington University in St. Louis*
  | *Department of Politcal Science*
date: '2020'
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      countIncrementalSlides: false
#   beamer_presentation: default
#   slidy_presentation: default


---


## Orientation for today

**Last time**

1. Version control/documentation
    + Getting up on github
    + Helping your future self

<br>



--

**Today**

1. Debugging
2. Profiling

<br>

--

**Next class**
1. `ggplot`



---


# Basic debugging: browser(), debug(), traceback()


- `traceback` will help you identify the function that is failing
- `debug`, `debugonce` will go through a function one line at a time
- `browser` This let's you work within the function environment starting at a specified point

---


## Running example


```{r}
webData<-url("http://pages.wustl.edu/montgomery/incumbents2.txt")
OOS <- read.table(webData)
summary(OOS)
```


---

```{r}
boxplot(voteshare~inparty, data=OOS[OOS$year==1956,])
```

---

```{r}
plot(voteshare~inparty, data=OOS[OOS$year==1956,])
```

---

## Running a regression by year: Do you see a pattern?


```{r, fig.height=3.5}
output.vector<-NULL
for (i in unique(OOS$year)){
    output.vector[which(unique(OOS$year) == i)]<- 
      lm(voteshare ~ inparty, data=OOS[OOS$year == i,])$coefficients[2]
}
plot(unique(OOS$year), output.vector, type="l", ylab="Coefficient (Presiden'ts party)", xlab="Year") 
abline(h=0, lty=3)
```



---

## Functionalize it


- Now we might think -- there is a more general case where I want to get a bunch of seperate regression estimates on defined subsets of the data
```{r, fig.height=3.5, eval=FALSE}
by.var.lm<-function(by.var, formula, data, coef.num){
  output.vector<-NULL
  for (i in unique(by.var)){
    output.vector[which(unique(by.var) == i)]<- 
      lm(formula, data=data[by.var == i,])$coefficients[coef.num]
  }
  return(output.vector)
}
plot(by.var.lm(year, voteshare~inparty, OOS, 2), type="l")
```


---

## This is not working, what to do?

- As a first step, figure out where it's broken using `traceback`
```{r, fig.height=3.5, eval=FALSE}
traceback(by.var.lm(year, voteshare~inparty, OOS, 2))
```



---

- A second thing to try is to use `debug`
```{r, fig.height=3.5, eval=FALSE}
debug(by.var.lm)
```


---

- A second thing to try is to put a `broswer` function into the function itself
```{r, fig.height=3.5, eval=FALSE}
browser()
```

---

- Another thing to try is just put in some various print commands


```{r, fig.height=3.5, eval=FALSE}
by.var.lm<-function(by.var, formula, data, coef.num){
  output.vector<-NULL; print("one")
  for (i in unique(by.var)){ 
    print(i) # I can see where I get to in the loop
    output.vector[which(unique(by.var) == i)]<- 
      lm(formula, data=data[by.var == i,])$coefficients[coef.num]
  }
  print('got out of loop')
  return(output.vector)
}
plot(by.var.lm(year, voteshare~inparty, OOS, 2), type="l")
```


---


## Class activity, debug the function and add comments

Do it

--- 


## So now I have a function that works, can I use it again?


```{r, fig.height=3.5, eval=FALSE}
#Note for jacob: Need to ener in missing data into the 'Class' variable.

website<-url("http://pages.wustl.edu/montgomery/titanic")
titanic<-read.delim(website)
table(titanic$Gender)
table(titanic$Class)
```


---

## Make this work


```{r, eval=FALSE}
by.var.lm(Class, (as.numeric(Survived)-1) ~ Gender, titanic, 2)
```


---


# Benchmarking and code improvements

```{r}
x <- runif(500)
system.time(sqrt(x))
```


The goal is to see how long a function takes to evaluate

---


## Much better: microbenchmark


```{r}
library(microbenchmark)
microbenchmark(sqrt(x)) # evalues 100 times per default
microbenchmark(sqrt(x), times=1000)
```

---

## Now we can compare different functions

```{r}
microbenchmark(sqrt(x), 
               x^0.5,
               times=1000)
```


```{r}
microbenchmark(sqrt(x), x^0.5, x^(1/2), exp(log(x)/2),
               times=1000)
```


---

## And also completely different functions
```{r}
microbenchmark(sqrt(x), x^4-3*x)
```

---

- For ease of interpretation, if a microbenchmark takes
- 1 millisecond, then 1,000 calls take a second
- 1 microsecond, then 1,000,000 calls take a second
- 1 nanosecond,  then 1,000,000,000 calls take a second
- Or use unit=eps for evaluations per second

```{r}
microbenchmark(sqrt(x), x^0.5, x^(1/2), exp(log(x)/2),
               unit="eps")
```


---

- Evaluating every function takes time
- Evaluating () or {} takes time
- Even specifying useless arguments in functions takes time!

```{r}
f0 <- function() NULL
f1 <- function(a=1) NULL
f2 <- function(a=1, b=2) NULL
f3 <- function(a=1, b=2, c=3) NULL
f4 <- function(a=1, b=2, c=3, d=4) NULL
f5 <- function(a=1, b=2, c=3, d=4, e=5) NULL
```


---

```{r}
microbenchmark(f0(), f1(), f2(), f3(), f4(), f5(), times=10000)
```


---

## There is room for improvement (or mistakes) in the most basic functions!
## Extracting one element of a data frame

```{r}
?mtcars
head(mtcars)
```


---


```{r}
microbenchmark(
  "[32, 11]" = mtcars[32,11],
  "$carb[32]"	= mtcars$carb[32],
  "[[c(11, 32)]]" = mtcars[[c(11,32)]],
  "[[11]][32]" = mtcars[[11]][32],
  ".subset2" = .subset2(mtcars,11)[32])
```

---


# Vectorizing

- The key idea behind vectorizing your code is to think about entire
- vectors instead of thinking about their components. Using apply and co
- instead of for loops is a start, but does not really solve this issue.
- Truly vectorized functions will make use of code written in C instead 
 of R. Loops in C are much faster because they have much less overhead.

---

## Addition on each element of a data frame

```{r}
rm(list=ls())
m=5
n=5
matrix1 <- replicate(m, rnorm(n)) # create matrix
matdf <- matdf1 <- data.frame(matrix1) 
matdf
```

---
  
  


```{r}
for (i in 1:m) {
  for (j in 1:n) {
    matdf1[i,j] <- matdf1[i,j] + 1.87*cos(.25)*pi # addition
  }
}
matdf1
```

---

```{r}
matdf2<-data.frame(matrix1) 
matdf2 <- matdf2 + 1.87*cos(.25)*pi
matdf2
```


---

```{r}
microbenchmark(
  "loop" = for (i in 1:m) {
    for (j in 1:n) {
      matdf[i,j] <- matdf[i,j] + 1.87*cos(.25)*pi
    }
  }, 
  "vectorized" = matdf <- matdf + 1.87*cos(.25)*pi
)
```


---

```{r}
mat1 <- matrix(abs(rnorm(2500))+pi, ncol=50)
apply(mat1, 1, function(x) sum(x))
rowSums(mat1)
```

---


```{r}
microbenchmark(apply(mat1, 1, function(x) sum(x)),
               rowSums(mat1))
```


---

- Even for basic tasks, think about the actual calculations you perform

```{r}
mat2 <- matrix(sample(1:7, 90000, replace=T), ncol=300)
mat3 <- matrix(sample(2:6, 90000, replace=T), ncol=300)
ys <- sample(3:5, 300, replace=T)
```


---

```{r}
all.equal(mat2 %*% mat3 %*% ys , mat2 %*% (mat3 %*% ys))
microbenchmark(mat2 %*% mat3 %*% ys,
               mat2 %*% (mat3 %*% ys))
```

- Why?  Think through the dimensionality


---

## Paste/collapse and copies

```{r}
random_states <- function() {
  paste(sample(state.name,10,replace =TRUE),collapse ="")
}
states10 <- replicate(10, random_states())
states10
states100 <- replicate(100, random_states())

```


---

```{r}
collapse <- function(states) {
  out <- ""
  for (x in states) {
    out <- paste0(out, x) # same as paste(..., sep="", collapse)
  }
  out
}

```

---

```{r}
microbenchmark(
  "loop10" = collapse(states10),
  "vec10" = paste(states10, collapse =""),
  "loop100" = collapse(states100),
  "vec100" = paste(states100, collapse ="")
)
```

---

## Allocate memory and fill, don't append to the end

- Here, we are not only getting around using the loop, but also avoiding copies. 
- Whenever you append(), cbind(), rbind(), or paste() to create a bigger object, R must first allocate space for the new object and then copy the old object to its new home. 
- If you're repeating this many times, like in a for loop, this can be quite computationally expensive.


---

### Class exercise

1. Make a new version of `by.var.lm`
2. Let's see which team can find the fastest implementation



