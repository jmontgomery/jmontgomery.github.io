---
title: "Supervised Learning: Introduction and Basic Concepts"
author: |
  | Jacob M. Montgomery
  | *Washington University in St. Louis*
  | *Department of Politcal Science*
date: '2020'
header-includes:
  - \usepackage{amsmath}
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      countIncrementalSlides: false
#   beamer_presentation: default
#   slidy_presentation: default


---


## Orientation for this component

Last time


1. We talked about basic ideas of probability theory as applied to machine learning

--

This time

1. Introduction to machine learning:
    + Basic idea
    + Signal or noise?
    + Example: Regression trees
    + Regularization and the LASSO

--

Next time

1. Supervised learning 2
    + Classificaiton
    + Fit statistics/Diagnostics
    + Trees, neighbors, nets, and ensembles


---
## Finding a function

- We have some outcome, $y$, we are interested in modeling.
    - Election outcomes
    - Political attitudes
    - Economic growth

--
    
- We have some set of variables (or features), we'll call it $X$, related to $y$.
    - Elections $\leftarrow$ polls, incumbency, fundraising
    - Political attitudes  $\leftarrow$ demographics, news sources, party ID
    - Economic growth $\leftarrow$ business confidence, savings rate, productivity


---

- More formally, we say that we want to model $y$ as a *function$ of $X$.
    - $y$: Outcome or *dependent* variable
    - $x$: Predictor or *independent* variable
    - $f(\cdot)$: The function

- Formal statement: 

$$y \sim f(x)$$


---
## What's a function?


- Let's not get scared by terminology

- You have been working with functions for most of your life.
    - $y = a + bx$
    - $y = log(x)$
    - $y = a + bx + cx^2$
    - $y = \beta_ + \beta_1x_1 + \beta_2x_2$

---
##OK, but why are we doing this?

The are probably as many purposes for supervised learning as there are projects. But here are some broad categories:

1. Prediction
2. Feature selection
3. Exploration
4. Theory testing (?)


---
##Prediction

1. Collect outcomes $y$ and predictors $X$. This is called a "training sample."
2. Estimate $f_x(\cdot)$.  The sub-script indicates the model was estimated with the training sample.
3. Collect predictors for "new" observations $X^\prime$.
4. Predict "new" observations as:

$$y^\prime \sim f_x(X^\prime)$$

<br>
<br>


--

> Example: Can we predict who will be president in 2020?


---
##Feature selection

1. Collect outcomes $y$ and predictors $X$.
2. Estimate a different $f(\cdot)$ for different subsets of variables.
3. Use some criteria/algorithm to see what "features" matter.
4. Use this information for inference or further investigation.


<br>
<br>

--

> Example: Is the condition of the economy an important predictor of whether incumbents get re-elected?


---
## Exploration

1. Collect outcomes $y$ and predictors $X$.
2. Estimate a different $f(\cdot)$ using lot's of variables.
3. Find some patterns in the data.
4. Use that to develop theory for later testing.



<br>
<br>

--

> Example: Do voters punish incumbents for a bad economy?  Or do they only care about their own pocketbook?


---
## Sounds good, so what's the problem?


**Problem 1**: Infinity is a big number
- The are an infinite number of potential functions, $f(\cdot)$.
- We can't try all possible functions.  That problem isn't clearly defined.
    

--

**Problem 2**: Not enough data
- Even if we knew a subset of $f(\cdot)$ to consider, we may not have enough data
- If $f(\cdot)$ is complex, can be particularly hard to approximate unless large $n$

--

**Problem 3**: What are the right features?
- Even if we have some idea of $f(\cdot)$ and a lot of data, we don't always know the right features to include.
- And in some cases there are *a lot* of features.

---

**Problem 4**: Is it noise or is it error
- A lot of outcomes we want to study are "noisy"
- One way to think of this is that $f(\cdot)$ can be divided into two compoenents
    * Systematic component
    * Error component
   


Example: The linear regression
    
$$f(X) = \underbrace{\beta_0 + \beta_1x_1 + \beta_2 x_2}_{systematic} + \underbrace{\epsilon}_{error}$$
$$\epsilon  \sim N(0, \sigma^2)$$

---

**Problem 5**: Putting it all together  

- We don't know if we have the right "set" of functions to consider. 
- Even if we did, we don't have infinite data.
- And we don't even know if we are using the right features.
- So we can't ever be sure we are separating out the systematic and error portions.

--

**Problem 6**: Meta problems
- In many settings, the DGP is not static.
- There may be unknown unknowns.
- It is difficult or impossible to know if the data used to train your model is useful for the task at hand.


---
##All I heard was womp, womp, womp

So what does it all mean?

**Problem 1**: To many options for $f(\cdot)$

> Basic approach: Assume the DGP can be represented as some subset of all possible functions (e.g., a line).

--

**Problem 2**: Not enough data

**Problem 3**: What are the right features?

**Problem 4**: Is it noise or is it error

> Basic approach: Use cross-validation or related methods to build models that are fitting signal rather than noise.  

--

**Problem 6**: Meta problems


> Basic approach: Humility.



---


## Example: Predicting presidential elections with vote share

Today we are going to use the results of US presidential elections since 1948
```{r, eval=TRUE, message=FALSE, warning=FALSE}
library(tidyverse)
electData<-read.csv("http://politicaldatascience.com/PDS/Datasets/presElect.csv")
```

- Year: Year of the election
- q2gdp: GDP in the second quarter
- vote: Share of the two-party vote that went to the **incumbent party.**
- term: 1=Incumbent party has served more than one term; 0 = First term for incumbent party
- JuneApp: Approval as recorded in June prior to the election.
- Inc: Indicator if the **incumbent party** candidate is the current incumbent.

---

##Fancy machine learning: Linear regression

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, fig.width=12}
par(mar=c(2,2,.5,.5), mgp=c(1,0,0), tcl=0, cex.lab=1)
plot(electData$q2gdp, electData$vote, ylab="Incumbent party share of vote", xlab="Q2 GDP Growth", ylim=c(44, 64), pch="", xlim=c(-8, 10.5), cex=.8)
abline(h=seq(45, 65, by=5), col="gray80")
abline(lm(electData$vote~electData$q2gdp), lwd=2)
points(electData$q2gdp[1:17], electData$vote[1:17], ylab="Incumbent party share of vote", xlab="Q2 GDP Growth", ylim=c(44, 64), pch=19, xlim=c(-8, 10.5), cex=.8)
text(electData$q2gdp[1:17]+.65, electData$vote[1:17], electData$year[1:17], cex=1.2)
points(electData$q2gdp[18], electData$vote[18], ylab="Incumbent party share of vote", xlab="Q2 GDP Growth", ylim=c(44, 64), pch=19, xlim=c(-8, 10.5), cex=.8, col="red")
text(electData$q2gdp[18]+.65, electData$vote[18], electData$year[18], cex=1.2, col="red")
```

---

##So how do we do it?

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=TRUE}
Model1<-lm(vote~q2gdp, data=electData)
summary(Model1)
```


---
## Inuition for the linear model

    
$$f(X) = \underbrace{\beta_0 + \beta_1x_1 + \beta_2 x_2}_{systematic} + \underbrace{\epsilon}_{error}$$
$$\epsilon  \sim N(0, \sigma^2)$$

- The "Multiple R-squared" is a fit statistic.
    * Ranges from 0 to 1
    * Closer to 1 is better

--

- The "Estimate" is the 

- The "Std. Error" is what we talked about in our previous lecture

--

- Smaller p-values mean there is more evidence that that specific variable matters (sort of)


---

## Example: Prediction


```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=TRUE}
electData$vote[electData$year==2016]
Model2<-lm(vote~q2gdp+JuneApp, data=electData[electData$year!=2016,])
predict(Model2, newdata=electData[electData$year==2016,])
```

Pretty good!


---

## Example: Feature selection


```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=TRUE}
Model3<-lm(vote~q2gdp+JuneApp, data=electData)
summary(Model3)
```

---

## Example: Exploration


```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=TRUE}
Model4<-lm(vote~JuneApp+Inc, data=electData)
summary(Model4)
```


