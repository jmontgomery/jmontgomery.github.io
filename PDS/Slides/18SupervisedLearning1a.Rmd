---
title: "Supervised Learning: Introduction and Basic Concepts"
author: |
  | Jacob M. Montgomery
  | *Washington University in St. Louis*
  | *Department of Politcal Science*
date: '2020'
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      countIncrementalSlides: false
#   beamer_presentation: default
#   slidy_presentation: default


---


## Orientation for this component

Last time


1. We talked about basic ideas of probability theory as applied to machine learning

--

This time

1. Introduction to machine learning:
    + Basic idea
    + Signal or noise?
    + Example: Regression trees
    + Regularization and the LASSO

--

Next time

1. Supervised learning 2
    + Classificaiton
    + Fit statistics/Diagnostics
    + Trees, neighbors, nets, and ensembles


---
## Finding a function

- We have some outcome, $y$, we are interested in modeling.
    - Election outcomes
    - Political attitudes
    - Economic growth

--
    
- We have some set of variables (or features), we'll call it $X$, related to $y$.
    - elections $\leftarrow$ Polls, incumbency, fundraising
    - Political attitudes  $\leftarrow$ demographics, news sources, party ID
    - Economic growth $\leftarrow$ business confidence


---

- More formally, we say that we want to model $y$ as a *function$ of $X$.
    - $y$: Outcome or *dependent* variable
    - $x$: Predictor or *independent* variable
    - $f(\cdot)$: The function

- Formal statement: 

$$y \sim f(x)$$


---
## What's a function?


- Let's not get scared by terminology

- You have been working with functions for most of your life.
    - $y = a + bx$
    - $y = log(x)$
    - $y = a + bx + cx^2$
    - $y = \beta_ + \beta_1x_1 + \beta_2x_2$


---
## Sounds good, so what's the problem?


Problem 1: Infinity is a big number
- The fundamental problem is that there are an infinite number of potential functions, $f()$.
- We can't try all possible functions.  That problem isn't clearly defined.
    

--

Problem 2: Not enough data
- Even if we knew a subset of $f(\cdot)$ to consider, we may not have enough data
- If $f(\cdot)$ is complex, can be particularly hard to approximate unless large $n$

--

Problem 3: What are the right features?
- Even if we have some idea of $f(\cdot)$ and a lot of data, 
- 



---


## Get set up

Today we are going to use the 2019 data release from the Voter Study Group

- Download: https://www.voterstudygroup.org/publication/2019-voter-survey-full-data-set
- Codebook: https://www.voterstudygroup.org/publication/2019-voter-survey-full-data-set


```{r, eval=TRUE, message=FALSE, warning=FALSE}
library(tidyverse)
VSG<-read_csv("~/Downloads/VOTER_Survey_Jan217_Release1-csv.csv")
```

---

## Recode a bit

```{r, eval=TRUE, message=FALSE, warning=FALSE}
with(VSG, table(fav_biden_2019))
VSG<-VSG %>% 
  mutate(fav_biden_2019=na_if(fav_biden_2019, 8)) %>%
  mutate(fav_biden_2019=na_if(fav_biden_2019, 98))
with(VSG, table(fav_biden_2019))
```

Here is the mean value:

```{r, eval=TRUE, message=FALSE, warning=FALSE}
mean(VSG$fav_biden_2019, na.rm=TRUE)
```


---
