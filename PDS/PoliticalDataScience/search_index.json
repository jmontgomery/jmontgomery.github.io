[
["index.html", "Political Data Science 1 Don’t be a clown 1.1 As easy as cake 1.2 Class structures", " Political Data Science Jacob Montgomery and Mariah Yelenick 1 Don’t be a clown I see miracles all around me Stop and look around, it’s all astounding Water, fire, air and dirt Fucking magnets, how do they work? And I don’t wanna talk to a scientist Y’all motherfuckers lying, and getting me pissed — Insane Clown Posse, Miracles Link if you don’t know what I’m talking about Pollsters are wizards, shamans, diviners. They toss numbers around the way astragalomancers once tossed bones to foretell events to come. (The name comes from the Greek astragalos, meaning “knucklebone.” But you knew that.) I have never been called by a political pollster and don’t know anybody who has, but I know some pollsters, who assure me they don’t make the numbers up, and I believe them. — Roger Simon, Chief Political Columnist, Politico Link Depending on who you listen to, artificial intelligence and machine learning1 are either the cause or the solution to all of the world’s problems. On the one hand you have algorithms spreading misinformtion, large scale corporate surveillance, and predicted mass unemployment in the service sector. On the other hand you have ever-improving health diagnostics, data-driven journalism, and all the world’s information at the touch of your fingers (or voice). The term “data science” means different things to different people, but for most people the term doesn’t mean much at all. In the two quotes above, we see both the Insane Clown Posse and Politico’s (for God’s sake) chief political columnist share a loving embrace with ignorance about fundamental forces in our life. We swim in data and statistics. News, politics, and policy is increasingly being driven by data and algorithms. But all too few people know much about how these algorithms work. Like magnets or random sampling, data science is just a mysterious force that we have to cope with. The central goal of this class is to make sure you don’t have to be a clown. In today’s world, your future career will surely You will find that data science, machine learning, big data, and artificial intelligence is just another tool (if a powerful tool). It is neither good nor evil by itself. It is humans and human judgement (or lack of judgement) that lead to good our bad outcomes. But whether you intend to work for the forces of good or evil (I tend towards chaotic neutral) 1.1 As easy as cake One way 1.1.1 Coding 1.1.2 Data acquision Is that polling data you are looking at a random sample of Americans, or just everyone who attended that sick Delta Sig party? Were the people in your data randomly assigned to watch Fox news, or did they choose to? No matter how fancy your machine learning algorithm, the results don’t mean anything very much if you don’t 1.1.3 Algorithms 1.1.4 Domain knowledge Like baking, the final thing you need to do good data science is what most people call “domain knowledge” and what I call “knowing what the hell you are talking about.” It turns out that having a really cool statistical model, huge amounts of data, and even a super computer sproting 24 GPUs will not save you from reaching the wrong answer if you don’t think (and aren’t trained to think). Link 1.1.5 Putting it together A final method. You can get along fine in may cases following the instructions on the back of the chocolate chip cookie bag. But to really become a “baker” you need to be able to create your own recipes for each occasion. And to do that you actually need to “know what the hell you are talking about.” So 1.2 Class structures 1.2.1 Learning objective #1: Team based learning This course was designed to incorporate elements of Team Based Learning. This is an approach to creating permanent groups to work on problems in class and out of class throughout the semester. We are not going to follow the TBL approach strictly. But we are going to have fewer lectures and more structured group activities. Learn more about Team Based Learning by watching this video. 1.2.2 Learning objective #2: Show up ready Moving an increasing amount of teaching resources online is a big trend in education at all levels. But this isn’t just trendy, it appears to be very effective. Preliminary research shows that online learning paired with in-class interactions with faculty is a much more effective than the traditional lecture format. Watch this short TED talk by Peter Norvig to learn more: So in advance of each lecture 1.2.3 Learning objective #3: How is this going to work? The approach I am trying to adopt for this class is to help you learn in four basic steps. Initial exposure to materials through self-study. Repeated exposure to materials in short lectures. Use your new knowledge in a collaborative environment where assistance is readily available. Use your new knowledge on your own. The goal is for you to see and use information in multiple ways to improve learning outcomes. Experience (and research) shows that this approach is far superior to simple lectures in helping you learn more and retain it longer. To help you along this process, each learning component will be broken down as follows. You will read your book and review online materials. I will begin most classes with a short lecture where I will cover the materials again and answer questions. You will apply your knowledge during in-class team assignments. If you have any questions or run into problems, I will be right there to give you help. To keep the team motivated, these assignments will be graded. You will apply your knowledge on your own (or with friends) in your problem sets and final project. Machine learning and statistics is really just a subset of artificial intelligence (AI) research. For fun, just start telling people you are in an AI class and see how they react.↩︎ "],
["getting-started-in-r.html", "2 Getting Started in R 2.1 Learning Objectives 2.2 Assigning values to objects 2.3 R as a calculator 2.4 The global environment and how to clean it 2.5 Getting help 2.6 Installing packages", " 2 Getting Started in R 2.1 Learning Objectives Learn how to assign a value to an object in R. Learn your way around R (using R Studio). Learn how to do simple arithmetic in R. 2.2 Assigning values to objects You can assign values to objects in two ways as shown below. The assignment arrow is functionally equivalent to the equal sign. When assigning values to objects, R will always take the value on the right side of the assignment operator (&lt;- or =) and store it in the object on the left side of the assignment operator. This means that the two lines of commented code in the following snippet do different things. Side note: to comment a single line of code in R, use the hashtag or pound sign at the beginning of the line. If you’re working in an R script, the commented portion will turn green. x &lt;- 4 x ## [1] 4 y = 6 y ## [1] 6 #y = x #x = y It is best practice when coding to avoid “magic numbers” - i.e. all numbers should be stored in named variables so that if we want to change the value, we only have to do so once. This also removes any ambiguity for someone else reading your code who might wonder what the number represents. total.votes.ak &lt;- 238307 voting.age.population.ak &lt;- 496387 turnout.ak &lt;-total.votes.ak/voting.age.population.ak turnout.ak ## [1] 0.4800831 2.3 R as a calculator 5+4 # Addition ## [1] 9 6-3 # Subtraction ## [1] 3 34 / 6 # Division ## [1] 5.666667 5 * 3 # Multiplication ## [1] 15 5^4 # Exponents ## [1] 625 625^(1/4) # More exponents ## [1] 5 11%%2 # modular arithmetic (11 mod 2) is the remainder operator ## [1] 1 31 %/% 7 # The integer part of a fraction ## [1] 4 R comes with a number of constants prestored that you can use 6.25 # numbers pi # And a few others NA # Missing value NULL # Nothing. 0/0 # NaN means &quot;Not a number&quot; 1/0 # Inf means infinity R follows the order of operations (Please Excuse My Dear Aunt Sally). Side note - if you have multiple exponentiation, they execute right to left. 2*(3-4)+2 ## [1] 0 2*(3-4)+2*(4 + 3)^(1/3) ## [1] 1.825862 2.4 The global environment and how to clean it Named objects are stored in the “global environment”, which means that they can be accessed at any time by any function you might run. They are “global” variables which makes them different from “local” variables (variables that can only be accessed from within a certain scope like within a function). The commands ls() and rm() are used to show or remove variables from the global environment respectively. a &lt;- 1 b &lt;- 2 ls() ## [1] &quot;a&quot; &quot;b&quot; ## [3] &quot;mayors&quot; &quot;mayorsDF&quot; ## [5] &quot;total.votes.ak&quot; &quot;turnout.ak&quot; ## [7] &quot;voting.age.population.ak&quot; &quot;x&quot; ## [9] &quot;y&quot; rm(a) #this removes a from the global environment ls() ## [1] &quot;b&quot; &quot;mayors&quot; ## [3] &quot;mayorsDF&quot; &quot;total.votes.ak&quot; ## [5] &quot;turnout.ak&quot; &quot;voting.age.population.ak&quot; ## [7] &quot;x&quot; &quot;y&quot; c &lt;- 3 rm(list = ls()) #this removes all global variables Some things are present in the working environment, but not shown in the global environment .x&lt;-&quot;Hide me&quot; print(.x) ## [1] &quot;Hide me&quot; ls() ## character(0) Anything that starts with a “.” will be accessible in your code, but hidden 2.5 Getting help Learning about functions and how to specify them correctly is half the battle help(sqrt) # help w/ functions ?sqrt # same thing help.start() # lots of help help.search(&quot;sqrt&quot;) # what am I looking for? Fuzzy matching example(sqrt) RSiteSearch(&quot;missing&quot;) TIPS: 1) Remember that these help menus are usually written by the same people who wrote the functions you are using. They are uniformly not helpful unless you already know a good bit about computer programming and (in some cases) a lot about the function itself. 2) There is a basic structure that all help files must meet, and it is very important that you try and get the hang of this. 2.6 Installing packages The beauty of R is that there are packages, although things can be a bit unorganized. install.packages(&quot;BAS&quot;) # This will prompt a user interface to choose the &quot;mirror&quot; or repository library(BAS) # this will actually load the library for use. You must call this every time. search() # you can see what packages are attached to the workspace (and also what other objects) help(package=&quot;BAS&quot;) # Will (usually) give you a list of functions for the package example(BAS) # some package writers give you little examples to get you started All packages documentation are on CRAN Many packages come with example datasets built in data() data(rock) ?rock # there are help files for these ls() # there&#39;s rock -- in the global environment data(road, package=&quot;MASS&quot;) # you can load these datasets without loading the package "],
["data-types-in-r.html", "3 Data Types in R 3.1 Functions 3.2 Vectors 3.3 Functions and vectors 3.4 Logicals/Booleans 3.5 Characters/Strings 3.6 Matrices 3.7 Matrix algebra (optional) 3.8 Lists 3.9 Arrays 3.10 Dataframes 3.11 General info", " 3 Data Types in R 3.1 Functions log ## function (x, base = exp(1)) .Primitive(&quot;log&quot;) log(2) # ln(2) ## [1] 0.6931472 log(2, base=10) # log(2) base 10 ## [1] 0.30103 log(base = 10, x = 2) ## [1] 0.30103 exp(log(1)) # e^ln(1) = 1 ## [1] 1 3.2 Vectors The c() function is used to collect/concatenate things together into a vector c(0,7,8) ## [1] 0 7 8 x&lt;-c(0,7,8) # assign this to a named object An easy way to make a sequence vector is using the : operator. numbers5to20 &lt;- 5:20 # numbers5to20 ## [1] 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Note that it always increments by 1 1.5:10 ## [1] 1.5 2.5 3.5 4.5 5.5 6.5 7.5 8.5 9.5 You can also concatenate any two vectors to make a new vector c(numbers5to20, x) ## [1] 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 0 7 8 3.3 Functions and vectors Many functions have been “Vectorized” meaning that they work on each element in the vector numbers5to20*2 ## [1] 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 sqrt(numbers5to20) ## [1] 2.236068 2.449490 2.645751 2.828427 3.000000 3.162278 3.316625 3.464102 ## [9] 3.605551 3.741657 3.872983 4.000000 4.123106 4.242641 4.358899 4.472136 log(numbers5to20) ## [1] 1.609438 1.791759 1.945910 2.079442 2.197225 2.302585 2.397895 2.484907 ## [9] 2.564949 2.639057 2.708050 2.772589 2.833213 2.890372 2.944439 2.995732 abs(numbers5to20) ## [1] 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 numbers5to20^2 ## [1] 25 36 49 64 81 100 121 144 169 196 225 256 289 324 361 400 But when you “Interact” two vectors, they will work “elementwise” numbers5to20*numbers5to20 ## [1] 25 36 49 64 81 100 121 144 169 196 225 256 289 324 361 400 numbers5to20+numbers5to20 ## [1] 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 numbers5to20+rev(numbers5to20) ## [1] 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 data &lt;- c(NA, 4, 7, NA, 19) is.na(data) #tells us true or false whether each value is NA ## [1] TRUE FALSE FALSE TRUE FALSE !is.na(data) #true if the value is *not* NA ## [1] FALSE TRUE TRUE FALSE TRUE Other functions operate on a functions work more directly sum(numbers5to20) ## [1] 200 prod(numbers5to20) #multiples all elements together ## [1] 1.013709e+17 mean(numbers5to20) ## [1] 12.5 var(numbers5to20) ## [1] 22.66667 max(numbers5to20, na.rm=T) # maximum -- ignore missing data ## [1] 20 min(numbers5to20, na.rm=TRUE) #minimum -- notice that T=TRUE ## [1] 5 summary(numbers5to20) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 5.00 8.75 12.50 12.50 16.25 20.00 Accessing elements of a vector or matrix is usually done with the [] operators We can access the first or fortieth element of vap. numbers5to20[1] ## [1] 5 numbers5to20[40] ## [1] NA We can also extract several elements at a time using vectors. numbers5to20[c(3,6,7)] ## [1] 7 10 11 numbers5to20[3:7] ## [1] 7 8 9 10 11 We can repeat numbers as well numbers5to20[c(3,3,2,2)] ## [1] 7 7 6 6 This code prints everything but the 4th through 7th elements by using the negative sign numbers5to20[-(4:7)] ## [1] 5 6 7 12 13 14 15 16 17 18 19 20 x x*3 #scalar multiplication y&lt;-x-5 #simple addition and multiplicaiton are done &quot;by element&quot; y x^3 # ditto with exponents y^x # but if each are three elements long, it will execute by element Vector recycling When vectors have different lengths, the shorter one is extended by repeating the vector. This means two things: 1. The vector lengths must be multiples of each other 2. This is a very easy way to make a bad, bad mistake. You can easily find the length of a vector length(numbers5to20) ## [1] 16 Other functions will create vectors as outputs rep(1, 5) #Repeat the value 1, 5 times ## [1] 1 1 1 1 1 seq(1, 21, by=2) #Make the sequence 1 to 21 moving by increments of 2 ## [1] 1 3 5 7 9 11 13 15 17 19 21 rep(seq(2,20, by=2), 2) #Repeat the pattern 2, 4, ... 20, twice ## [1] 2 4 6 8 10 12 14 16 18 20 2 4 6 8 10 12 14 16 18 20 rep(c(1,4), c(3,2)) #Repeat 1, 3 times and 4, twice ## [1] 1 1 1 4 4 rep(c(1,4), each=3) #Repeat each value 3 times ## [1] 1 1 1 4 4 4 3.4 Logicals/Booleans Logicals are often used when subsetting or recoding data Generally necessary to understand this for data wrangling x&lt;-c(0, 7, 8) chooser&lt;-c(T, F, T) x[chooser] # print ony those elements of x where chooser is TRUE ## [1] 0 8 Arithmetic operations on logicals create numerics where: TRUE is treated as a ‘1’, and FALSE is treated as a ‘0’ sum(chooser) # Number of true values ## [1] 2 3.4.1 Boolean logic x == 7 #equals ## [1] FALSE TRUE FALSE x != 7 #does not equal ## [1] TRUE FALSE TRUE x &gt; 7 #greater than ## [1] FALSE FALSE TRUE x &gt;= 7 #greater than or equal to ## [1] FALSE TRUE TRUE x &lt; 7 #less than ## [1] TRUE FALSE FALSE x &lt;= 7 #less than or equal to ## [1] TRUE TRUE FALSE x &lt; 7 | x == 7 ## the or operator ## [1] TRUE TRUE FALSE x &lt;= 7 &amp; x == 7 ## the and operator ## [1] FALSE TRUE FALSE “or” - the pipe symbol - returns true if either/any of the conditions are true “and” - the ampersand - returns true if both/all of the conditions are true Most of the time, we use boolean logic to subset datasets. Here’s some data to get us started vap&lt;-voting.age.population&lt;-c(3481823, 496387, 4582842, 2120139,26955438, 3617942,2673154,652189,472143,14085749,6915512, 995937,1073799,9600372,4732010,2265860,2068253, 3213141,3188765,1033632,4242214,4997677,7620982, 3908159,2139918,4426278,731365,1321923,1870315,1012033, 6598368,1452962,14838076,6752018,494923,8697456,2697855, 2850525,9612380,824854,3303593,594599,4636679, 17038979,1797941,487900,5841335,4876661,1421717, 4257230,392344) total.votes&lt;-tv&lt;-c(NA, 238307, 1553032, 780409,8899059,1586105, 1162391,258053, 122356,4884544, 2143845,348988, 458927,3586292, 1719351,1071509, 864083,1370062, 954896,NA, 1809237, 2243835,3852008, 2217552,NA, 2178278, 411061,610499, 586274,418550, 2315643,568597, 4703830,2036451, 220479,4184072, NA,1399650, NA,392882, 1117311,341105, 1868363,NA, 582561, 263025,2398589, 2085074,473014, 2183155, 196217) tv[!is.na(tv)] #get all valid datapoints from the tv dataset ## [1] 238307 1553032 780409 8899059 1586105 1162391 258053 122356 4884544 ## [10] 2143845 348988 458927 3586292 1719351 1071509 864083 1370062 954896 ## [19] 1809237 2243835 3852008 2217552 2178278 411061 610499 586274 418550 ## [28] 2315643 568597 4703830 2036451 220479 4184072 1399650 392882 1117311 ## [37] 341105 1868363 582561 263025 2398589 2085074 473014 2183155 196217 small.states&lt;- voting.age.population[voting.age.population &lt; median(voting.age.population)] small.states ## [1] 496387 2120139 2673154 652189 472143 995937 1073799 2265860 2068253 ## [10] 1033632 2139918 731365 1321923 1870315 1012033 1452962 494923 2697855 ## [19] 2850525 824854 594599 1797941 487900 1421717 392344 state.size&lt;-(voting.age.population &gt; median(voting.age.population)) *1 state.size #this code makes a new vector equal to 1 if it&#39;s a large state (larger than median), 0 otherwise ## [1] 1 0 1 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 0 0 1 0 1 1 0 1 0 0 ## [39] 1 0 1 0 1 1 0 0 1 1 0 1 0 which(state.size == 1) #returns the vector of indices of the elements that have state.size equal to 1 ## [1] 1 3 5 6 10 11 14 15 18 21 22 23 24 26 31 33 34 36 39 41 43 44 47 48 50 any(x&gt;2) #returns true if the condition is true for any element ## [1] TRUE all(x&gt;2) #returns true if the condition is true for all elements ## [1] FALSE 3.5 Characters/Strings colors &lt;- c(&quot;red&quot;, &quot;yellow&quot;, &quot;blue&quot;, &quot;green&quot;, &quot;magenta&quot;, &quot;cyan&quot;) You might want only a portion of the string. substr(colors, start=1, stop=2) ## [1] &quot;re&quot; &quot;ye&quot; &quot;bl&quot; &quot;gr&quot; &quot;ma&quot; &quot;cy&quot; paste0(colors, &quot;flowers&quot;) # combine two strings ## [1] &quot;redflowers&quot; &quot;yellowflowers&quot; &quot;blueflowers&quot; &quot;greenflowers&quot; ## [5] &quot;magentaflowers&quot; &quot;cyanflowers&quot; paste(colors, &quot;flowers&quot;, sep=&quot;&quot;) # combine two strings ## [1] &quot;redflowers&quot; &quot;yellowflowers&quot; &quot;blueflowers&quot; &quot;greenflowers&quot; ## [5] &quot;magentaflowers&quot; &quot;cyanflowers&quot; paste(&quot;I like&quot;, colors, &quot;flowers&quot;) ## [1] &quot;I like red flowers&quot; &quot;I like yellow flowers&quot; &quot;I like blue flowers&quot; ## [4] &quot;I like green flowers&quot; &quot;I like magenta flowers&quot; &quot;I like cyan flowers&quot; paste(&quot;I like&quot;, colors, &quot;flowers&quot;, collapse = &quot;&quot;) ## [1] &quot;I like red flowersI like yellow flowersI like blue flowersI like green flowersI like magenta flowersI like cyan flowers&quot; nchar(colors) #how many characters in each string ## [1] 3 6 4 5 7 4 You may want to divide a string into components extreme.statement&lt;-&quot;Coding is my life&quot; this.out&lt;-strsplit(extreme.statement, split=&quot; &quot;) unlist(this.out) ## [1] &quot;Coding&quot; &quot;is&quot; &quot;my&quot; &quot;life&quot; Use gsub to replace or remove parts of a string gsub(&quot;my life&quot;, &quot;the bee&#39;s knees&quot;, extreme.statement) ## [1] &quot;Coding is the bee&#39;s knees&quot; # less extreme. More true gsub(&quot; is my life&quot;, &quot;&quot;, extreme.statement) ## [1] &quot;Coding&quot; Tips for using strings: If you are doing a lot with strings try the library ‘strgr’, which has some user-friendly functions If you include ‘’ in a string, in many instances it will be a carriage return (e.g., plotting) A very common programming error is to forget a closing quotation mark. This will make the computer think you are still making a giantly long string. 3.6 Matrices A matrix is just a collection of vectors You can combine vectors by column using ‘cbind’ m1 &lt;- cbind(vap, tv) head(m1) ## vap tv ## [1,] 3481823 NA ## [2,] 496387 238307 ## [3,] 4582842 1553032 ## [4,] 2120139 780409 ## [5,] 26955438 8899059 ## [6,] 3617942 1586105 Or you can combine by rows using ‘rbind’ m2 &lt;- rbind(vap, tv) head(m2) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] ## vap 3481823 496387 4582842 2120139 26955438 3617942 2673154 652189 472143 ## tv NA 238307 1553032 780409 8899059 1586105 1162391 258053 122356 ## [,10] [,11] [,12] [,13] [,14] [,15] [,16] [,17] [,18] ## vap 14085749 6915512 995937 1073799 9600372 4732010 2265860 2068253 3213141 ## tv 4884544 2143845 348988 458927 3586292 1719351 1071509 864083 1370062 ## [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26] [,27] ## vap 3188765 1033632 4242214 4997677 7620982 3908159 2139918 4426278 731365 ## tv 954896 NA 1809237 2243835 3852008 2217552 NA 2178278 411061 ## [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] ## vap 1321923 1870315 1012033 6598368 1452962 14838076 6752018 494923 8697456 ## tv 610499 586274 418550 2315643 568597 4703830 2036451 220479 4184072 ## [,37] [,38] [,39] [,40] [,41] [,42] [,43] [,44] [,45] ## vap 2697855 2850525 9612380 824854 3303593 594599 4636679 17038979 1797941 ## tv NA 1399650 NA 392882 1117311 341105 1868363 NA 582561 ## [,46] [,47] [,48] [,49] [,50] [,51] ## vap 487900 5841335 4876661 1421717 4257230 392344 ## tv 263025 2398589 2085074 473014 2183155 196217 We can access by ‘matrixname[row, column]’ m2[1,2] # first row, second column ## vap ## 496387 m1[,1] # the 1st column ## [1] 3481823 496387 4582842 2120139 26955438 3617942 2673154 652189 ## [9] 472143 14085749 6915512 995937 1073799 9600372 4732010 2265860 ## [17] 2068253 3213141 3188765 1033632 4242214 4997677 7620982 3908159 ## [25] 2139918 4426278 731365 1321923 1870315 1012033 6598368 1452962 ## [33] 14838076 6752018 494923 8697456 2697855 2850525 9612380 824854 ## [41] 3303593 594599 4636679 17038979 1797941 487900 5841335 4876661 ## [49] 1421717 4257230 392344 Can get a submatrix m1[1:5,1:2] ## vap tv ## [1,] 3481823 NA ## [2,] 496387 238307 ## [3,] 4582842 1553032 ## [4,] 2120139 780409 ## [5,] 26955438 8899059 m2[1,1:10] ## [1] 3481823 496387 4582842 2120139 26955438 3617942 2673154 652189 ## [9] 472143 14085749 m2[1,1:10] ## [1] 3481823 496387 4582842 2120139 26955438 3617942 2673154 652189 ## [9] 472143 14085749 m2[1:2, 1:10] ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] ## vap 3481823 496387 4582842 2120139 26955438 3617942 2673154 652189 472143 ## tv NA 238307 1553032 780409 8899059 1586105 1162391 258053 122356 ## [,10] ## vap 14085749 ## tv 4884544 m2[, 1:10] # same as previous line since there are only two rows. ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] ## vap 3481823 496387 4582842 2120139 26955438 3617942 2673154 652189 472143 ## tv NA 238307 1553032 780409 8899059 1586105 1162391 258053 122356 ## [,10] ## vap 14085749 ## tv 4884544 class(m2) ## [1] &quot;matrix&quot; Objects in R are simply pieces of data that contain specific attributes. Classes define what attributes an object must have and can have. Matrices always have an attribute that determines the number of rows and columns dim(m1) ## [1] 51 2 For any object you can look at it’s attributes using (helpfully) the ‘attributes’ function attributes(m1) ## $dim ## [1] 51 2 ## ## $dimnames ## $dimnames[[1]] ## NULL ## ## $dimnames[[2]] ## [1] &quot;vap&quot; &quot;tv&quot; We see that the matrix also has another attribute dimnames(m1) ## [[1]] ## NULL ## ## [[2]] ## [1] &quot;vap&quot; &quot;tv&quot; The top refers to the row names (which do not exist) The bottom are the column names (that were borrowed from the vectors used to construct the matrix). You can also access these using functions colnames(m1) ## [1] &quot;vap&quot; &quot;tv&quot; colnames(m2) ## NULL rownames(m1) ## NULL rownames(m2) ## [1] &quot;vap&quot; &quot;tv&quot; And you can reset these using the same functions colnames(m1)&lt;-c(&quot;Voting age population&quot;, &quot;Total Votes&quot;) colnames(m1) ## [1] &quot;Voting age population&quot; &quot;Total Votes&quot; You can also do this with the following dimnames(m1)[[2]][1]&lt;-&quot;Pigglywiggly&quot; head(m1) ## Pigglywiggly Total Votes ## [1,] 3481823 NA ## [2,] 496387 238307 ## [3,] 4582842 1553032 ## [4,] 2120139 780409 ## [5,] 26955438 8899059 ## [6,] 3617942 1586105 We have re-named the first column to have the name “Pigglywiggly” We are able to do this because the output of ‘dimnames’ is a list You can subset matrices with a boolean/logical matrix to get certain values from it just like you would a vector Matrices (and vectors) can only contain one datatype If you try to create one with multiple datatypes, it will convert everything to be the same datatype 3.7 Matrix algebra (optional) A couple of matrices H3&lt;-matrix(c(1, 1/2, 1/3, 1/2, 1/3, 1/4, 1/3, 1/4, 1/5), nrow=3) H3 ## [,1] [,2] [,3] ## [1,] 1.0000000 0.5000000 0.3333333 ## [2,] 0.5000000 0.3333333 0.2500000 ## [3,] 0.3333333 0.2500000 0.2000000 1/cbind(seq(1,3), seq(2, 4), seq(3,5)) # most basic function continue to be &quot;element wise&quot; ## [,1] [,2] [,3] ## [1,] 1.0000000 0.5000000 0.3333333 ## [2,] 0.5000000 0.3333333 0.2500000 ## [3,] 0.3333333 0.2500000 0.2000000 H3+1 ## [,1] [,2] [,3] ## [1,] 2.000000 1.500000 1.333333 ## [2,] 1.500000 1.333333 1.250000 ## [3,] 1.333333 1.250000 1.200000 H3*2 ## [,1] [,2] [,3] ## [1,] 2.0000000 1.0000000 0.6666667 ## [2,] 1.0000000 0.6666667 0.5000000 ## [3,] 0.6666667 0.5000000 0.4000000 H3^2 ## [,1] [,2] [,3] ## [1,] 1.0000000 0.2500000 0.1111111 ## [2,] 0.2500000 0.1111111 0.0625000 ## [3,] 0.1111111 0.0625000 0.0400000 mean(H3) # others will treat the matrix as a vector no matter what ## [1] 0.4111111 rowSums(H3) # others work on matrices in particular ways (more on this later) ## [1] 1.8333333 1.0833333 0.7833333 colSums(H3) ## [1] 1.8333333 1.0833333 0.7833333 rowMeans(H3) ## [1] 0.6111111 0.3611111 0.2611111 colMeans(H3) ## [1] 0.6111111 0.3611111 0.2611111 Logicals work too H3 == 1 ## [,1] [,2] [,3] ## [1,] TRUE FALSE FALSE ## [2,] FALSE FALSE FALSE ## [3,] FALSE FALSE FALSE H3 == c(1,2,3) # wha...? ## [,1] [,2] [,3] ## [1,] TRUE FALSE FALSE ## [2,] FALSE FALSE FALSE ## [3,] FALSE FALSE FALSE H3 == H3 ## [,1] [,2] [,3] ## [1,] TRUE TRUE TRUE ## [2,] TRUE TRUE TRUE ## [3,] TRUE TRUE TRUE Some work like they do in the math books det(H3) # the determinant -- hard for you ... easy in R ## [1] 0.000462963 diag(H3) # get the diagonal elements of amatrix ## [1] 1.0000000 0.3333333 0.2000000 diag(1, nrow=3) # make a 3by3 identity matrix ## [,1] [,2] [,3] ## [1,] 1 0 0 ## [2,] 0 1 0 ## [3,] 0 0 1 t(H3) # matrix transpose ## [,1] [,2] [,3] ## [1,] 1.0000000 0.5000000 0.3333333 ## [2,] 0.5000000 0.3333333 0.2500000 ## [3,] 0.3333333 0.2500000 0.2000000 Hnew&lt;-H3 Hnew[lower.tri(H3, diag=TRUE)] # extract the lower triangular elements of H3 ## [1] 1.0000000 0.5000000 0.3333333 0.3333333 0.2500000 0.2000000 # Get the trace trace &lt;- function(data) (sum(diag(data))) # our own little function .. more on this next time trace(H3) ## [1] 1.533333 # Matrix multipication is %*% t(H3)%*%H3 ## [,1] [,2] [,3] ## [1,] 1.361111 0.7500000 0.5250000 ## [2,] 0.750000 0.4236111 0.3000000 ## [3,] 0.525000 0.3000000 0.2136111 c(1,2,3)%*%c(1,2,3) # dot product ## [,1] ## [1,] 14 matrix(c(1,2,3), ncol=1)%*%c(1,2,3) # outer product ## [,1] [,2] [,3] ## [1,] 1 2 3 ## [2,] 2 4 6 ## [3,] 3 6 9 #matrix inversion solve(H3) ## [,1] [,2] [,3] ## [1,] 9 -36 30 ## [2,] -36 192 -180 ## [3,] 30 -180 180 invH3&lt;-solve(H3) H3%*%invH3 ## close enough? ## [,1] [,2] [,3] ## [1,] 1.000000e+00 0.000000e+00 0 ## [2,] 8.881784e-16 1.000000e+00 0 ## [3,] 0.000000e+00 -7.105427e-15 1 # Why is it called solve? It can also be used to solve linear systems. b&lt;-c(1,2,3) b ## [1] 1 2 3 solve(H3, b) ## [1] 27 -192 210 3.8 Lists Let’s make a list that contains a matrix, a vector, and an integer. list.a&lt;-list(m1, vap, 3) str(list.a) ## List of 3 ## $ : num [1:51, 1:2] 3481823 496387 4582842 2120139 26955438 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : NULL ## .. ..$ : chr [1:2] &quot;Pigglywiggly&quot; &quot;Total Votes&quot; ## $ : num [1:51] 3481823 496387 4582842 2120139 26955438 ... ## $ : num 3 This is the advantage of lists. They can contain basically anything, even other lists vector1&lt;-c(1,2,3) gospels&lt;-c(&quot;matthew&quot;,&quot;mark&quot;,&quot;luke&quot;, &quot;john&quot;) my.matrix&lt;-matrix(c(1:20), nrow=4) my.data&lt;-data.frame(cbind(vap, tv)) my.crazy.list&lt;-list(vector1, gospels, my.matrix, TRUE, list.a) str(my.crazy.list) ## List of 5 ## $ : num [1:3] 1 2 3 ## $ : chr [1:4] &quot;matthew&quot; &quot;mark&quot; &quot;luke&quot; &quot;john&quot; ## $ : int [1:4, 1:5] 1 2 3 4 5 6 7 8 9 10 ... ## $ : logi TRUE ## $ :List of 3 ## ..$ : num [1:51, 1:2] 3481823 496387 4582842 2120139 26955438 ... ## .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. ..$ : NULL ## .. .. ..$ : chr [1:2] &quot;Pigglywiggly&quot; &quot;Total Votes&quot; ## ..$ : num [1:51] 3481823 496387 4582842 2120139 26955438 ... ## ..$ : num 3 Lists have attributes but we haven’t set them yet attributes(my.crazy.list) ## NULL This reports the number of major sub-elements in the list. length(my.crazy.list) ## [1] 5 This won’t work for complicated lists dim(my.crazy.list) ## NULL We can give names to elements of a list names(my.crazy.list)&lt;-c(&quot;OneTwoThree&quot;, &quot;Gospels&quot;, &quot;SmallMat&quot;, &quot;OneLogical&quot;, &quot;AnotherList&quot;) str(my.crazy.list) ## List of 5 ## $ OneTwoThree: num [1:3] 1 2 3 ## $ Gospels : chr [1:4] &quot;matthew&quot; &quot;mark&quot; &quot;luke&quot; &quot;john&quot; ## $ SmallMat : int [1:4, 1:5] 1 2 3 4 5 6 7 8 9 10 ... ## $ OneLogical : logi TRUE ## $ AnotherList:List of 3 ## ..$ : num [1:51, 1:2] 3481823 496387 4582842 2120139 26955438 ... ## .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. ..$ : NULL ## .. .. ..$ : chr [1:2] &quot;Pigglywiggly&quot; &quot;Total Votes&quot; ## ..$ : num [1:51] 3481823 496387 4582842 2120139 26955438 ... ## ..$ : num 3 Now each part of the list has a name attribute Skip the steps above by doing the following: my.crazy.list&lt;-list(OneTwoThree=vector1, Gospels=gospels, SmallMat=my.matrix, OneLogical=TRUE, AnotherList=list.a) str(my.crazy.list) ## List of 5 ## $ OneTwoThree: num [1:3] 1 2 3 ## $ Gospels : chr [1:4] &quot;matthew&quot; &quot;mark&quot; &quot;luke&quot; &quot;john&quot; ## $ SmallMat : int [1:4, 1:5] 1 2 3 4 5 6 7 8 9 10 ... ## $ OneLogical : logi TRUE ## $ AnotherList:List of 3 ## ..$ : num [1:51, 1:2] 3481823 496387 4582842 2120139 26955438 ... ## .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. ..$ : NULL ## .. .. ..$ : chr [1:2] &quot;Pigglywiggly&quot; &quot;Total Votes&quot; ## ..$ : num [1:51] 3481823 496387 4582842 2120139 26955438 ... ## ..$ : num 3 names(my.crazy.list) ## [1] &quot;OneTwoThree&quot; &quot;Gospels&quot; &quot;SmallMat&quot; &quot;OneLogical&quot; &quot;AnotherList&quot; There are at least four ways of accessing elements of a list my.crazy.list[[1]] ## [1] 1 2 3 my.crazy.list$OneTwoThree ## [1] 1 2 3 my.crazy.list[1] ## $OneTwoThree ## [1] 1 2 3 my.crazy.list[&quot;OneTwoThree&quot;] ## $OneTwoThree ## [1] 1 2 3 You can add elements in a similarly confusing number of ways my.crazy.list$hocuspocus&lt;-&quot;hocuspocus&quot; str(my.crazy.list) ## List of 6 ## $ OneTwoThree: num [1:3] 1 2 3 ## $ Gospels : chr [1:4] &quot;matthew&quot; &quot;mark&quot; &quot;luke&quot; &quot;john&quot; ## $ SmallMat : int [1:4, 1:5] 1 2 3 4 5 6 7 8 9 10 ... ## $ OneLogical : logi TRUE ## $ AnotherList:List of 3 ## ..$ : num [1:51, 1:2] 3481823 496387 4582842 2120139 26955438 ... ## .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. ..$ : NULL ## .. .. ..$ : chr [1:2] &quot;Pigglywiggly&quot; &quot;Total Votes&quot; ## ..$ : num [1:51] 3481823 496387 4582842 2120139 26955438 ... ## ..$ : num 3 ## $ hocuspocus : chr &quot;hocuspocus&quot; You can also access access/add to/subtract from the sub-elements themselves. We just add what we know about accessing elements of matrices/vectors/etc. to how we access lists. my.crazy.list[[3]][1,] # first row of my.matrix ## [1] 1 5 9 13 17 my.matrix[1,] #the same ## [1] 1 5 9 13 17 But lists don’t play well with basic commands. Only components of lists. #this won&#39;t work #my.crazy.list + 2 #but this will! my.crazy.list[[3]] + 2 ## [,1] [,2] [,3] [,4] [,5] ## [1,] 3 7 11 15 19 ## [2,] 4 8 12 16 20 ## [3,] 5 9 13 17 21 ## [4,] 6 10 14 18 22 3.9 Arrays Arrays are effectively matrices that can have more than 2 dimensions. An array with exactly two dimensions is a matrix. The following example creates an array of two 3x4 matrices each with 3 rows and 4 columns. # Take the sequence from 1 to 24 as input to the array. result &lt;- array(1:24, dim=c(3,4,2)) result ## , , 1 ## ## [,1] [,2] [,3] [,4] ## [1,] 1 4 7 10 ## [2,] 2 5 8 11 ## [3,] 3 6 9 12 ## ## , , 2 ## ## [,1] [,2] [,3] [,4] ## [1,] 13 16 19 22 ## [2,] 14 17 20 23 ## [3,] 15 18 21 24 # You can also name all of the dimensions. column.names &lt;- c(&quot;COL1&quot;,&quot;COL2&quot;,&quot;COL3&quot;,&quot;COL4&quot;) row.names &lt;- c(&quot;ROW1&quot;,&quot;ROW2&quot;,&quot;ROW3&quot;) matrix.names &lt;- c(&quot;Matrix1&quot;,&quot;Matrix2&quot;) result2 &lt;- array(1:24, dim=c(3,4,2), dimnames=list(row.names, column.names, matrix.names)) result2 ## , , Matrix1 ## ## COL1 COL2 COL3 COL4 ## ROW1 1 4 7 10 ## ROW2 2 5 8 11 ## ROW3 3 6 9 12 ## ## , , Matrix2 ## ## COL1 COL2 COL3 COL4 ## ROW1 13 16 19 22 ## ROW2 14 17 20 23 ## ROW3 15 18 21 24 # Print the third row of the second matrix of the array. result[3,,2] ## [1] 15 18 21 24 # Print the element in the 1st row and 3rd column of the 1st matrix. result[1,3,1] ## [1] 7 # Print the 2nd Matrix. result[,,2] ## [,1] [,2] [,3] [,4] ## [1,] 13 16 19 22 ## [2,] 14 17 20 23 ## [3,] 15 18 21 24 3.10 Dataframes They are rectangular like a matrix, but each column can be of a different class and you can access elements of the data frame like it’s a list. turnout &lt;- tv/vap voting.data &lt;- data.frame(tv, vap, turnout) head(voting.data) ## tv vap turnout ## 1 NA 3481823 NA ## 2 238307 496387 0.4800831 ## 3 1553032 4582842 0.3388797 ## 4 780409 2120139 0.3680933 ## 5 8899059 26955438 0.3301397 ## 6 1586105 3617942 0.4383998 str(voting.data) ## &#39;data.frame&#39;: 51 obs. of 3 variables: ## $ tv : num NA 238307 1553032 780409 8899059 ... ## $ vap : num 3481823 496387 4582842 2120139 26955438 ... ## $ turnout: num NA 0.48 0.339 0.368 0.33 ... There are at least four ways to access a variable head(voting.data[[1]]) ## [1] NA 238307 1553032 780409 8899059 1586105 head(voting.data$tv) ## [1] NA 238307 1553032 780409 8899059 1586105 head(voting.data[&quot;tv&quot;]) ## tv ## 1 NA ## 2 238307 ## 3 1553032 ## 4 780409 ## 5 8899059 ## 6 1586105 head(voting.data[,1]) ## [1] NA 238307 1553032 780409 8899059 1586105 names(voting.data) #access the column names ## [1] &quot;tv&quot; &quot;vap&quot; &quot;turnout&quot; # NOTE: dataframes always have column names!! colnames(voting.data) ## [1] &quot;tv&quot; &quot;vap&quot; &quot;turnout&quot; We can change back and forth between a matrix and a data frame as.data.frame(my.matrix) ## V1 V2 V3 V4 V5 ## 1 1 5 9 13 17 ## 2 2 6 10 14 18 ## 3 3 7 11 15 19 ## 4 4 8 12 16 20 data.frame(my.matrix) ## X1 X2 X3 X4 X5 ## 1 1 5 9 13 17 ## 2 2 6 10 14 18 ## 3 3 7 11 15 19 ## 4 4 8 12 16 20 head(as.matrix(voting.data)) ## tv vap turnout ## [1,] NA 3481823 NA ## [2,] 238307 496387 0.4800831 ## [3,] 1553032 4582842 0.3388797 ## [4,] 780409 2120139 0.3680933 ## [5,] 8899059 26955438 0.3301397 ## [6,] 1586105 3617942 0.4383998 Sometimes all of this can be a bit cumbersome The ‘with’ command will run a function with the dataset slightly easier # these are equivalent mean(voting.data$vap) ## [1] 4430673 with(voting.data, mean(vap)) ## [1] 4430673 3.11 General info You can determine the type of a variable by calling class on it as follows class(vap) ## [1] &quot;numeric&quot; There are functions to move back and forth between types (‘as.class’ functions) grp &lt;- c(&quot;control&quot;, &quot;treatment&quot;, &quot;control&quot;, &quot;treatment&quot;) grp &lt;- factor(grp) as.integer(grp) ## [1] 1 2 1 2 You can also check if an object is a specific class. is.integer(vap) ## [1] FALSE is.numeric(vap) ## [1] TRUE There are several types of these as.character(0:5) # Turning numbers into characters ## [1] &quot;0&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; as.logical(0:5) # All numbers but &#39;0&#39; become TRUE ## [1] FALSE TRUE TRUE TRUE TRUE TRUE But not all of them work as.numeric(c(&#39;1&#39;, &#39;2&#39;, &#39;3&#39;)) ## [1] 1 2 3 as.numeric(c(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;)) ## Warning: NAs introduced by coercion ## [1] NA NA NA "],
["files-for-loops-and-functions.html", "4 Files, For Loops, and Functions 4.1 The working directory 4.2 Input and output 4.3 if, else, ifelse 4.4 repeat and while 4.5 for loops 4.6 Functions 4.7 Setting defaults 4.8 Scope 4.9 Debugging 4.10 Benchmarking and code improvements", " 4 Files, For Loops, and Functions 4.1 The working directory First we want to change the working directory. This is the folder where R will save and look for data by default (although you can always override this) Note that the file path (in Windows at least) requires slashes. You can either use two back slashes to separate folders or one forward slash. setwd(&quot;~/Dropbox/Classes/R Programming&quot;) ## For Windows, will need to be something like setwd(&quot;C:\\\\Documents and Settings\\\\Jacob Montgomery\\\\My Documents\\\\RWork&quot;) ## or setwd(&quot;C:/Documents and Settings/Jacob Montgomery/My Documents/RWork&quot;) ## or setwd(file.path(&quot;C:&quot;, &quot;Documents and Settings&quot;, &quot;Jacob Montgomery&quot;, &quot;My Documents&quot;, &quot;RWork&quot;)) 4.2 Input and output voting.data&lt;-data.frame(vap, tv) Now let’s save our newly created dataset dump(&quot;voting.data&quot;, &quot;voting.data.R&quot;) # inputs are string. Note that you must put the *.R in yourself You might also want to save multiple objects dump(c(&quot;vap&quot;, &quot;tv&quot;), &quot;voting.data.vectors.R&quot;) dump(list=objects(), &quot;everything.R&quot;) ## an alternative we can just use the command save.image(&quot;everything.RData&quot;) # saves an image of your current workspace Now we can clear our wokspace, and load these objects rm(list=ls()) source(&quot;voting.data.vectors.R&quot;) ls() # only saved objects present To read/write dataframes from/to a csv (comma separated values) file, the following commands will be useful votes.06&lt;-read.csv(&quot;~/Dropbox/Classes/R Programming/R Scripts/VotingData2006.csv&quot;, header=T) write.csv(votes.06, file=&quot;VD06.csv&quot;) Tips: All of the functions for reading in data are actually using the scan() function. No matter how crazy your data look, you can always read it into R by clever use of scan(). 4.3 if, else, ifelse The basic syntax for an if call is if(condition){ commands to run } The inputs in the parentheses needs can be anything that returns a logical. You can put anything you want in the braces The simplest examples possible. if(TRUE) { print(&quot;I got here&quot;) } ## [1] &quot;I got here&quot; if(FALSE){ print(&quot;I can&#39;t get here&quot;) } You can combine this with else if(condition) { commands to run when condition is TRUE } else { # notice that these are on the same line commands to run when the condition is FALSE } x = 10 if(x &gt; 2) { print(&quot;X is larger than 2&quot;) } else { print(&quot;X is 2 or smaller&quot;) } ## [1] &quot;X is larger than 2&quot; But this set up will not play well with vectors. It runs, but is confusing if (c(3, 1) &gt; 2){ print(&quot;This won&#39;t work&quot;) } ## Warning in if (c(3, 1) &gt; 2) {: the condition has length &gt; 1 and only the first ## element will be used ## [1] &quot;This won&#39;t work&quot; The ifelse command works nicely with vectors, but syntax is different. This command is equivalent to a ternary in other languages if you’re familiar with that term. ifelse(condition, return when condition T, return when condition F) x = c(0, 2) ifelse(x &gt; 1, &quot;yes&quot;, &quot;no&quot;) ## [1] &quot;no&quot; &quot;yes&quot; WARNING If your outputs are vectors ifelse will work element-wise yes = c(&quot;yes1&quot;, &quot;yes2&quot;) no = c(&quot;no1&quot;, &quot;no2&quot;) ifelse(x &gt; 1, yes, no) ## [1] &quot;no1&quot; &quot;yes2&quot; ifelse(x &lt; 2, yes, no) ## [1] &quot;yes1&quot; &quot;no2&quot; Note that the curly braces are not technically necessary if you have only a one line command BUT you should use them anyway so someone can read your code! x = 3 if (x &gt; 2) y = 2 * x else y = 3 * x y ## [1] 6 4.4 repeat and while Repeat just repeats commands in the braces until it sees a BREAK command If you don’t include BREAK your computer will be in an infinite loop. Save your work before using! Or maybe just don’t use it repeat{ stuff to do until it sees BREAK } # make a blank plot with the limits set by those vectors plot(NULL, xlim=c(0, 100), ylim=c(0, 1), xlab=&quot;x&quot;, ylab=&quot;1/x&quot;) x = 1 repeat { y = 1 / x x = x + 1 points(x, y) if (x == 100) { break } } A while loop is just a repeat, where the break condition is specified at the top while(condition){ commands that repeat until condition flips to FALSE } plot(NULL, xlim=c(0, 100), ylim=c(0, 1), xlab=&quot;x&quot;, ylab=&quot;1/x&quot;) x = 1 while(x &lt; 100) { y = 1 / x x = x + 1 points(x, y) } 4.5 for loops The for command is probably the most common flow control option. It has three basic parts: An object name that will be used in the following commands A vector that we will “loop over” Commands that will be executed for each value of the vector for (name in vector){ execute these commands using each value of the vecotr } for (monkey in c(&quot;Spider&quot;, &quot;Howler&quot;, &quot;Rhesus&quot;)) { ## Each loop does the equivalent of: monkey = &quot;Spider&quot; or monkey = &quot;Howler&quot; or ... print(monkey) } ## [1] &quot;Spider&quot; ## [1] &quot;Howler&quot; ## [1] &quot;Rhesus&quot; Or more commonly for (i in 1:10){ print(i) } ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 ## [1] 5 ## [1] 6 ## [1] 7 ## [1] 8 ## [1] 9 ## [1] 10 ## for loops are very useful in many situations plot(NULL, xlim=c(0, 100), ylim=c(0, 1)) for (i in 1:100) { points(i, 1 / i) } 4.5.1 next and break Sometimes you might not want to execute the commands for every element in the vector use the next command to skip (you can also use the break) some.odds = NULL for (i in 1:200) { if (i %% 2 == 0) { next } some.odds = c(some.odds, i) } some.odds ## [1] 1 3 5 7 9 11 13 15 17 19 21 23 25 27 29 31 33 35 ## [19] 37 39 41 43 45 47 49 51 53 55 57 59 61 63 65 67 69 71 ## [37] 73 75 77 79 81 83 85 87 89 91 93 95 97 99 101 103 105 107 ## [55] 109 111 113 115 117 119 121 123 125 127 129 131 133 135 137 139 141 143 ## [73] 145 147 149 151 153 155 157 159 161 163 165 167 169 171 173 175 177 179 ## [91] 181 183 185 187 189 191 193 195 197 199 Technically, you don’t have to be so formal. But the indenting and braces are there for the protection of your future self. for (i in 1:10) print(i) ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 ## [1] 5 ## [1] 6 ## [1] 7 ## [1] 8 ## [1] 9 ## [1] 10 4.6 Functions 4.6.1 The basics Use the ‘function’ command and assign it to an object If you need, specify the expected inputs Do some stuff Return something (and only one thing) to the global environment. my.function = function(x) { do stuff here return(output) } Here’s an example: countThrees = function(vector) { threes &lt;- 0 for(i in vector) { if(i == 3) { threes &lt;- threes + 1 } } return(threes) } v &lt;- c(1, 2, 3, 4, 3, 3) countThrees(v) ## [1] 3 What would happen if we passed in one number instead of a vector? countThrees(2) ## [1] 0 countThrees(3) ## [1] 1 Or a matrix? m &lt;- matrix(1:24, 4, 6) countThrees(m) ## [1] 1 If you want to return multiple values in R, you must put them in a vector or list and return the data structure instead. Remember that a list is essentially a vector that can contain different data types. Sometimes a function will return a value, but other times it will just execute a command like print or plot. 4.7 Setting defaults You can set default values for some of your arguments or all of them gaga.equation = function(num.rah=2, num.ah=3, num.ga=2, num.la=2, num.oo=1) { rahs = paste(rep(&quot;RAH&quot;, num.rah), collapse=&quot;, &quot;) ahs = paste(rep(&quot;AH&quot;, num.ah), collapse=&quot;, &quot;) gas = paste(rep(&quot;GA&quot;, num.ga), collapse=&quot;, &quot;) oo = paste(rep(&quot;OO&quot;, num.oo), collapse=&quot;, &quot;) las = paste(rep(&quot;LA&quot;, num.la), collapse=&quot;, &quot;) paste(rahs, &quot;,&quot;, ahs, &quot;! ROMA, ROMAMA!&quot;, gas, &quot;,&quot;, oo, las) } gaga.equation() ## [1] &quot;RAH, RAH , AH, AH, AH ! ROMA, ROMAMA! GA, GA , OO LA, LA&quot; gaga.equation(num.rah=5) ## [1] &quot;RAH, RAH, RAH, RAH, RAH , AH, AH, AH ! ROMA, ROMAMA! GA, GA , OO LA, LA&quot; If an argument (sometimes called a parameter) does not have a default value, it must be specified when the function is called. 4.8 Scope In the example above, if we tried to print rahs outside of the function, we would get an error. The variable rahs doesn’t exist in the global environment. print(rahs) What happens in the function, stays in the function Remember that for loop variables can be accessed after the loop. for(i in 1:4) { print(i+2) } ## [1] 3 ## [1] 4 ## [1] 5 ## [1] 6 print(i) ## [1] 4 Note that i equals 4 (its last loop value) after the loop is finished. This is different from functions because the only way to retain access to a local variable that was created in the function is to return it. a &lt;- 10 outer_func &lt;- function() { a &lt;- 20 inner_func &lt;- function() { a &lt;- 30 print(a) } inner_func() print(a) } outer_func() ## [1] 30 ## [1] 20 a ## [1] 10 If you try to run inner_func(), it will say “Error in inner_func() : could not find function”inner_func\"\" because that function is actually a local object inside the function outer_func. That means that outer_func is the only place that can use inner_func. Scope kind of works like a bunch of one way mirrors. If I write a function, it can access all global variables and local (to the function) variables, but the global environment can only access global variables. In the above code example, inner_func can access all of its variables, all of outer_func’s variables, and the global environment variables as well. 4.8.1 Advanced scope topics In R, there’s a superassignment operator which is &lt;&lt;- This assigns the variable to one environment up from its current location. Check out these examples and try to follow along with the environments. This example will replace the global variable a (which used to store 10) with 20 from the outer_func code. Printing a at the end of the script will print 20 this time. a &lt;- 10 outer_func &lt;- function() { a &lt;&lt;- 20 inner_func &lt;- function() { a &lt;- 30 print(a) } inner_func() print(a) } outer_func() ## [1] 30 ## [1] 20 a ## [1] 20 This example will replace a from the outer_func environment with the value 30 so when outer_func prints a, it will now contain 30. a &lt;- 10 outer_func &lt;- function() { a &lt;- 20 inner_func &lt;- function() { a &lt;&lt;- 30 print(a) } inner_func() print(a) } outer_func() ## [1] 30 ## [1] 30 a ## [1] 10 4.9 Debugging traceback will help you identify the function that is failing debug, debugonce will go through a function one line at a time browser This let’s you work within the function environment starting at a specified point Here’s an example to help us practice our debugging skills: webData&lt;-url(&quot;http://pages.wustl.edu/montgomery/incumbents2.txt&quot;) OOS &lt;- read.table(webData) summary(OOS) ## x year congress chalspend ## Min. : 1 Min. :1956 Min. : 84.00 Min. : 8.517 ## 1st Qu.:1672 1st Qu.:1968 1st Qu.: 90.00 1st Qu.: 9.315 ## Median :3347 Median :1978 Median : 95.00 Median :10.998 ## Mean :3348 Mean :1977 Mean : 94.42 Mean :10.880 ## 3rd Qu.:5024 3rd Qu.:1988 3rd Qu.:100.00 3rd Qu.:12.366 ## Max. :6695 Max. :1996 Max. :104.00 Max. :15.039 ## NA&#39;s :3380 ## incspend difflog presvote voteshare ## Min. : 8.586 Min. :-3.060 Min. :0.06565 Min. :0.3476 ## 1st Qu.:12.304 1st Qu.: 0.686 1st Qu.:0.46894 1st Qu.:0.5740 ## Median :12.839 Median : 1.651 Median :0.55519 Median :0.6450 ## Mean :12.759 Mean : 1.858 Mean :0.55335 Mean :0.6470 ## 3rd Qu.:13.266 3rd Qu.: 3.025 3rd Qu.:0.63425 3rd Qu.:0.7141 ## Max. :15.422 Max. : 5.856 Max. :0.96061 Max. :0.9997 ## NA&#39;s :3374 NA&#39;s :3436 NA&#39;s :125 ## inparty incparty seniority midterm ## Min. :0.0000 Min. :0.000 Min. : 1.000 Min. :0.0000 ## 1st Qu.:0.0000 1st Qu.:0.000 1st Qu.: 2.000 1st Qu.:0.0000 ## Median :0.0000 Median :1.000 Median : 4.000 Median :0.0000 ## Mean :0.4942 Mean :0.563 Mean : 4.949 Mean :0.2327 ## 3rd Qu.:1.0000 3rd Qu.:1.000 3rd Qu.: 7.000 3rd Qu.:0.0000 ## Max. :1.0000 Max. :1.000 Max. :26.000 Max. :1.0000 ## ## chalquality south population urban ## Min. :0.0000 Min. :0.0000 Min. :11.98 Min. : 5.956 ## 1st Qu.:0.0000 1st Qu.:0.0000 1st Qu.:12.92 1st Qu.:12.325 ## Median :0.0000 Median :0.0000 Median :13.06 Median :12.728 ## Mean :0.2348 Mean :0.2378 Mean :13.04 Mean :12.612 ## 3rd Qu.:0.0000 3rd Qu.:0.0000 3rd Qu.:13.16 3rd Qu.:13.006 ## Max. :1.0000 Max. :1.0000 Max. :17.08 Max. :16.481 ## NA&#39;s :5 NA&#39;s :2 NA&#39;s :2 ## age65 milpop unemployed incspend2 ## Min. : 8.164 Min. : 3.045 Min. : 7.425 Min. : 5355 ## 1st Qu.:10.452 1st Qu.: 5.517 1st Qu.: 8.816 1st Qu.: 220620 ## Median :10.760 Median : 6.246 Median : 9.142 Median : 376741 ## Mean :10.819 Mean : 6.777 Mean : 9.170 Mean : 450124 ## 3rd Qu.:11.215 3rd Qu.: 8.077 3rd Qu.: 9.544 3rd Qu.: 577283 ## Max. :14.552 Max. :12.691 Max. :13.147 Max. :4987593 ## NA&#39;s :2 NA&#39;s :2 NA&#39;s :2 NA&#39;s :3374 boxplot(voteshare~inparty, data=OOS[OOS$year==1956,]) plot(voteshare~inparty, data=OOS[OOS$year==1956,]) Running a regression by year: Do you see a pattern? output.vector&lt;-NULL for (i in unique(OOS$year)){ output.vector[which(unique(OOS$year) == i)]&lt;- lm(voteshare ~ inparty, data=OOS[OOS$year == i,])$coefficients[2] } plot(unique(OOS$year), output.vector, type=&quot;l&quot;, ylab=&quot;Coefficient (President&#39;s party)&quot;, xlab=&quot;Year&quot;) abline(h=0, lty=3) Now we might think – there is a more general case where I want to get a bunch of seperate regression estimates on defined subsets of the data by.var.lm&lt;-function(by.var, formula, data, coef.num){ output.vector&lt;-NULL for (i in unique(by.var)){ output.vector[which(unique(by.var) == i)]&lt;- lm(formula, data=data[by.var == i,])$coefficients[coef.num] } return(output.vector) } plot(by.var.lm(year, voteshare~inparty, OOS, 2), type=&quot;l&quot;) This is not working, what to do? As a first step, figure out where it’s broken using traceback traceback(by.var.lm(year, voteshare~inparty, OOS, 2)) A second thing to try is to use debug debug(by.var.lm) A second thing to try is to put a broswer function into the function itself browser() Another thing to try is just put in some various print commands by.var.lm&lt;-function(by.var, formula, data, coef.num){ output.vector&lt;-NULL; print(&quot;one&quot;) for (i in unique(by.var)){ print(i) # I can see where I get to in the loop output.vector[which(unique(by.var) == i)]&lt;- lm(formula, data=data[by.var == i,])$coefficients[coef.num] } print(&#39;got out of loop&#39;) return(output.vector) } plot(by.var.lm(year, voteshare~inparty, OOS, 2), type=&quot;l&quot;) So now I have a function that works, can I use it again? website&lt;-url(&quot;http://pages.wustl.edu/montgomery/titanic&quot;) titanic&lt;-read.delim(website) table(titanic$Gender) table(titanic$Class) Make this work by.var.lm(Class, (as.numeric(Survived)-1) ~ Gender, titanic, 2) 4.10 Benchmarking and code improvements x &lt;- runif(500) system.time(sqrt(x)) ## user system elapsed ## 0 0 0 The goal is to see how long a function takes to evaluate Much better: microbenchmark library(microbenchmark) microbenchmark(sqrt(x)) # evaluates 100 times per default ## Unit: microseconds ## expr min lq mean median uq max neval ## sqrt(x) 8.6 8.8 9.294 8.9 9.3 20.1 100 microbenchmark(sqrt(x), times=1000) ## Unit: microseconds ## expr min lq mean median uq max neval ## sqrt(x) 3.4 3.6 5.5099 6.5 6.8 28.4 1000 Now we can compare different functions microbenchmark(sqrt(x), x^0.5, times=1000) ## Unit: microseconds ## expr min lq mean median uq max neval ## sqrt(x) 3.5 6.0 6.3815 6.3 6.8 28.8 1000 ## x^0.5 25.8 33.6 38.2472 40.8 43.0 56.9 1000 microbenchmark(sqrt(x), x^0.5, x^(1/2), exp(log(x)/2), times=1000) ## Unit: microseconds ## expr min lq mean median uq max neval ## sqrt(x) 3.4 3.7 5.9840 4.2 7.00 27.5 1000 ## x^0.5 24.8 26.4 36.2490 27.6 43.70 84.3 1000 ## x^(1/2) 25.1 26.7 36.5848 27.4 44.50 130.2 1000 ## exp(log(x)/2) 59.8 62.5 77.0483 66.2 85.05 153.1 1000 And also completely different functions microbenchmark(sqrt(x), x^4-3*x) ## Unit: microseconds ## expr min lq mean median uq max neval ## sqrt(x) 3.5 5.85 8.261 8.80 10.50 16.1 100 ## x^4 - 3 * x 33.0 36.35 51.677 56.65 60.05 67.5 100 For ease of interpretation, if a microbenchmark takes - 1 millisecond, then 1,000 calls take a second - 1 microsecond, then 1,000,000 calls take a second - 1 nanosecond, then 1,000,000,000 calls take a second Or use unit=eps for evaluations per second microbenchmark(sqrt(x), x^0.5, x^(1/2), exp(log(x)/2), unit=&quot;eps&quot;) ## Unit: evaluations per second ## expr min lq mean median uq max ## sqrt(x) 32051.282 53342.817 76853.264 70679.321 81967.213 158730.159 ## x^0.5 10183.299 12911.561 15118.699 13860.021 16182.289 22026.432 ## x^(1/2) 10905.125 12690.355 14702.112 13377.932 15095.036 21834.061 ## exp(log(x)/2) 6218.905 6875.222 7454.179 7331.382 7593.054 9191.176 ## neval ## 100 ## 100 ## 100 ## 100 Evaluating every function takes time Evaluating () or {} takes time Even specifying useless arguments in functions takes time! f0 &lt;- function() NULL f1 &lt;- function(a=1) NULL f2 &lt;- function(a=1, b=2) NULL f3 &lt;- function(a=1, b=2, c=3) NULL f4 &lt;- function(a=1, b=2, c=3, d=4) NULL f5 &lt;- function(a=1, b=2, c=3, d=4, e=5) NULL microbenchmark(f0(), f1(), f2(), f3(), f4(), f5(), times=10000) ## Unit: nanoseconds ## expr min lq mean median uq max neval ## f0() 200 500 1086.85 900 1000 1886800 10000 ## f1() 200 600 1181.26 1000 1100 1805200 10000 ## f2() 200 600 1274.18 1100 1200 1924400 10000 ## f3() 200 700 1353.73 1200 1300 1898700 10000 ## f4() 300 800 1472.79 1300 1400 2222100 10000 ## f5() 300 800 1555.75 1400 1550 1994100 10000 Extracting one element of a data frame microbenchmark( &quot;[32, 11]&quot; = mtcars[32,11], &quot;$carb[32]&quot; = mtcars$carb[32], &quot;[[c(11, 32)]]&quot; = mtcars[[c(11,32)]], &quot;[[11]][32]&quot; = mtcars[[11]][32], &quot;.subset2&quot; = .subset2(mtcars,11)[32]) ## Unit: microseconds ## expr min lq mean median uq max neval ## [32, 11] 41.2 43.5 327.488 44.50 47.05 27502.6 100 ## $carb[32] 6.0 7.2 9.186 8.70 9.50 31.1 100 ## [[c(11, 32)]] 16.6 17.7 21.583 18.30 19.85 87.0 100 ## [[11]][32] 15.9 17.0 19.948 18.05 19.25 55.5 100 ## .subset2 1.1 1.4 1.793 1.60 1.70 11.2 100 4.10.1 Vectorizing The key idea behind vectorizing your code is to think about entire vectors instead of thinking about their components. Using apply and co instead of for loops is a start, but does not really solve this issue. Truly vectorized functions will make use of code written in C instead of R. Loops in C are much faster because they have much less overhead. Addition on each element of a data frame rm(list=ls()) m=5 n=5 matrix1 &lt;- replicate(m, rnorm(n)) # create matrix matdf &lt;- matdf1 &lt;- data.frame(matrix1) matdf ## X1 X2 X3 X4 X5 ## 1 0.77902668 -0.1341114 -0.7276765 0.9521921 -2.6624090 ## 2 1.39900669 0.2512071 0.4089257 -0.4122272 -0.2407469 ## 3 0.07058374 0.6481974 -0.2049656 -0.3687698 -0.8678362 ## 4 -1.38502719 0.5369928 0.8257416 -0.2309489 0.0153521 ## 5 -0.64312325 -0.9258315 1.2894823 0.2343512 0.5468129 for (i in 1:m) { for (j in 1:n) { matdf1[i,j] &lt;- matdf1[i,j] + 1.87*cos(.25)*pi # addition } } matdf1 ## X1 X2 X3 X4 X5 ## 1 6.471172 5.558034 4.964469 6.644338 3.029737 ## 2 7.091152 5.943353 6.101071 5.279918 5.451399 ## 3 5.762729 6.340343 5.487180 5.323376 4.824309 ## 4 4.307118 6.229138 6.517887 5.461197 5.707498 ## 5 5.049022 4.766314 6.981628 5.926497 6.238959 matdf2&lt;-data.frame(matrix1) matdf2 &lt;- matdf2 + 1.87*cos(.25)*pi matdf2 ## X1 X2 X3 X4 X5 ## 1 6.471172 5.558034 4.964469 6.644338 3.029737 ## 2 7.091152 5.943353 6.101071 5.279918 5.451399 ## 3 5.762729 6.340343 5.487180 5.323376 4.824309 ## 4 4.307118 6.229138 6.517887 5.461197 5.707498 ## 5 5.049022 4.766314 6.981628 5.926497 6.238959 microbenchmark( &quot;loop&quot; = for (i in 1:m) { for (j in 1:n) { matdf[i,j] &lt;- matdf[i,j] + 1.87*cos(.25)*pi } }, &quot;vectorized&quot; = matdf &lt;- matdf + 1.87*cos(.25)*pi ) ## Unit: microseconds ## expr min lq mean median uq max neval ## loop 9533.8 19687.85 23851.486 23914.70 27764.3 48779.2 100 ## vectorized 481.3 1120.25 1437.073 1489.15 1628.7 3598.2 100 mat1 &lt;- matrix(abs(rnorm(2500))+pi, ncol=50) apply(mat1, 1, function(x) sum(x)) ## [1] 197.9621 194.8968 193.7300 196.5544 203.2666 200.1058 198.0696 193.0357 ## [9] 197.3568 190.7377 198.3769 198.3812 202.3417 195.7892 197.0623 199.2278 ## [17] 193.4941 197.2995 193.5900 198.0771 198.9786 194.6102 192.2619 199.7032 ## [25] 202.9484 194.7972 192.3170 193.4939 194.7921 203.1653 201.5228 195.0751 ## [33] 206.5902 191.8956 197.0218 193.7380 196.6974 193.6625 190.9351 202.5694 ## [41] 197.0443 204.6114 202.1752 197.3526 198.6625 198.3229 200.6450 193.8912 ## [49] 198.6583 197.4261 rowSums(mat1) ## [1] 197.9621 194.8968 193.7300 196.5544 203.2666 200.1058 198.0696 193.0357 ## [9] 197.3568 190.7377 198.3769 198.3812 202.3417 195.7892 197.0623 199.2278 ## [17] 193.4941 197.2995 193.5900 198.0771 198.9786 194.6102 192.2619 199.7032 ## [25] 202.9484 194.7972 192.3170 193.4939 194.7921 203.1653 201.5228 195.0751 ## [33] 206.5902 191.8956 197.0218 193.7380 196.6974 193.6625 190.9351 202.5694 ## [41] 197.0443 204.6114 202.1752 197.3526 198.6625 198.3229 200.6450 193.8912 ## [49] 198.6583 197.4261 microbenchmark(apply(mat1, 1, function(x) sum(x)), rowSums(mat1)) ## Unit: microseconds ## expr min lq mean median uq max ## apply(mat1, 1, function(x) sum(x)) 211.2 308.70 462.859 435.3 537.85 4460.7 ## rowSums(mat1) 18.6 34.05 44.089 42.8 50.20 101.5 ## neval ## 100 ## 100 Even for basic tasks, think about the actual calculations you perform mat2 &lt;- matrix(sample(1:7, 90000, replace=T), ncol=300) mat3 &lt;- matrix(sample(2:6, 90000, replace=T), ncol=300) ys &lt;- sample(3:5, 300, replace=T) all.equal(mat2 %*% mat3 %*% ys , mat2 %*% (mat3 %*% ys)) ## [1] TRUE microbenchmark(mat2 %*% mat3 %*% ys, mat2 %*% (mat3 %*% ys)) ## Unit: microseconds ## expr min lq mean median uq max ## mat2 %*% mat3 %*% ys 13513.3 29867.75 34498.258 35569.00 40172.15 52713.4 ## mat2 %*% (mat3 %*% ys) 548.4 1259.05 2285.515 1604.65 2138.95 16385.1 ## neval ## 100 ## 100 Why? Think through the dimensionality 4.10.2 Paste/collapse and copies random_states &lt;- function() { paste(sample(state.name,10,replace =TRUE),collapse =&quot;&quot;) } states10 &lt;- replicate(10, random_states()) states10 ## [1] &quot;VermontArizonaNew JerseyMinnesotaIowaFloridaWyomingOregonColoradoWashington&quot; ## [2] &quot;New YorkKansasSouth DakotaMainePennsylvaniaHawaiiSouth CarolinaNevadaCaliforniaTennessee&quot; ## [3] &quot;South CarolinaKentuckyKentuckyNebraskaNew MexicoTexasWyomingConnecticutSouth DakotaTennessee&quot; ## [4] &quot;ColoradoNew YorkGeorgiaNew HampshireLouisianaHawaiiDelawareNebraskaOregonPennsylvania&quot; ## [5] &quot;IndianaIdahoKansasSouth DakotaLouisianaWest VirginiaCaliforniaMontanaMontanaMaryland&quot; ## [6] &quot;North DakotaFloridaDelawareOhioAlabamaGeorgiaAlabamaLouisianaHawaiiIdaho&quot; ## [7] &quot;IowaWashingtonSouth CarolinaMarylandArizonaNebraskaMississippiArizonaPennsylvaniaVirginia&quot; ## [8] &quot;AlabamaMississippiUtahKansasNevadaMinnesotaPennsylvaniaMissouriIowaMinnesota&quot; ## [9] &quot;North DakotaLouisianaWyomingMissouriColoradoIllinoisVirginiaUtahTexasNew Hampshire&quot; ## [10] &quot;OklahomaWest VirginiaNorth CarolinaSouth CarolinaMarylandSouth CarolinaSouth DakotaVirginiaLouisianaCalifornia&quot; states100 &lt;- replicate(100, random_states()) collapse &lt;- function(states) { out &lt;- &quot;&quot; for (x in states) { out &lt;- paste0(out, x) # same as paste(..., sep=&quot;&quot;, collapse) } out } microbenchmark( &quot;loop10&quot; = collapse(states10), &quot;vec10&quot; = paste(states10, collapse =&quot;&quot;), &quot;loop100&quot; = collapse(states100), &quot;vec100&quot; = paste(states100, collapse =&quot;&quot;) ) ## Unit: microseconds ## expr min lq mean median uq max neval ## loop10 36.6 67.75 152.274 73.85 82.00 7597.0 100 ## vec10 11.9 19.30 24.455 21.85 27.90 53.6 100 ## loop100 1810.6 2584.10 2902.320 2720.20 3111.90 4632.1 100 ## vec100 89.3 150.40 167.794 161.60 183.85 293.7 100 PRO TIP: Allocate memory and fill, don’t append to the end Here, we are not only getting around using the loop, but also avoiding copies. Whenever you append(), cbind(), rbind(), or paste() to create a bigger object, R must first allocate space for the new object and then copy the old object to its new home. If you’re repeating this many times, like in a for loop, this can be quite computationally expensive. Instead, allocate an object of the largest size you think you’ll need, and fill it up as you go. Fun fact: in Java (another programming language), arrays function the same way as vectors in R. Java has a data structure called an ArrayList, which allows users to add and remove as needed. When it gets full, it doubles the size/capacity of the underlying array and copies everything over. When an element is removed, it doesn’t decrease the size of the underlying array because copying things over and allocating new space is very inefficient. "],
["version-control.html", "5 Version Control 5.1 Why version control? 5.2 Setup 5.3 Workflow 5.4 Branches 5.5 Forking 5.6 Reverting 5.7 Conflict management 5.8 Version Control in RStudio", " 5 Version Control 5.1 Why version control? Have you ever … (Source: Stack overflow) - Made a change to code, realised it was a mistake and wanted to revert back? - Lost code or had a backup that was too old? - Had to maintain multiple versions of a product? - Wanted to see the difference between two (or more) versions of your code? - Wanted to prove that a particular change broke or fixed a piece of code? - Wanted to review the history of some code? - Wanted to submit a change to someone else’s code? - Wanted to share your code, or let other people work on your code? - Wanted to see how much work is being done, and where, when and by whom? - Wanted to experiment with a new feature without interfering with working code? 5.2 Setup Install Git: http://git-scm.com/book/en/Getting-Started-Installing-Git Sign up for GitHub Install the GUI http://mac.github.com/ http://windows.github.com/ 5.3 Workflow Every time you work on a group project that is stored in git, you should pull right away, do your work, then commit and push immediately. I recommend doing this workflow every time you make a significant change or start working on something else. It backs up your work so that you can go back to an earlier version in case you mess something up later. 5.3.1 Pull This updates your repository to the newest version so that when other people on your team make changes, you will be able to have the most recently updated version of the code/repository. In the picture above, to pull, click on “Fetch origin”. 5.3.2 Commit This is step 1 of adding your changes to GitHub (push is step 2). Committing your changes requires that you specify which changed files you want to commit as well as a brief commit message summarizing what you changed since the last commit. In the picture above, to commit, click on “Commit to master” once you’ve selected the files to commit in the left pane. 5.3.3 Push This is step 2 of adding your changes to GitHub. You can think of committimg as wrapping up a gift that you made and pushing is mailing it to the recipient. They don’t “open” the gift until they Pull and see what you pushed. Pushing uploads all un-pushed commits to GitHub so that you can see them in GitHub desktop as well as your repository online. In the picture above, after you’ve committed, to push, click on “Push origin”. 5.4 Branches Large software projects use branches to have a production environment that is always working, and other branches for new feature development. Once a feature is ready, the development branch can be merged with the production branch (typically master). You’ll have to manually choose which version of each file to keep. In the picture above, to switch branches, click on the “Current branch” button and either create a new branch or select an existing one. 5.5 Forking If you see someone’s repository and want to copy it and make your own changes without affecting their repository (and potentially without them even knowing), you can “fork” the repository. This gives you your own copy of it to mess with as you please. 5.6 Reverting If you make a mistake and commit and push it (or your team member does), you can revert to a prior commit. This is why it’s super useful to commit and push regularly!!! You can revert from any commit which will set your current repository state back to exactly what it looked like at that exact moment in time. 5.7 Conflict management To create a conflict, you’ll need two people with access to the same repository (or two computers that both have the repo cloned). - Both people/computers sync back up - Person/computer 1 should add a new file - Person/computer 1 should commit and push their new file - Person/computer 2 should pull and see the new file - Person/computer 1 should type something in this file like “hello world” - Person/computer 1 should commit and push - Person/computer 2 should type something in this file like “helol world” - When person/computer 2 commits and pushes, it will cause a conflict that they will have to resolve Here’s a gif of how merge conflicts work in GitHub desktop 5.8 Version Control in RStudio If you have a GitHub repository that you want to open in RStudio, here are the steps: Open RStudio File -&gt; New Project -&gt; Version Control -&gt; Git Paste your repository URL and change where you want it to clone the repository on your local machine All of the files in the repository are now found in the “files” tab in RStudio. To pull, open the “git” tab and click the blue down arrow. To commit, select the check boxes next to the changed files you wish to commit and click the “commit” button. To push, click the green up arrow. Note: if you want to switch branches, you can click on “master” in the git tab. To switch projects, click on the cube icon in the top right corner. This gives you options for creating a new project, viewing recent projects, and opening existing projects. For more info, check out this link or this video: "],
["data-visualization-in-r.html", "6 Data Visualization in R 6.1 Intro to ggplot2 6.2 More geom options", " 6 Data Visualization in R 6.1 Intro to ggplot2 ggplot2 is a powerful way to build both simple and complex data visualizations Takes care of a lot of the stupid aspects of plot building Provides a language for layering visual elements Has been extended in dozens of ways to handle all kinds of data Integrates easily into the rest of the tidyverse 6.1.1 Example Data comes from 538.com library(ggplot2) primaryPolls&lt;-read.csv(&#39;https://jmontgomery.github.io/PDS/Datasets/president_primary_polls_feb2020.csv&#39;, stringsAsFactors = F) primaryPolls$start_date&lt;-as.Date(primaryPolls$start_date, &quot;%m/%d/%Y&quot;) primaryPolls&lt;-primaryPolls[primaryPolls$state==&quot;New Hampshire&quot;,] primaryPolls&lt;-primaryPolls[primaryPolls$candidate_name%in%c(&quot;Amy Klobuchar&quot;, &quot;Bernard Sanders&quot;, &quot;Elizabeth Warren&quot;, &quot;Joseph R. Biden Jr.&quot;, &quot;Michael Bloomberg&quot;, &quot;Pete Buttigieg&quot;),] ggplot(data=primaryPolls)+ geom_point(mapping = aes(x=start_date, y=pct)) The first line is always ggplot, which sets up the basic object that we will layer onto Then we use the + to add layers. In this case geom_points. THe + must be at the end of each line - not the beginning. Any geom layer requires a mapping argument, which itself comes with an aes argument explaining what goes on the x and y coordinates. Conveniently, the dataset only needs to be specified once. 6.1.2 Aesthetics The aes stands for aesthetics. The nice part is we can easily make this more comlex And ggplot has pretty good defaults to handle things like color choices, legends, etc. ggplot(data=primaryPolls)+ geom_point(mapping = aes(x=start_date, y=pct, color= candidate_name)) Note that ggplot automatically chose a unique color. It can do the same with shapes, point size, and transparency (alpha). alpha = 1 is completely opaque, alpha = 0.2 would be almost entirely see-through You can also set aesthetic characteristics manually (as I do with alpha here) Note that shapes only works by default with 6 categories ggplot(data=primaryPolls)+ geom_point(mapping = aes(x=start_date, y=pct, shape= candidate_name, color=candidate_name), alpha=.8) 6.1.3 Facets Perhaps most helpfully we can parse the data by features using a simple line ggplot will then arrange everything else so it looks pretty OK ggplot(data=primaryPolls)+ geom_point(mapping = aes(x=start_date, y=pct)) + facet_wrap(~ candidate_name, nrow=4) You can also make a grid of plots, one dimension has each population level and the other has the candidate names ggplot(data=primaryPolls)+ geom_point(mapping = aes(x=start_date, y=pct)) + facet_wrap(population ~ candidate_name, nrow=2) 6.2 More geom options ggplot(data=primaryPolls)+ geom_smooth(mapping = aes(x=start_date, y=pct, color=candidate_name)) + facet_wrap(~ candidate_name, nrow=2) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; ggplot(data=primaryPolls)+ geom_smooth(mapping = aes(x=start_date, y=pct, color=candidate_name)) + geom_point(mapping = aes(x=start_date, y=pct, color=candidate_name), alpha=.4) + facet_wrap(~ candidate_name, nrow=2) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; ggplot(data=primaryPolls)+ geom_smooth(mapping = aes(x=start_date, y=pct, color=candidate_name, linetype=candidate_name)) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; ANd maybe we don’t want a legend? ggplot(data=primaryPolls)+ geom_smooth(mapping = aes(x=start_date, y=pct, group=candidate_name)) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; ggplot(data=primaryPolls)+ geom_smooth(mapping = aes(x=start_date, y=pct, color=candidate_name), show.legend=FALSE) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; We can combine multiple geom objects ggplot(data=primaryPolls)+ geom_smooth(mapping = aes(x=start_date, y=pct, color=candidate_name))+ geom_point(mapping = aes(x=start_date, y=pct, color=candidate_name), alpha=.4) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; But we can also do this in a way easier to change (less copying and pasting) ggplot(data=primaryPolls, mapping=aes(x=start_date, y=pct, color=candidate_name))+ geom_smooth()+ geom_point(alpha=.4) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; And you can add specifics elments to a sub-layer ggplot(data=primaryPolls, mapping=aes(x=start_date, y=pct, color=candidate_name))+ geom_smooth()+ geom_point(aes(size=sample_size), alpha=.4) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; A lot of other options you are interested require knowing the right geom function ggplot(data=primaryPolls, mapping=aes(x=fte_grade))+ geom_bar() This is also the same as counting the number of obserervations in each bin ggplot(data=primaryPolls, mapping=aes(x=fte_grade))+ stat_count() This is also the same as counting the number of obserervations in each bin ggplot(data=primaryPolls, mapping=aes(x=candidate_name, y=pct))+ stat_summary( fun.ymin=min, fun.ymax=max, fun.y=median ) You can also flip the coordinate system fairly quickly ggplot(data=primaryPolls, mapping=aes(x=candidate_name, y=pct))+ geom_boxplot() ggplot(data=primaryPolls, mapping=aes(x=candidate_name, y=pct))+ geom_boxplot() + coord_flip() "],
["dplyr-and-tidy.html", "7 dplyr and tidy 7.1 Into the tidyverse 7.2 Back to dplyr 7.3 Relational data 7.4 stringr 7.5 Pipes and maps 7.6 map 7.7 walk, purrr, and more", " 7 dplyr and tidy 7.1 Into the tidyverse dplyr is a handy package for changing data tidyr is a handy package for reshaping data In combination they offer a powerful way to quickly extract insight from your data 7.1.1 Our example Data comes from fivethirtyeight.com library(dplyr) library(tidyr) library(readr) primaryPolls&lt;-read_csv(&#39;https://jmontgomery.github.io/PDS/Datasets/president_primary_polls_feb2020.csv&#39;) primaryPolls$start_date&lt;-as.Date(primaryPolls$start_date, &quot;%m/%d/%y&quot;) class(primaryPolls) ## [1] &quot;spec_tbl_df&quot; &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; A tibble is basically a data frame They are both friendlier and more structured than traditional data frames primaryPolls ## # A tibble: 16,661 x 33 ## question_id poll_id cycle state pollster_id pollster sponsor_ids sponsors ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 116805 63512 2020 New ~ 1515 Data fo~ NA &lt;NA&gt; ## 2 116805 63512 2020 New ~ 1515 Data fo~ NA &lt;NA&gt; ## 3 116805 63512 2020 New ~ 1515 Data fo~ NA &lt;NA&gt; ## 4 116805 63512 2020 New ~ 1515 Data fo~ NA &lt;NA&gt; ## 5 116805 63512 2020 New ~ 1515 Data fo~ NA &lt;NA&gt; ## 6 116805 63512 2020 New ~ 1515 Data fo~ NA &lt;NA&gt; ## 7 116805 63512 2020 New ~ 1515 Data fo~ NA &lt;NA&gt; ## 8 116805 63512 2020 New ~ 1515 Data fo~ NA &lt;NA&gt; ## 9 116799 63511 2020 &lt;NA&gt; 744 Ipsos 71 Reuters ## 10 116799 63511 2020 &lt;NA&gt; 744 Ipsos 71 Reuters ## # ... with 16,651 more rows, and 25 more variables: display_name &lt;chr&gt;, ## # pollster_rating_id &lt;dbl&gt;, pollster_rating_name &lt;chr&gt;, fte_grade &lt;chr&gt;, ## # sample_size &lt;dbl&gt;, population &lt;chr&gt;, population_full &lt;chr&gt;, ## # methodology &lt;chr&gt;, office_type &lt;chr&gt;, start_date &lt;date&gt;, end_date &lt;chr&gt;, ## # sponsor_candidate &lt;lgl&gt;, internal &lt;lgl&gt;, partisan &lt;lgl&gt;, tracking &lt;lgl&gt;, ## # nationwide_batch &lt;lgl&gt;, created_at &lt;chr&gt;, notes &lt;chr&gt;, url &lt;chr&gt;, ## # stage &lt;chr&gt;, party &lt;chr&gt;, answer &lt;chr&gt;, candidate_id &lt;dbl&gt;, ## # candidate_name &lt;chr&gt;, pct &lt;dbl&gt; You can also print the first 10 rows of all the columns print(primaryPolls, width=Inf) ## # A tibble: 16,661 x 33 ## question_id poll_id cycle state pollster_id pollster ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 116805 63512 2020 New Hampshire 1515 Data for Progress ## 2 116805 63512 2020 New Hampshire 1515 Data for Progress ## 3 116805 63512 2020 New Hampshire 1515 Data for Progress ## 4 116805 63512 2020 New Hampshire 1515 Data for Progress ## 5 116805 63512 2020 New Hampshire 1515 Data for Progress ## 6 116805 63512 2020 New Hampshire 1515 Data for Progress ## 7 116805 63512 2020 New Hampshire 1515 Data for Progress ## 8 116805 63512 2020 New Hampshire 1515 Data for Progress ## 9 116799 63511 2020 &lt;NA&gt; 744 Ipsos ## 10 116799 63511 2020 &lt;NA&gt; 744 Ipsos ## sponsor_ids sponsors display_name pollster_rating_id ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 NA &lt;NA&gt; Data for Progress 522 ## 2 NA &lt;NA&gt; Data for Progress 522 ## 3 NA &lt;NA&gt; Data for Progress 522 ## 4 NA &lt;NA&gt; Data for Progress 522 ## 5 NA &lt;NA&gt; Data for Progress 522 ## 6 NA &lt;NA&gt; Data for Progress 522 ## 7 NA &lt;NA&gt; Data for Progress 522 ## 8 NA &lt;NA&gt; Data for Progress 522 ## 9 71 Reuters Ipsos 154 ## 10 71 Reuters Ipsos 154 ## pollster_rating_name fte_grade sample_size population population_full ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Data for Progress B/C 1295 lv lv-d ## 2 Data for Progress B/C 1295 lv lv-d ## 3 Data for Progress B/C 1295 lv lv-d ## 4 Data for Progress B/C 1295 lv lv-d ## 5 Data for Progress B/C 1295 lv lv-d ## 6 Data for Progress B/C 1295 lv lv-d ## 7 Data for Progress B/C 1295 lv lv-d ## 8 Data for Progress B/C 1295 lv lv-d ## 9 Ipsos B- 556 rv rv-d ## 10 Ipsos B- 556 rv rv-d ## methodology office_type start_date end_date sponsor_candidate internal ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;lgl&gt; &lt;lgl&gt; ## 1 Text U.S. President 2020-02-07 2/10/20 NA FALSE ## 2 Text U.S. President 2020-02-07 2/10/20 NA FALSE ## 3 Text U.S. President 2020-02-07 2/10/20 NA FALSE ## 4 Text U.S. President 2020-02-07 2/10/20 NA FALSE ## 5 Text U.S. President 2020-02-07 2/10/20 NA FALSE ## 6 Text U.S. President 2020-02-07 2/10/20 NA FALSE ## 7 Text U.S. President 2020-02-07 2/10/20 NA FALSE ## 8 Text U.S. President 2020-02-07 2/10/20 NA FALSE ## 9 Online U.S. President 2020-02-06 2/10/20 NA FALSE ## 10 Online U.S. President 2020-02-06 2/10/20 NA FALSE ## partisan tracking nationwide_batch created_at notes ## &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 NA FALSE FALSE 2/10/20 21:47 &lt;NA&gt; ## 2 NA FALSE FALSE 2/10/20 21:47 &lt;NA&gt; ## 3 NA FALSE FALSE 2/10/20 21:47 &lt;NA&gt; ## 4 NA FALSE FALSE 2/10/20 21:47 &lt;NA&gt; ## 5 NA FALSE FALSE 2/10/20 21:47 &lt;NA&gt; ## 6 NA FALSE FALSE 2/10/20 21:47 &lt;NA&gt; ## 7 NA FALSE FALSE 2/10/20 21:47 &lt;NA&gt; ## 8 NA FALSE FALSE 2/10/20 21:47 &lt;NA&gt; ## 9 NA FALSE FALSE 2/10/20 18:27 &lt;NA&gt; ## 10 NA FALSE FALSE 2/10/20 18:27 &lt;NA&gt; ## url ## &lt;chr&gt; ## 1 http://filesforprogress.org/datasets/2020/2/nh/new_hampshire_primary.pdf ## 2 http://filesforprogress.org/datasets/2020/2/nh/new_hampshire_primary.pdf ## 3 http://filesforprogress.org/datasets/2020/2/nh/new_hampshire_primary.pdf ## 4 http://filesforprogress.org/datasets/2020/2/nh/new_hampshire_primary.pdf ## 5 http://filesforprogress.org/datasets/2020/2/nh/new_hampshire_primary.pdf ## 6 http://filesforprogress.org/datasets/2020/2/nh/new_hampshire_primary.pdf ## 7 http://filesforprogress.org/datasets/2020/2/nh/new_hampshire_primary.pdf ## 8 http://filesforprogress.org/datasets/2020/2/nh/new_hampshire_primary.pdf ## 9 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-02/topline_~ ## 10 https://www.ipsos.com/sites/default/files/ct/news/documents/2020-02/topline_~ ## stage party answer candidate_id candidate_name pct ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 primary DEM Sanders 13257 Bernard Sanders 28 ## 2 primary DEM Yang 13329 Andrew Yang 5 ## 3 primary DEM Buttigieg 13345 Pete Buttigieg 26 ## 4 primary DEM Biden 13256 Joseph R. Biden Jr. 9 ## 5 primary DEM Gabbard 13343 Tulsi Gabbard 3 ## 6 primary DEM Klobuchar 13310 Amy Klobuchar 13 ## 7 primary DEM Warren 13258 Elizabeth Warren 14 ## 8 primary DEM Steyer 13327 Tom Steyer 3 ## 9 primary DEM Sanders 13257 Bernard Sanders 20 ## 10 primary DEM Biden 13256 Joseph R. Biden Jr. 17 ## # ... with 16,651 more rows You can access elements basically the same way They never allow partial matching (which is evil anyways) Partial matching allows you to type the first few characters of a column name and it will figure out which one you meant You can use as.tibble or as.data.frame to jump back and forth 7.2 Back to dplyr Subset data by rows: filter Reorder by rows: arrange Subset data by column: select Create new variables as a function of other variables: mutate Collapse values down (or extract statistic): summarise We can use group_by to make changes in the scope 7.2.1 filter filter allows you to easily subset data using conditions as we have done before using accessors filter(primaryPolls, candidate_name == c(&quot;Amy Klobuchar&quot;)) ## # A tibble: 874 x 33 ## question_id poll_id cycle state pollster_id pollster sponsor_ids sponsors ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 116805 63512 2020 New ~ 1515 Data fo~ NA &lt;NA&gt; ## 2 116799 63511 2020 &lt;NA&gt; 744 Ipsos 71 Reuters ## 3 116732 63489 2020 New ~ 1102 Emerson~ 43 7News ## 4 116733 63490 2020 New ~ 458 Suffolk~ 68323 Boston ~ ## 5 116743 63493 2020 New ~ 23 America~ NA &lt;NA&gt; ## 6 116798 63510 2020 New ~ 1529 Elucd NA &lt;NA&gt; ## 7 116745 63494 2020 New ~ 1470 Univers~ 143 CNN ## 8 116792 63508 2020 Cali~ 1491 Capitol~ NA &lt;NA&gt; ## 9 116763 63496 2020 &lt;NA&gt; 396 Quinnip~ NA &lt;NA&gt; ## 10 116714 63483 2020 New ~ 1102 Emerson~ 43 7News ## # ... with 864 more rows, and 25 more variables: display_name &lt;chr&gt;, ## # pollster_rating_id &lt;dbl&gt;, pollster_rating_name &lt;chr&gt;, fte_grade &lt;chr&gt;, ## # sample_size &lt;dbl&gt;, population &lt;chr&gt;, population_full &lt;chr&gt;, ## # methodology &lt;chr&gt;, office_type &lt;chr&gt;, start_date &lt;date&gt;, end_date &lt;chr&gt;, ## # sponsor_candidate &lt;lgl&gt;, internal &lt;lgl&gt;, partisan &lt;lgl&gt;, tracking &lt;lgl&gt;, ## # nationwide_batch &lt;lgl&gt;, created_at &lt;chr&gt;, notes &lt;chr&gt;, url &lt;chr&gt;, ## # stage &lt;chr&gt;, party &lt;chr&gt;, answer &lt;chr&gt;, candidate_id &lt;dbl&gt;, ## # candidate_name &lt;chr&gt;, pct &lt;dbl&gt; Or you can include multiple conditions filter(primaryPolls, candidate_name == c(&quot;Amy Klobuchar&quot;), state==&quot;New Hampshire&quot;) ## # A tibble: 84 x 33 ## question_id poll_id cycle state pollster_id pollster sponsor_ids sponsors ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 116805 63512 2020 New ~ 1515 Data fo~ NA &lt;NA&gt; ## 2 116732 63489 2020 New ~ 1102 Emerson~ 43 7News ## 3 116733 63490 2020 New ~ 458 Suffolk~ 68323 Boston ~ ## 4 116743 63493 2020 New ~ 23 America~ NA &lt;NA&gt; ## 5 116798 63510 2020 New ~ 1529 Elucd NA &lt;NA&gt; ## 6 116745 63494 2020 New ~ 1470 Univers~ 143 CNN ## 7 116714 63483 2020 New ~ 1102 Emerson~ 43 7News ## 8 116715 63484 2020 New ~ 458 Suffolk~ 68323 Boston ~ ## 9 116717 63485 2020 New ~ 1470 Univers~ 143 CNN ## 10 116718 63486 2020 New ~ 568 YouGov 133 CBS News ## # ... with 74 more rows, and 25 more variables: display_name &lt;chr&gt;, ## # pollster_rating_id &lt;dbl&gt;, pollster_rating_name &lt;chr&gt;, fte_grade &lt;chr&gt;, ## # sample_size &lt;dbl&gt;, population &lt;chr&gt;, population_full &lt;chr&gt;, ## # methodology &lt;chr&gt;, office_type &lt;chr&gt;, start_date &lt;date&gt;, end_date &lt;chr&gt;, ## # sponsor_candidate &lt;lgl&gt;, internal &lt;lgl&gt;, partisan &lt;lgl&gt;, tracking &lt;lgl&gt;, ## # nationwide_batch &lt;lgl&gt;, created_at &lt;chr&gt;, notes &lt;chr&gt;, url &lt;chr&gt;, ## # stage &lt;chr&gt;, party &lt;chr&gt;, answer &lt;chr&gt;, candidate_id &lt;dbl&gt;, ## # candidate_name &lt;chr&gt;, pct &lt;dbl&gt; Everything you have already learned about boolean operators applies here. 7.2.2 arrange arrange does the same thing, but organizes data by rows insead of subsetting by rows. arrange(primaryPolls, state, pollster_id) ## # A tibble: 16,661 x 33 ## question_id poll_id cycle state pollster_id pollster sponsor_ids sponsors ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 99478 58691 2020 Alab~ 1193 SurveyM~ 132 NBC News ## 2 99478 58691 2020 Alab~ 1193 SurveyM~ 132 NBC News ## 3 99478 58691 2020 Alab~ 1193 SurveyM~ 132 NBC News ## 4 99478 58691 2020 Alab~ 1193 SurveyM~ 132 NBC News ## 5 99478 58691 2020 Alab~ 1193 SurveyM~ 132 NBC News ## 6 99478 58691 2020 Alab~ 1193 SurveyM~ 132 NBC News ## 7 99478 58691 2020 Alab~ 1193 SurveyM~ 132 NBC News ## 8 99478 58691 2020 Alab~ 1193 SurveyM~ 132 NBC News ## 9 99478 58691 2020 Alab~ 1193 SurveyM~ 132 NBC News ## 10 99478 58691 2020 Alab~ 1193 SurveyM~ 132 NBC News ## # ... with 16,651 more rows, and 25 more variables: display_name &lt;chr&gt;, ## # pollster_rating_id &lt;dbl&gt;, pollster_rating_name &lt;chr&gt;, fte_grade &lt;chr&gt;, ## # sample_size &lt;dbl&gt;, population &lt;chr&gt;, population_full &lt;chr&gt;, ## # methodology &lt;chr&gt;, office_type &lt;chr&gt;, start_date &lt;date&gt;, end_date &lt;chr&gt;, ## # sponsor_candidate &lt;lgl&gt;, internal &lt;lgl&gt;, partisan &lt;lgl&gt;, tracking &lt;lgl&gt;, ## # nationwide_batch &lt;lgl&gt;, created_at &lt;chr&gt;, notes &lt;chr&gt;, url &lt;chr&gt;, ## # stage &lt;chr&gt;, party &lt;chr&gt;, answer &lt;chr&gt;, candidate_id &lt;dbl&gt;, ## # candidate_name &lt;chr&gt;, pct &lt;dbl&gt; Or in descending order arrange(primaryPolls, state, desc(pollster_id)) ## # A tibble: 16,661 x 33 ## question_id poll_id cycle state pollster_id pollster sponsor_ids sponsors ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 93812 57768 2020 Alab~ 1365 Change ~ NA &lt;NA&gt; ## 2 93812 57768 2020 Alab~ 1365 Change ~ NA &lt;NA&gt; ## 3 93812 57768 2020 Alab~ 1365 Change ~ NA &lt;NA&gt; ## 4 93812 57768 2020 Alab~ 1365 Change ~ NA &lt;NA&gt; ## 5 93812 57768 2020 Alab~ 1365 Change ~ NA &lt;NA&gt; ## 6 93812 57768 2020 Alab~ 1365 Change ~ NA &lt;NA&gt; ## 7 93812 57768 2020 Alab~ 1365 Change ~ NA &lt;NA&gt; ## 8 93812 57768 2020 Alab~ 1365 Change ~ NA &lt;NA&gt; ## 9 93812 57768 2020 Alab~ 1365 Change ~ NA &lt;NA&gt; ## 10 93812 57768 2020 Alab~ 1365 Change ~ NA &lt;NA&gt; ## # ... with 16,651 more rows, and 25 more variables: display_name &lt;chr&gt;, ## # pollster_rating_id &lt;dbl&gt;, pollster_rating_name &lt;chr&gt;, fte_grade &lt;chr&gt;, ## # sample_size &lt;dbl&gt;, population &lt;chr&gt;, population_full &lt;chr&gt;, ## # methodology &lt;chr&gt;, office_type &lt;chr&gt;, start_date &lt;date&gt;, end_date &lt;chr&gt;, ## # sponsor_candidate &lt;lgl&gt;, internal &lt;lgl&gt;, partisan &lt;lgl&gt;, tracking &lt;lgl&gt;, ## # nationwide_batch &lt;lgl&gt;, created_at &lt;chr&gt;, notes &lt;chr&gt;, url &lt;chr&gt;, ## # stage &lt;chr&gt;, party &lt;chr&gt;, answer &lt;chr&gt;, candidate_id &lt;dbl&gt;, ## # candidate_name &lt;chr&gt;, pct &lt;dbl&gt; 7.2.3 select Select is just a much easier way to subset by column select(primaryPolls, state, candidate_name, start_date) ## # A tibble: 16,661 x 3 ## state candidate_name start_date ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; ## 1 New Hampshire Bernard Sanders 2020-02-07 ## 2 New Hampshire Andrew Yang 2020-02-07 ## 3 New Hampshire Pete Buttigieg 2020-02-07 ## 4 New Hampshire Joseph R. Biden Jr. 2020-02-07 ## 5 New Hampshire Tulsi Gabbard 2020-02-07 ## 6 New Hampshire Amy Klobuchar 2020-02-07 ## 7 New Hampshire Elizabeth Warren 2020-02-07 ## 8 New Hampshire Tom Steyer 2020-02-07 ## 9 &lt;NA&gt; Bernard Sanders 2020-02-06 ## 10 &lt;NA&gt; Joseph R. Biden Jr. 2020-02-06 ## # ... with 16,651 more rows It comes with a nice syntax for doing this without just listing var1:var20 will select all columns between these two -var1:var20 will select everything except that range starts_with(\"cand\") will select columns that start with “cand” Similar functionality for ends_with, contains, and matches A fun trick to move your favorite variables to the front, but keep it all: select(primaryPolls, state, candidate_name, start_date, everything()) ## # A tibble: 16,661 x 33 ## state candidate_name start_date question_id poll_id cycle pollster_id ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 New ~ Bernard Sande~ 2020-02-07 116805 63512 2020 1515 ## 2 New ~ Andrew Yang 2020-02-07 116805 63512 2020 1515 ## 3 New ~ Pete Buttigieg 2020-02-07 116805 63512 2020 1515 ## 4 New ~ Joseph R. Bid~ 2020-02-07 116805 63512 2020 1515 ## 5 New ~ Tulsi Gabbard 2020-02-07 116805 63512 2020 1515 ## 6 New ~ Amy Klobuchar 2020-02-07 116805 63512 2020 1515 ## 7 New ~ Elizabeth War~ 2020-02-07 116805 63512 2020 1515 ## 8 New ~ Tom Steyer 2020-02-07 116805 63512 2020 1515 ## 9 &lt;NA&gt; Bernard Sande~ 2020-02-06 116799 63511 2020 744 ## 10 &lt;NA&gt; Joseph R. Bid~ 2020-02-06 116799 63511 2020 744 ## # ... with 16,651 more rows, and 26 more variables: pollster &lt;chr&gt;, ## # sponsor_ids &lt;dbl&gt;, sponsors &lt;chr&gt;, display_name &lt;chr&gt;, ## # pollster_rating_id &lt;dbl&gt;, pollster_rating_name &lt;chr&gt;, fte_grade &lt;chr&gt;, ## # sample_size &lt;dbl&gt;, population &lt;chr&gt;, population_full &lt;chr&gt;, ## # methodology &lt;chr&gt;, office_type &lt;chr&gt;, end_date &lt;chr&gt;, ## # sponsor_candidate &lt;lgl&gt;, internal &lt;lgl&gt;, partisan &lt;lgl&gt;, tracking &lt;lgl&gt;, ## # nationwide_batch &lt;lgl&gt;, created_at &lt;chr&gt;, notes &lt;chr&gt;, url &lt;chr&gt;, ## # stage &lt;chr&gt;, party &lt;chr&gt;, answer &lt;chr&gt;, candidate_id &lt;dbl&gt;, pct &lt;dbl&gt; Note here that rename is the mythical easy way to rename a column, although syntax seems backwards You have to specify the new column name on the left side of the equal sign and the old column name on the right basicPolls&lt;-select(primaryPolls, state, candidate_name, start_date, pct) rename(basicPolls, candidate = candidate_name) ## # A tibble: 16,661 x 4 ## state candidate start_date pct ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; ## 1 New Hampshire Bernard Sanders 2020-02-07 28 ## 2 New Hampshire Andrew Yang 2020-02-07 5 ## 3 New Hampshire Pete Buttigieg 2020-02-07 26 ## 4 New Hampshire Joseph R. Biden Jr. 2020-02-07 9 ## 5 New Hampshire Tulsi Gabbard 2020-02-07 3 ## 6 New Hampshire Amy Klobuchar 2020-02-07 13 ## 7 New Hampshire Elizabeth Warren 2020-02-07 14 ## 8 New Hampshire Tom Steyer 2020-02-07 3 ## 9 &lt;NA&gt; Bernard Sanders 2020-02-06 20 ## 10 &lt;NA&gt; Joseph R. Biden Jr. 2020-02-06 17 ## # ... with 16,651 more rows 7.2.4 mutate mutate allows us to create a new variable that is a function of the others If you want to add the new column(s) to your existing tibble, you must use the assignment operator. Otherwise it will just print it out and throw the results away mutate(basicPolls, proportion=pct/100) ## # A tibble: 16,661 x 5 ## state candidate_name start_date pct proportion ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 New Hampshire Bernard Sanders 2020-02-07 28 0.28 ## 2 New Hampshire Andrew Yang 2020-02-07 5 0.05 ## 3 New Hampshire Pete Buttigieg 2020-02-07 26 0.26 ## 4 New Hampshire Joseph R. Biden Jr. 2020-02-07 9 0.09 ## 5 New Hampshire Tulsi Gabbard 2020-02-07 3 0.03 ## 6 New Hampshire Amy Klobuchar 2020-02-07 13 0.13 ## 7 New Hampshire Elizabeth Warren 2020-02-07 14 0.14 ## 8 New Hampshire Tom Steyer 2020-02-07 3 0.03 ## 9 &lt;NA&gt; Bernard Sanders 2020-02-06 20 0.2 ## 10 &lt;NA&gt; Joseph R. Biden Jr. 2020-02-06 17 0.17 ## # ... with 16,651 more rows basicPolls &lt;- mutate(basicPolls, proportion=pct/100) transmute creates and returns a new tibble with only the mutated variable(s) transmute(basicPolls, proportion=pct/100) ## # A tibble: 16,661 x 1 ## proportion ## &lt;dbl&gt; ## 1 0.28 ## 2 0.05 ## 3 0.26 ## 4 0.09 ## 5 0.03 ## 6 0.13 ## 7 0.14 ## 8 0.03 ## 9 0.2 ## 10 0.17 ## # ... with 16,651 more rows transmute(primaryPolls, numberRespondents=round((pct/100)*sample_size)) ## # A tibble: 16,661 x 1 ## numberRespondents ## &lt;dbl&gt; ## 1 363 ## 2 65 ## 3 337 ## 4 117 ## 5 39 ## 6 168 ## 7 181 ## 8 39 ## 9 111 ## 10 95 ## # ... with 16,651 more rows transmute(primaryPolls, proportion=pct/100, numberRespondents=round(proportion*sample_size), ) ## # A tibble: 16,661 x 2 ## proportion numberRespondents ## &lt;dbl&gt; &lt;dbl&gt; ## 1 0.28 363 ## 2 0.05 65 ## 3 0.26 337 ## 4 0.09 117 ## 5 0.03 39 ## 6 0.13 168 ## 7 0.14 181 ## 8 0.03 39 ## 9 0.2 111 ## 10 0.17 95 ## # ... with 16,651 more rows Note that you can use a ton of the basic functions we have already covered like sum, mean, sqrt, etc. A useful one is n(), which just counts the number of observations This includes logical comparisons mutate(basicPolls, top_tier=(pct&gt;10)*1) ## # A tibble: 16,661 x 6 ## state candidate_name start_date pct proportion top_tier ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 New Hampshire Bernard Sanders 2020-02-07 28 0.28 1 ## 2 New Hampshire Andrew Yang 2020-02-07 5 0.05 0 ## 3 New Hampshire Pete Buttigieg 2020-02-07 26 0.26 1 ## 4 New Hampshire Joseph R. Biden Jr. 2020-02-07 9 0.09 0 ## 5 New Hampshire Tulsi Gabbard 2020-02-07 3 0.03 0 ## 6 New Hampshire Amy Klobuchar 2020-02-07 13 0.13 1 ## 7 New Hampshire Elizabeth Warren 2020-02-07 14 0.14 1 ## 8 New Hampshire Tom Steyer 2020-02-07 3 0.03 0 ## 9 &lt;NA&gt; Bernard Sanders 2020-02-06 20 0.2 1 ## 10 &lt;NA&gt; Joseph R. Biden Jr. 2020-02-06 17 0.17 1 ## # ... with 16,651 more rows 7.2.5 summarise We can easily extract summary statistics summarise(basicPolls, average_candidate=mean(pct), count=n()) ## # A tibble: 1 x 2 ## average_candidate count ## &lt;dbl&gt; &lt;int&gt; ## 1 6.34 16661 This is more powerful when also using the group_by function basicPolls_grouped&lt;-group_by(basicPolls, candidate_name) summarise(basicPolls_grouped, average_candidate=mean(pct), count=n()) ## # A tibble: 76 x 3 ## candidate_name average_candidate count ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Amy Klobuchar 2.32 874 ## 2 Andrew Cuomo 0.433 12 ## 3 Andrew Yang 2.34 831 ## 4 Barack Obama 0 2 ## 5 Ben Sasse 0.711 36 ## 6 Bernard Sanders 18.3 960 ## 7 Beto O&#39;Rourke 3.76 653 ## 8 Bill de Blasio 0.534 318 ## 9 Bob Corker 0.611 36 ## 10 Charles D. Baker 31.5 2 ## # ... with 66 more rows basicPolls_grouped&lt;-group_by(basicPolls, candidate_name, state) summarise(basicPolls_grouped, average_candidate=mean(pct), count=n()) ## # A tibble: 1,024 x 4 ## # Groups: candidate_name [76] ## candidate_name state average_candidate count ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Amy Klobuchar Alabama 1 3 ## 2 Amy Klobuchar Arizona 1.18 6 ## 3 Amy Klobuchar California 1.74 40 ## 4 Amy Klobuchar Colorado 0.1 1 ## 5 Amy Klobuchar Delaware 1 1 ## 6 Amy Klobuchar Florida 1.98 13 ## 7 Amy Klobuchar Georgia 1.27 4 ## 8 Amy Klobuchar Illinois 2.15 2 ## 9 Amy Klobuchar Indiana 0 1 ## 10 Amy Klobuchar Iowa 5.97 61 ## # ... with 1,014 more rows 7.2.6 Piping The tidyverse includes a nice syntax for combining multiple commands so we don’t have to create new objects all of the time. The %?% syntax allows us to pass on the results of one line to another The result from the left side of the %&gt;% is passed as the first parameter of the next function basicPolls %&gt;% group_by(candidate_name, state) %&gt;% summarise(average_candidate=mean(pct), count=n()) ## # A tibble: 1,024 x 4 ## # Groups: candidate_name [76] ## candidate_name state average_candidate count ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Amy Klobuchar Alabama 1 3 ## 2 Amy Klobuchar Arizona 1.18 6 ## 3 Amy Klobuchar California 1.74 40 ## 4 Amy Klobuchar Colorado 0.1 1 ## 5 Amy Klobuchar Delaware 1 1 ## 6 Amy Klobuchar Florida 1.98 13 ## 7 Amy Klobuchar Georgia 1.27 4 ## 8 Amy Klobuchar Illinois 2.15 2 ## 9 Amy Klobuchar Indiana 0 1 ## 10 Amy Klobuchar Iowa 5.97 61 ## # ... with 1,014 more rows The above code is equivalent to the following: summarise(group_by(basicPolls, candidate_name, state), average_candidate=mean(pct), count=n()) ## # A tibble: 1,024 x 4 ## # Groups: candidate_name [76] ## candidate_name state average_candidate count ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Amy Klobuchar Alabama 1 3 ## 2 Amy Klobuchar Arizona 1.18 6 ## 3 Amy Klobuchar California 1.74 40 ## 4 Amy Klobuchar Colorado 0.1 1 ## 5 Amy Klobuchar Delaware 1 1 ## 6 Amy Klobuchar Florida 1.98 13 ## 7 Amy Klobuchar Georgia 1.27 4 ## 8 Amy Klobuchar Illinois 2.15 2 ## 9 Amy Klobuchar Indiana 0 1 ## 10 Amy Klobuchar Iowa 5.97 61 ## # ... with 1,014 more rows Which is equivalent to this: grouped_by &lt;- group_by(basicPolls, candidate_name, state) summarise(grouped_by, average_candidate=mean(pct), count=n()) ## # A tibble: 1,024 x 4 ## # Groups: candidate_name [76] ## candidate_name state average_candidate count ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Amy Klobuchar Alabama 1 3 ## 2 Amy Klobuchar Arizona 1.18 6 ## 3 Amy Klobuchar California 1.74 40 ## 4 Amy Klobuchar Colorado 0.1 1 ## 5 Amy Klobuchar Delaware 1 1 ## 6 Amy Klobuchar Florida 1.98 13 ## 7 Amy Klobuchar Georgia 1.27 4 ## 8 Amy Klobuchar Illinois 2.15 2 ## 9 Amy Klobuchar Indiana 0 1 ## 10 Amy Klobuchar Iowa 5.97 61 ## # ... with 1,014 more rows See assigned readings for more useful summary variables and ungroup basicPolls %&gt;% group_by(candidate_name, state) %&gt;% summarise(average_candidate=mean(pct), count=n()) %&gt;% filter(count&gt;10) ## # A tibble: 206 x 4 ## # Groups: candidate_name [44] ## candidate_name state average_candidate count ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Amy Klobuchar California 1.74 40 ## 2 Amy Klobuchar Florida 1.98 13 ## 3 Amy Klobuchar Iowa 5.97 61 ## 4 Amy Klobuchar Nevada 1.71 15 ## 5 Amy Klobuchar New Hampshire 5.42 84 ## 6 Amy Klobuchar Pennsylvania 1.53 11 ## 7 Amy Klobuchar South Carolina 1.27 34 ## 8 Amy Klobuchar Texas 1.47 23 ## 9 Amy Klobuchar Wisconsin 2.52 16 ## 10 Amy Klobuchar &lt;NA&gt; 1.62 503 ## # ... with 196 more rows primaryPolls %&gt;% group_by(candidate_name, state) %&gt;% summarise(average_candidate=mean(pct), count=n()) %&gt;% filter(count&gt;10) %&gt;% mutate(average_prop=average_candidate/100) %&gt;% select(average_prop, candidate_name, state, count) ## # A tibble: 206 x 4 ## # Groups: candidate_name [44] ## average_prop candidate_name state count ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 0.0174 Amy Klobuchar California 40 ## 2 0.0198 Amy Klobuchar Florida 13 ## 3 0.0597 Amy Klobuchar Iowa 61 ## 4 0.0171 Amy Klobuchar Nevada 15 ## 5 0.0542 Amy Klobuchar New Hampshire 84 ## 6 0.0153 Amy Klobuchar Pennsylvania 11 ## 7 0.0127 Amy Klobuchar South Carolina 34 ## 8 0.0147 Amy Klobuchar Texas 23 ## 9 0.0252 Amy Klobuchar Wisconsin 16 ## 10 0.0162 Amy Klobuchar &lt;NA&gt; 503 ## # ... with 196 more rows 7.2.7 Pivots In many cases the data is not quite organized the way we want. Right now we have each poll as a separate row. But what if we want each candidate to be a row so we can analyze their trends in polls over time? Or what if we get the trend line and want to instead reorganize to look at each poll separately? The key commands here are pivot_wider and pivot_longer See Chapter 12 for some additional (but less universally useful functions) In our running example we have one entry for each poll. How could we combine these to list the result from each unique poll togehter? The key here is that the values of interest are in the pct column and the groupings of interest are in the candidates column nevadaPrimaries&lt;-primaryPolls %&gt;% filter(candidate_name %in% c(&quot;Amy Klobuchar&quot;, &quot;Bernard Sanders&quot;, &quot;Elizabeth Warren&quot;, &quot;Joseph R. Biden Jr.&quot;, &quot;Michael Bloomberg&quot;, &quot;Pete Buttigieg&quot;)) %&gt;% filter(state==&quot;Nevada&quot;) %&gt;% select(candidate_name, pct, start_date, sample_size) print(nevadaPrimaries, n=Inf) ## # A tibble: 76 x 4 ## candidate_name pct start_date sample_size ## &lt;chr&gt; &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; ## 1 Joseph R. Biden Jr. 19.4 2020-01-08 500 ## 2 Bernard Sanders 17.6 2020-01-08 500 ## 3 Elizabeth Warren 10.6 2020-01-08 500 ## 4 Pete Buttigieg 8.2 2020-01-08 500 ## 5 Amy Klobuchar 3.6 2020-01-08 500 ## 6 Elizabeth Warren 14 2020-01-06 600 ## 7 Bernard Sanders 29 2020-01-06 600 ## 8 Joseph R. Biden Jr. 28 2020-01-06 600 ## 9 Pete Buttigieg 6 2020-01-06 600 ## 10 Amy Klobuchar 4 2020-01-06 600 ## 11 Joseph R. Biden Jr. 23 2020-01-05 635 ## 12 Bernard Sanders 17 2020-01-05 635 ## 13 Elizabeth Warren 12 2020-01-05 635 ## 14 Pete Buttigieg 6 2020-01-05 635 ## 15 Michael Bloomberg 2 2020-01-05 635 ## 16 Amy Klobuchar 2 2020-01-05 635 ## 17 Joseph R. Biden Jr. 24 2019-11-10 627 ## 18 Bernard Sanders 18 2019-11-10 627 ## 19 Elizabeth Warren 18 2019-11-10 627 ## 20 Pete Buttigieg 8 2019-11-10 627 ## 21 Amy Klobuchar 2 2019-11-10 627 ## 22 Joseph R. Biden Jr. 33 2019-11-06 626 ## 23 Bernard Sanders 23 2019-11-06 626 ## 24 Elizabeth Warren 21 2019-11-06 626 ## 25 Pete Buttigieg 9 2019-11-06 626 ## 26 Amy Klobuchar 2 2019-11-06 626 ## 27 Joseph R. Biden Jr. 29.9 2019-10-31 451 ## 28 Bernard Sanders 18.8 2019-10-31 451 ## 29 Elizabeth Warren 22.2 2019-10-31 451 ## 30 Pete Buttigieg 4.9 2019-10-31 451 ## 31 Amy Klobuchar 0.7 2019-10-31 451 ## 32 Joseph R. Biden Jr. 29.1 2019-10-28 600 ## 33 Pete Buttigieg 7.3 2019-10-28 600 ## 34 Amy Klobuchar 2.5 2019-10-28 600 ## 35 Bernard Sanders 19.1 2019-10-28 600 ## 36 Elizabeth Warren 19.2 2019-10-28 600 ## 37 Joseph R. Biden Jr. 22 2019-09-22 324 ## 38 Bernard Sanders 22 2019-09-22 324 ## 39 Elizabeth Warren 18 2019-09-22 324 ## 40 Pete Buttigieg 4 2019-09-22 324 ## 41 Amy Klobuchar 1 2019-09-22 324 ## 42 Joseph R. Biden Jr. 23.2 2019-09-19 500 ## 43 Pete Buttigieg 3.4 2019-09-19 500 ## 44 Amy Klobuchar 0.4 2019-09-19 500 ## 45 Bernard Sanders 14.2 2019-09-19 500 ## 46 Elizabeth Warren 19.4 2019-09-19 500 ## 47 Bernard Sanders 29 2019-08-28 563 ## 48 Joseph R. Biden Jr. 27 2019-08-28 563 ## 49 Elizabeth Warren 18 2019-08-28 563 ## 50 Pete Buttigieg 4 2019-08-28 563 ## 51 Amy Klobuchar 0 2019-08-28 563 ## 52 Joseph R. Biden Jr. 25 2019-08-14 382 ## 53 Elizabeth Warren 15 2019-08-14 382 ## 54 Bernard Sanders 10 2019-08-14 382 ## 55 Pete Buttigieg 5 2019-08-14 382 ## 56 Amy Klobuchar 2 2019-08-14 382 ## 57 Joseph R. Biden Jr. 26 2019-08-02 439 ## 58 Elizabeth Warren 23 2019-08-02 439 ## 59 Bernard Sanders 22 2019-08-02 439 ## 60 Pete Buttigieg 7 2019-08-02 439 ## 61 Amy Klobuchar 1 2019-08-02 439 ## 62 Joseph R. Biden Jr. 36 2019-06-06 370 ## 63 Elizabeth Warren 19 2019-06-06 370 ## 64 Bernard Sanders 13 2019-06-06 370 ## 65 Pete Buttigieg 7 2019-06-06 370 ## 66 Amy Klobuchar 1 2019-06-06 370 ## 67 Joseph R. Biden Jr. 29 2019-05-09 389 ## 68 Bernard Sanders 24 2019-05-09 389 ## 69 Pete Buttigieg 13 2019-05-09 389 ## 70 Elizabeth Warren 12 2019-05-09 389 ## 71 Amy Klobuchar 1 2019-05-09 389 ## 72 Elizabeth Warren 9.9 2019-03-28 310 ## 73 Pete Buttigieg 4.7 2019-03-28 310 ## 74 Joseph R. Biden Jr. 26.4 2019-03-28 310 ## 75 Bernard Sanders 22.5 2019-03-28 310 ## 76 Amy Klobuchar 2.4 2019-03-28 310 setting n=Inf in the print will ensure that all rows are shown (the equivalent for columns is width=Inf) nevadaPrimaries contains one row for every combination of a Nevada poll (specified by start_date and sample_size) and a candidate wideNevada&lt;-pivot_wider(nevadaPrimaries, names_from = candidate_name, values_from = pct) print(wideNevada, width=Inf) ## # A tibble: 15 x 8 ## start_date sample_size `Joseph R. Biden Jr.` `Bernard Sanders` ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2020-01-08 500 19.4 17.6 ## 2 2020-01-06 600 28 29 ## 3 2020-01-05 635 23 17 ## 4 2019-11-10 627 24 18 ## 5 2019-11-06 626 33 23 ## 6 2019-10-31 451 29.9 18.8 ## 7 2019-10-28 600 29.1 19.1 ## 8 2019-09-22 324 22 22 ## 9 2019-09-19 500 23.2 14.2 ## 10 2019-08-28 563 27 29 ## 11 2019-08-14 382 25 10 ## 12 2019-08-02 439 26 22 ## 13 2019-06-06 370 36 13 ## 14 2019-05-09 389 29 24 ## 15 2019-03-28 310 26.4 22.5 ## `Elizabeth Warren` `Pete Buttigieg` `Amy Klobuchar` `Michael Bloomberg` ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 10.6 8.2 3.6 NA ## 2 14 6 4 NA ## 3 12 6 2 2 ## 4 18 8 2 NA ## 5 21 9 2 NA ## 6 22.2 4.9 0.7 NA ## 7 19.2 7.3 2.5 NA ## 8 18 4 1 NA ## 9 19.4 3.4 0.4 NA ## 10 18 4 0 NA ## 11 15 5 2 NA ## 12 23 7 1 NA ## 13 19 7 1 NA ## 14 12 13 1 NA ## 15 9.9 4.7 2.4 NA wideNevada contains one row for every Nevada poll and a column for the pct each candidate got dim(nevadaPrimaries) ## [1] 76 4 dim(wideNevada) ## [1] 15 8 Or we could organize it into a time series …. timeNevada&lt;-pivot_wider(nevadaPrimaries, id_cols=candidate_name, names_from = c(start_date), values_from = pct) print(timeNevada, width=Inf) ## # A tibble: 6 x 16 ## candidate_name `2020-01-08` `2020-01-06` `2020-01-05` `2019-11-10` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Joseph R. Biden Jr. 19.4 28 23 24 ## 2 Bernard Sanders 17.6 29 17 18 ## 3 Elizabeth Warren 10.6 14 12 18 ## 4 Pete Buttigieg 8.2 6 6 8 ## 5 Amy Klobuchar 3.6 4 2 2 ## 6 Michael Bloomberg NA NA 2 NA ## `2019-11-06` `2019-10-31` `2019-10-28` `2019-09-22` `2019-09-19` `2019-08-28` ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 33 29.9 29.1 22 23.2 27 ## 2 23 18.8 19.1 22 14.2 29 ## 3 21 22.2 19.2 18 19.4 18 ## 4 9 4.9 7.3 4 3.4 4 ## 5 2 0.7 2.5 1 0.4 0 ## 6 NA NA NA NA NA NA ## `2019-08-14` `2019-08-02` `2019-06-06` `2019-05-09` `2019-03-28` ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 25 26 36 29 26.4 ## 2 10 22 13 24 22.5 ## 3 15 23 19 12 9.9 ## 4 5 7 7 13 4.7 ## 5 2 1 1 1 2.4 ## 6 NA NA NA NA NA Of course sometimes we want to do the reverse using pivot_longer In this case, we no longer have a single indicator variable for the values of start_date timeNevada %&gt;% select(candidate_name, `2020-01-08`, `2020-01-06`) %&gt;% pivot_longer(c(`2020-01-08`, `2020-01-06`), names_to = &quot;start_date_test&quot;, values_to = &quot;pct_test&quot;) ## # A tibble: 12 x 3 ## candidate_name start_date_test pct_test ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Joseph R. Biden Jr. 2020-01-08 19.4 ## 2 Joseph R. Biden Jr. 2020-01-06 28 ## 3 Bernard Sanders 2020-01-08 17.6 ## 4 Bernard Sanders 2020-01-06 29 ## 5 Elizabeth Warren 2020-01-08 10.6 ## 6 Elizabeth Warren 2020-01-06 14 ## 7 Pete Buttigieg 2020-01-08 8.2 ## 8 Pete Buttigieg 2020-01-06 6 ## 9 Amy Klobuchar 2020-01-08 3.6 ## 10 Amy Klobuchar 2020-01-06 4 ## 11 Michael Bloomberg 2020-01-08 NA ## 12 Michael Bloomberg 2020-01-06 NA This will partially undo the pivot_wider command above Now, each row is a combination of one of the six candidates and one of the two start dates Note that to get this, we used names_to and values_to instead of names_from and values_from 7.3 Relational data Most complex analyses involve more than one table of data. Certainly most active databases are not just rectangles. Modern databases are relational, where we know how rows in each rectangle are related to each other. With some slight mind bending, we can learn how to work cleanly with such data. A classic example of relational data is a social media website like Twitter. They would have multiple tables/datasets - one for each user and their user information, one for each tweet and its author, one for each like, the user who did the like, and the tweet that was liked, etc. From this data, we can use relational queries to count the average number of likes Donald Trump gets on his tweets that are tweeted between 1 and 2 AM. The primary relational querying language is SQL (Structured Query Language) but most of the same techniques can be applied in R using tidy. Download and unzip the following: https://github.com/jmontgomery/jmontgomery.github.io/blob/master/PDS/Datasets/Tweets.csv.zip Read these in using the correct file address library(tidyverse) mayors&lt;-read_csv(file=&quot;https://raw.githubusercontent.com/jmontgomery/jmontgomery.github.io/master/PDS/Datasets/Mayors.csv&quot;) tweets&lt;-read_csv(&quot;C:/Users/maria/OneDrive/WUSTL/2019-20/PDS/Tweets.csv&quot;) print(object.size(mayors), units=&quot;auto&quot;) ## 1.5 Mb print(object.size(tweets), units=&quot;auto&quot;) ## 180.1 Mb There are various ways we might want to work across levels Mutating joins, where you make a new variable constructed form matched observations in the other. E.g., how many tweets for each mayor Filtering joins, where you filter cases based on whether they match across. E.g., filter to mayors who have tweets. Combining the datasets in various ways to construct new databases with rows and columns that meet desired specifications. E.g., Tweets of all moyors from Indiana. mayors ## # A tibble: 1,473 x 51 ## X1 MayorID FullName LastName FirstName GenderMale GenderFemale RaceWhite ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 Marty H~ Handlon Marty 0 1 1 ## 2 2 2 Bill Ha~ Ham Jr. Bill 1 0 1 ## 3 3 3 Randall~ Woodfin Randall 1 0 0 ## 4 4 4 Tab Bow~ Bowling Tab 1 0 1 ## 5 5 5 Mark Sa~ Saliba Mark 1 0 1 ## 6 6 6 Steve H~ Holt Steve 1 0 1 ## 7 7 7 Sherman~ Guyton Sherman 1 0 1 ## 8 8 8 Frank V~ Brocato Frank V. 1 0 1 ## 9 9 9 Tommy B~ Battle Tommy 1 0 1 ## 10 10 10 Paul Fi~ Finley Paul 1 0 1 ## # ... with 1,463 more rows, and 43 more variables: RaceBlack &lt;dbl&gt;, ## # RaceHispanic &lt;dbl&gt;, RaceOther &lt;dbl&gt;, PartyRepublican &lt;dbl&gt;, ## # PartyDemocrat &lt;dbl&gt;, PartyNonPartisan &lt;dbl&gt;, PartyOther &lt;dbl&gt;, ## # Ideology &lt;dbl&gt;, IdeologySD &lt;dbl&gt;, LastElectionDate &lt;chr&gt;, ## # PercentVote &lt;dbl&gt;, YearsCurrentPosition &lt;dbl&gt;, CityManager &lt;dbl&gt;, ## # CouncilManager &lt;dbl&gt;, MayorCouncil &lt;dbl&gt;, Title &lt;chr&gt;, CityID &lt;dbl&gt;, ## # CityName &lt;chr&gt;, CityNameFull &lt;chr&gt;, CensusID &lt;chr&gt;, CensusID2 &lt;dbl&gt;, ## # State &lt;chr&gt;, StateAB &lt;chr&gt;, Region &lt;dbl&gt;, Division &lt;dbl&gt;, StateFIPS &lt;dbl&gt;, ## # Population &lt;dbl&gt;, Latitude &lt;dbl&gt;, Longitude &lt;dbl&gt;, CityAge &lt;dbl&gt;, ## # CityMale &lt;dbl&gt;, CityFemale &lt;dbl&gt;, CityWhite &lt;dbl&gt;, CityBlack &lt;dbl&gt;, ## # CityHispanic &lt;dbl&gt;, CityOwner &lt;dbl&gt;, CityRenter &lt;dbl&gt;, GovWebsite &lt;chr&gt;, ## # FacebookPageName &lt;chr&gt;, FacebookPageID &lt;dbl&gt;, FacebookLink &lt;chr&gt;, ## # TwitterHandle &lt;chr&gt;, TwitterLink &lt;chr&gt; tweets ## # A tibble: 604,818 x 17 ## X1 TweetID ScreenName Text CreatedTime Favorited FavoritesCount ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 9.90e17 a_silberb~ &quot;Man~ 2018-04-28 22:26:48 0 9 ## 2 2 9.90e17 a_silberb~ &quot;Suc~ 2018-04-28 22:13:38 0 8 ## 3 3 9.90e17 a_silberb~ &quot;Won~ 2018-04-28 19:42:14 0 11 ## 4 4 9.90e17 a_silberb~ &quot;I e~ 2018-04-28 14:42:20 0 8 ## 5 5 9.90e17 a_silberb~ &quot;At ~ 2018-04-28 13:58:39 0 7 ## 6 6 9.90e17 a_silberb~ &quot;Won~ 2018-04-28 13:53:21 0 6 ## 7 7 9.90e17 a_silberb~ &quot;RT ~ 2018-04-28 12:26:17 0 0 ## 8 8 9.90e17 a_silberb~ &quot;My ~ 2018-04-27 16:31:34 0 4 ## 9 9 9.90e17 a_silberb~ &quot;At ~ 2018-04-27 16:31:23 0 6 ## 10 10 9.90e17 a_silberb~ &quot;I e~ 2018-04-27 03:19:42 0 6 ## # ... with 604,808 more rows, and 10 more variables: IsRetweet &lt;dbl&gt;, ## # RetweetCount &lt;dbl&gt;, Retweeted &lt;dbl&gt;, ReplyToSN &lt;chr&gt;, ReplyToSID &lt;dbl&gt;, ## # ReplyToUID &lt;dbl&gt;, Truncated &lt;dbl&gt;, StatusSource &lt;chr&gt;, Longitude &lt;dbl&gt;, ## # Latitude &lt;dbl&gt; This is a simple relational databset that connects tweets to mayors. The variable ‘TwitterHandle’ in the mayors dataset should match up to ‘ScreenName’ in the tweets data. But it will help you get the basics here. These variables will serve to link across datasets. Let’s rename so they are the same tweets &lt;- rename(tweets, TwitterHandle=ScreenName) tweets ## # A tibble: 604,818 x 17 ## X1 TweetID TwitterHandle Text CreatedTime Favorited ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; ## 1 1 9.90e17 a_silberberg &quot;Man~ 2018-04-28 22:26:48 0 ## 2 2 9.90e17 a_silberberg &quot;Suc~ 2018-04-28 22:13:38 0 ## 3 3 9.90e17 a_silberberg &quot;Won~ 2018-04-28 19:42:14 0 ## 4 4 9.90e17 a_silberberg &quot;I e~ 2018-04-28 14:42:20 0 ## 5 5 9.90e17 a_silberberg &quot;At ~ 2018-04-28 13:58:39 0 ## 6 6 9.90e17 a_silberberg &quot;Won~ 2018-04-28 13:53:21 0 ## 7 7 9.90e17 a_silberberg &quot;RT ~ 2018-04-28 12:26:17 0 ## 8 8 9.90e17 a_silberberg &quot;My ~ 2018-04-27 16:31:34 0 ## 9 9 9.90e17 a_silberberg &quot;At ~ 2018-04-27 16:31:23 0 ## 10 10 9.90e17 a_silberberg &quot;I e~ 2018-04-27 03:19:42 0 ## # ... with 604,808 more rows, and 11 more variables: FavoritesCount &lt;dbl&gt;, ## # IsRetweet &lt;dbl&gt;, RetweetCount &lt;dbl&gt;, Retweeted &lt;dbl&gt;, ReplyToSN &lt;chr&gt;, ## # ReplyToSID &lt;dbl&gt;, ReplyToUID &lt;dbl&gt;, Truncated &lt;dbl&gt;, StatusSource &lt;chr&gt;, ## # Longitude &lt;dbl&gt;, Latitude &lt;dbl&gt; But each dataset will also need a key – a unique identier Let’s actually look to see if these are unique identifiers? mayors %&gt;% count(TwitterHandle) %&gt;% filter(n&gt;1) ## # A tibble: 3 x 2 ## TwitterHandle n ## &lt;chr&gt; &lt;int&gt; ## 1 robertgarcialb 2 ## 2 rodhiggins2017 2 ## 3 &lt;NA&gt; 743 tweets %&gt;% count(TweetID) %&gt;% filter(n&gt;1) ## # A tibble: 2 x 2 ## TweetID n ## &lt;dbl&gt; &lt;int&gt; ## 1 4.13e17 2 ## 2 7.78e17 2 Hmmm … you might want to figure out these duplicates before running any analyses. 7.3.1 Mutating join A mutating join adds variables to the right on your datset tweets %&gt;% left_join(select(mayors, TwitterHandle, LastName), by=&quot;TwitterHandle&quot;) ## # A tibble: 608,006 x 18 ## X1 TweetID TwitterHandle Text CreatedTime Favorited ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; ## 1 1 9.90e17 a_silberberg &quot;Man~ 2018-04-28 22:26:48 0 ## 2 2 9.90e17 a_silberberg &quot;Suc~ 2018-04-28 22:13:38 0 ## 3 3 9.90e17 a_silberberg &quot;Won~ 2018-04-28 19:42:14 0 ## 4 4 9.90e17 a_silberberg &quot;I e~ 2018-04-28 14:42:20 0 ## 5 5 9.90e17 a_silberberg &quot;At ~ 2018-04-28 13:58:39 0 ## 6 6 9.90e17 a_silberberg &quot;Won~ 2018-04-28 13:53:21 0 ## 7 7 9.90e17 a_silberberg &quot;RT ~ 2018-04-28 12:26:17 0 ## 8 8 9.90e17 a_silberberg &quot;My ~ 2018-04-27 16:31:34 0 ## 9 9 9.90e17 a_silberberg &quot;At ~ 2018-04-27 16:31:23 0 ## 10 10 9.90e17 a_silberberg &quot;I e~ 2018-04-27 03:19:42 0 ## # ... with 607,996 more rows, and 12 more variables: FavoritesCount &lt;dbl&gt;, ## # IsRetweet &lt;dbl&gt;, RetweetCount &lt;dbl&gt;, Retweeted &lt;dbl&gt;, ReplyToSN &lt;chr&gt;, ## # ReplyToSID &lt;dbl&gt;, ReplyToUID &lt;dbl&gt;, Truncated &lt;dbl&gt;, StatusSource &lt;chr&gt;, ## # Longitude &lt;dbl&gt;, Latitude &lt;dbl&gt;, LastName &lt;chr&gt; 7.3.2 Joins topography “Inner joins” produce results only where the linking variable appears on both tables “Outer joins” produce results with all data, and fills in missing values as necessary Left join keeps only observations from the first specified data if their is no match. Right join keeps only observations from the second data Full join keeps everything Let’s draw up the venn diagrams for: Inner joins Left joins Right joins Full joins 7.3.3 Many and one-to-many The join we did above was a one-to-many join, where the last name was added to all of the tweets for that mayor. But I did this on purpose and it can go awry when the keys are not as unique as you think they are. Joins when there are duplicates lead to creations of new rows for all possible combinations. 7.3.4 Filtering joins semi_join(x, y) keeps all observations in x that have a match in y. anti_join(x, y) drops all observations in x that have a match in y. The latter is very useful for figuring out why your joins are not working as you expect. For important data merges, you should always run these to be sure that these are returning the values and numbers you expect. 7.3.5 Set operations Tidy also includes functions where it expects datasets with the same columns. intersect(x, y) will return only observations in both x and y. union(x, y) will return unique observations in both x and y. setdiff(x, y) will return observations in x, but not in y. This is useful for deduplication tasks and also for identifying problems from specific merge commands. 7.3.6 Exercise Add a third set of data — mentions mentions &lt;-read_csv(file=&quot;https://raw.githubusercontent.com/jmontgomery/jmontgomery.github.io/master/PDS/Datasets/TwitterMentions.csv&quot;) For each mayor, calculate the number of times they were mentioned mentions ## # A tibble: 61,570 x 18 ## X1 TweetID ScreenName Text MayorHandle CreatedTime Favorited ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; ## 1 1 9.91e17 visitdelr~ Join~ a_silberbe~ 2018-04-30 16:59:14 0 ## 2 2 9.91e17 SatirclAlx .@AC~ a_silberbe~ 2018-04-30 15:44:37 0 ## 3 3 9.91e17 Madelined~ @A_S~ a_silberbe~ 2018-04-30 00:28:15 0 ## 4 4 9.90e17 Her_Grace_ Anot~ a_silberbe~ 2018-04-29 04:02:13 0 ## 5 5 9.90e17 jamesjhare @nat~ a_silberbe~ 2018-04-29 00:04:25 0 ## 6 6 9.90e17 A_Silberb~ Many~ a_silberbe~ 2018-04-28 22:26:48 0 ## 7 7 9.90e17 rossi4va @hok~ a_silberbe~ 2018-04-28 22:22:11 0 ## 8 8 9.90e17 hokiesmas~ @nat~ a_silberbe~ 2018-04-28 22:21:00 0 ## 9 9 9.90e17 rossi4va RT @~ a_silberbe~ 2018-04-28 22:19:42 0 ## 10 10 9.90e17 A_Silberb~ Such~ a_silberbe~ 2018-04-28 22:13:38 0 ## # ... with 61,560 more rows, and 11 more variables: FavoritesCount &lt;dbl&gt;, ## # IsRetweet &lt;dbl&gt;, RetweetCount &lt;dbl&gt;, Retweeted &lt;dbl&gt;, ReplyToSN &lt;chr&gt;, ## # ReplyToSID &lt;dbl&gt;, ReplyToUID &lt;dbl&gt;, Truncated &lt;dbl&gt;, StatusSource &lt;chr&gt;, ## # Longitude &lt;dbl&gt;, Latitude &lt;dbl&gt; mayors ## # A tibble: 1,473 x 51 ## X1 MayorID FullName LastName FirstName GenderMale GenderFemale RaceWhite ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 Marty H~ Handlon Marty 0 1 1 ## 2 2 2 Bill Ha~ Ham Jr. Bill 1 0 1 ## 3 3 3 Randall~ Woodfin Randall 1 0 0 ## 4 4 4 Tab Bow~ Bowling Tab 1 0 1 ## 5 5 5 Mark Sa~ Saliba Mark 1 0 1 ## 6 6 6 Steve H~ Holt Steve 1 0 1 ## 7 7 7 Sherman~ Guyton Sherman 1 0 1 ## 8 8 8 Frank V~ Brocato Frank V. 1 0 1 ## 9 9 9 Tommy B~ Battle Tommy 1 0 1 ## 10 10 10 Paul Fi~ Finley Paul 1 0 1 ## # ... with 1,463 more rows, and 43 more variables: RaceBlack &lt;dbl&gt;, ## # RaceHispanic &lt;dbl&gt;, RaceOther &lt;dbl&gt;, PartyRepublican &lt;dbl&gt;, ## # PartyDemocrat &lt;dbl&gt;, PartyNonPartisan &lt;dbl&gt;, PartyOther &lt;dbl&gt;, ## # Ideology &lt;dbl&gt;, IdeologySD &lt;dbl&gt;, LastElectionDate &lt;chr&gt;, ## # PercentVote &lt;dbl&gt;, YearsCurrentPosition &lt;dbl&gt;, CityManager &lt;dbl&gt;, ## # CouncilManager &lt;dbl&gt;, MayorCouncil &lt;dbl&gt;, Title &lt;chr&gt;, CityID &lt;dbl&gt;, ## # CityName &lt;chr&gt;, CityNameFull &lt;chr&gt;, CensusID &lt;chr&gt;, CensusID2 &lt;dbl&gt;, ## # State &lt;chr&gt;, StateAB &lt;chr&gt;, Region &lt;dbl&gt;, Division &lt;dbl&gt;, StateFIPS &lt;dbl&gt;, ## # Population &lt;dbl&gt;, Latitude &lt;dbl&gt;, Longitude &lt;dbl&gt;, CityAge &lt;dbl&gt;, ## # CityMale &lt;dbl&gt;, CityFemale &lt;dbl&gt;, CityWhite &lt;dbl&gt;, CityBlack &lt;dbl&gt;, ## # CityHispanic &lt;dbl&gt;, CityOwner &lt;dbl&gt;, CityRenter &lt;dbl&gt;, GovWebsite &lt;chr&gt;, ## # FacebookPageName &lt;chr&gt;, FacebookPageID &lt;dbl&gt;, FacebookLink &lt;chr&gt;, ## # TwitterHandle &lt;chr&gt;, TwitterLink &lt;chr&gt; mentions &lt;- rename(mentions, TwitterHandle = &quot;ScreenName&quot;) mentionsCount &lt;- mentions %&gt;% group_by(MayorHandle) %&gt;% tally() answer1 &lt;- mayors %&gt;% left_join(mentionsCount, by=c(&quot;TwitterHandle&quot; = &quot;MayorHandle&quot;)) %&gt;% select(TwitterHandle, FullName, n) %&gt;% arrange(desc(n)) answer1 ## # A tibble: 1,473 x 3 ## TwitterHandle FullName n ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 markfarrellsf Mark Farrell 1000 ## 2 sam_hindi Sam Hindi 1000 ## 3 andrewgillum Andrew D. Gillum 1000 ## 4 keishabottoms Keisha Lance Bottoms 1000 ## 5 chicagosmayor Rahm Emmanuel 1000 ## 6 indymayorjoe Joseph &#39;Joe&#39; H. Hogsett 1000 ## 7 louisvillemayor Greg Fischer 1000 ## 8 billdeblasio Bill de Blasio 1000 ## 9 billpeduto William Peduto 1000 ## 10 mayorbriley David Briley 999 ## # ... with 1,463 more rows Add to the mayors datset the number of times each mayor tweeted. tweetCounts &lt;- tweets %&gt;% group_by(TwitterHandle) %&gt;% tally() answer2 &lt;- mayors %&gt;% left_join(tweetCounts, by=&quot;TwitterHandle&quot;) %&gt;% arrange(desc(n)) answer2 ## # A tibble: 1,473 x 52 ## X1 MayorID FullName LastName FirstName GenderMale GenderFemale RaceWhite ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 11 11 William~ Stimpson William ~ 1 0 1 ## 2 443 443 Thomas ~ Masters Thomas A. 1 0 0 ## 3 498 498 Rahm Em~ Emmanuel Rahm 1 0 1 ## 4 778 778 Emily L~ Larson Emily 0 1 1 ## 5 812 812 Jason L~ Shelton Jason L. 1 0 1 ## 6 902 902 Derek A~ Armstead Derek 1 0 0 ## 7 1070 1071 Greg Pe~ Peterson Greg 1 0 1 ## 8 1140 1141 Jim Ken~ Kenney Jim 1 0 1 ## 9 1142 1143 Ed Pawl~ Pawlows~ Ed 1 0 1 ## 10 37 37 Greg St~ Stanton Greg 1 0 1 ## # ... with 1,463 more rows, and 44 more variables: RaceBlack &lt;dbl&gt;, ## # RaceHispanic &lt;dbl&gt;, RaceOther &lt;dbl&gt;, PartyRepublican &lt;dbl&gt;, ## # PartyDemocrat &lt;dbl&gt;, PartyNonPartisan &lt;dbl&gt;, PartyOther &lt;dbl&gt;, ## # Ideology &lt;dbl&gt;, IdeologySD &lt;dbl&gt;, LastElectionDate &lt;chr&gt;, ## # PercentVote &lt;dbl&gt;, YearsCurrentPosition &lt;dbl&gt;, CityManager &lt;dbl&gt;, ## # CouncilManager &lt;dbl&gt;, MayorCouncil &lt;dbl&gt;, Title &lt;chr&gt;, CityID &lt;dbl&gt;, ## # CityName &lt;chr&gt;, CityNameFull &lt;chr&gt;, CensusID &lt;chr&gt;, CensusID2 &lt;dbl&gt;, ## # State &lt;chr&gt;, StateAB &lt;chr&gt;, Region &lt;dbl&gt;, Division &lt;dbl&gt;, StateFIPS &lt;dbl&gt;, ## # Population &lt;dbl&gt;, Latitude &lt;dbl&gt;, Longitude &lt;dbl&gt;, CityAge &lt;dbl&gt;, ## # CityMale &lt;dbl&gt;, CityFemale &lt;dbl&gt;, CityWhite &lt;dbl&gt;, CityBlack &lt;dbl&gt;, ## # CityHispanic &lt;dbl&gt;, CityOwner &lt;dbl&gt;, CityRenter &lt;dbl&gt;, GovWebsite &lt;chr&gt;, ## # FacebookPageName &lt;chr&gt;, FacebookPageID &lt;dbl&gt;, FacebookLink &lt;chr&gt;, ## # TwitterHandle &lt;chr&gt;, TwitterLink &lt;chr&gt;, n &lt;int&gt; Create a combined dataset of all tweets from the tweets and mentions data. Subset down to overlapping columns (and rename where needed) to make this easy. allData &lt;- full_join(tweets, mentions) ## Joining, by = c(&quot;X1&quot;, &quot;TweetID&quot;, &quot;TwitterHandle&quot;, &quot;Text&quot;, &quot;CreatedTime&quot;, &quot;Favorited&quot;, &quot;FavoritesCount&quot;, &quot;IsRetweet&quot;, &quot;RetweetCount&quot;, &quot;Retweeted&quot;, &quot;ReplyToSN&quot;, &quot;ReplyToSID&quot;, &quot;ReplyToUID&quot;, &quot;Truncated&quot;, &quot;StatusSource&quot;, &quot;Longitude&quot;, &quot;Latitude&quot;) allData ## # A tibble: 666,388 x 18 ## X1 TweetID TwitterHandle Text CreatedTime Favorited ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; ## 1 1 9.90e17 a_silberberg &quot;Man~ 2018-04-28 22:26:48 0 ## 2 2 9.90e17 a_silberberg &quot;Suc~ 2018-04-28 22:13:38 0 ## 3 3 9.90e17 a_silberberg &quot;Won~ 2018-04-28 19:42:14 0 ## 4 4 9.90e17 a_silberberg &quot;I e~ 2018-04-28 14:42:20 0 ## 5 5 9.90e17 a_silberberg &quot;At ~ 2018-04-28 13:58:39 0 ## 6 6 9.90e17 a_silberberg &quot;Won~ 2018-04-28 13:53:21 0 ## 7 7 9.90e17 a_silberberg &quot;RT ~ 2018-04-28 12:26:17 0 ## 8 8 9.90e17 a_silberberg &quot;My ~ 2018-04-27 16:31:34 0 ## 9 9 9.90e17 a_silberberg &quot;At ~ 2018-04-27 16:31:23 0 ## 10 10 9.90e17 a_silberberg &quot;I e~ 2018-04-27 03:19:42 0 ## # ... with 666,378 more rows, and 12 more variables: FavoritesCount &lt;dbl&gt;, ## # IsRetweet &lt;dbl&gt;, RetweetCount &lt;dbl&gt;, Retweeted &lt;dbl&gt;, ReplyToSN &lt;chr&gt;, ## # ReplyToSID &lt;dbl&gt;, ReplyToUID &lt;dbl&gt;, Truncated &lt;dbl&gt;, StatusSource &lt;chr&gt;, ## # Longitude &lt;dbl&gt;, Latitude &lt;dbl&gt;, MayorHandle &lt;chr&gt; 7.4 stringr stringr is a tidy package that is used for processing strings and text data library(tidyverse) tweets&lt;-read_csv(&quot;C:/Users/maria/OneDrive/WUSTL/2019-20/PDS/Tweets.csv&quot;) aTweet&lt;-tweets[1,]$Text aTweet ## [1] &quot;Many thanks to everyone involved in Alexandria&#39;s #EarthDay celebration. Together, we are reducing pollution and was… https://t.co/wwMOIg4t1w&quot; str_length(aTweet) ## [1] 140 words&lt;-str_split(aTweet, pattern = &quot; &quot;) words ## [[1]] ## [1] &quot;Many&quot; &quot;thanks&quot; ## [3] &quot;to&quot; &quot;everyone&quot; ## [5] &quot;involved&quot; &quot;in&quot; ## [7] &quot;Alexandria&#39;s&quot; &quot;#EarthDay&quot; ## [9] &quot;celebration.&quot; &quot;Together,&quot; ## [11] &quot;we&quot; &quot;are&quot; ## [13] &quot;reducing&quot; &quot;pollution&quot; ## [15] &quot;and&quot; &quot;was…&quot; ## [17] &quot;https://t.co/wwMOIg4t1w&quot; str_c(words) ## [1] &quot;c(\\&quot;Many\\&quot;, \\&quot;thanks\\&quot;, \\&quot;to\\&quot;, \\&quot;everyone\\&quot;, \\&quot;involved\\&quot;, \\&quot;in\\&quot;, \\&quot;Alexandria&#39;s\\&quot;, \\&quot;#EarthDay\\&quot;, \\&quot;celebration.\\&quot;, \\&quot;Together,\\&quot;, \\&quot;we\\&quot;, \\&quot;are\\&quot;, \\&quot;reducing\\&quot;, \\&quot;pollution\\&quot;, \\&quot;and\\&quot;, \\&quot;was…\\&quot;, \\&quot;https://t.co/wwMOIg4t1w\\&quot;)&quot; str_c(unlist(words)) ## [1] &quot;Many&quot; &quot;thanks&quot; ## [3] &quot;to&quot; &quot;everyone&quot; ## [5] &quot;involved&quot; &quot;in&quot; ## [7] &quot;Alexandria&#39;s&quot; &quot;#EarthDay&quot; ## [9] &quot;celebration.&quot; &quot;Together,&quot; ## [11] &quot;we&quot; &quot;are&quot; ## [13] &quot;reducing&quot; &quot;pollution&quot; ## [15] &quot;and&quot; &quot;was…&quot; ## [17] &quot;https://t.co/wwMOIg4t1w&quot; str_c(unlist(words), &quot;Added&quot;) ## [1] &quot;ManyAdded&quot; &quot;thanksAdded&quot; ## [3] &quot;toAdded&quot; &quot;everyoneAdded&quot; ## [5] &quot;involvedAdded&quot; &quot;inAdded&quot; ## [7] &quot;Alexandria&#39;sAdded&quot; &quot;#EarthDayAdded&quot; ## [9] &quot;celebration.Added&quot; &quot;Together,Added&quot; ## [11] &quot;weAdded&quot; &quot;areAdded&quot; ## [13] &quot;reducingAdded&quot; &quot;pollutionAdded&quot; ## [15] &quot;andAdded&quot; &quot;was…Added&quot; ## [17] &quot;https://t.co/wwMOIg4t1wAdded&quot; str_c(unlist(words), &quot;Added&quot;, sep=&quot; &quot;) ## [1] &quot;Many Added&quot; &quot;thanks Added&quot; ## [3] &quot;to Added&quot; &quot;everyone Added&quot; ## [5] &quot;involved Added&quot; &quot;in Added&quot; ## [7] &quot;Alexandria&#39;s Added&quot; &quot;#EarthDay Added&quot; ## [9] &quot;celebration. Added&quot; &quot;Together, Added&quot; ## [11] &quot;we Added&quot; &quot;are Added&quot; ## [13] &quot;reducing Added&quot; &quot;pollution Added&quot; ## [15] &quot;and Added&quot; &quot;was… Added&quot; ## [17] &quot;https://t.co/wwMOIg4t1w Added&quot; str_c(&quot;Before&quot;, unlist(words), &quot;Added&quot;, sep=&quot; &quot;) ## [1] &quot;Before Many Added&quot; ## [2] &quot;Before thanks Added&quot; ## [3] &quot;Before to Added&quot; ## [4] &quot;Before everyone Added&quot; ## [5] &quot;Before involved Added&quot; ## [6] &quot;Before in Added&quot; ## [7] &quot;Before Alexandria&#39;s Added&quot; ## [8] &quot;Before #EarthDay Added&quot; ## [9] &quot;Before celebration. Added&quot; ## [10] &quot;Before Together, Added&quot; ## [11] &quot;Before we Added&quot; ## [12] &quot;Before are Added&quot; ## [13] &quot;Before reducing Added&quot; ## [14] &quot;Before pollution Added&quot; ## [15] &quot;Before and Added&quot; ## [16] &quot;Before was… Added&quot; ## [17] &quot;Before https://t.co/wwMOIg4t1w Added&quot; Or you may want to assemble it all into all back into a coherent whole str_c(unlist(words), collapse=&quot; &quot;) ## [1] &quot;Many thanks to everyone involved in Alexandria&#39;s #EarthDay celebration. Together, we are reducing pollution and was… https://t.co/wwMOIg4t1w&quot; 7.4.1 Things you haven’t thought about strings Strings in memory are different than how they appear on the screen You can use the function writeLines to see how a function would atually render to a reader (as opposed to how it is stored in the computer.) The big confusion is that special characters have to be “escaped” or else they get in the way (From R4DS) x &lt;- c(&quot;\\&quot;&quot;, &quot;\\\\&quot;) x ## [1] &quot;\\&quot;&quot; &quot;\\\\&quot; writeLines(x) ## &quot; ## \\ Others to watch out for are \"\\n\" and \"\\t\" for next line and tab na is a problem, so you might use str_replace_na stringr replicates a lot of the functions we have already used for characters with (sometimes) slightly different syntax colors &lt;- c(&quot;red&quot;, &quot;yellow&quot;, &quot;blue&quot;, &quot;green&quot;, &quot;magenta&quot;, &quot;cyan&quot;) str_sub(colors, 1, 3) ## [1] &quot;red&quot; &quot;yel&quot; &quot;blu&quot; &quot;gre&quot; &quot;mag&quot; &quot;cya&quot; str_sub(colors, -3, -1) #count back from the end ## [1] &quot;red&quot; &quot;low&quot; &quot;lue&quot; &quot;een&quot; &quot;nta&quot; &quot;yan&quot; str_sub(colors, 1, 10) # Robust to going out of index ## [1] &quot;red&quot; &quot;yellow&quot; &quot;blue&quot; &quot;green&quot; &quot;magenta&quot; &quot;cyan&quot; str_sub(colors, 1, 3)&lt;-str_to_upper(str_sub(colors, 1, 3)) colors ## [1] &quot;RED&quot; &quot;YELlow&quot; &quot;BLUe&quot; &quot;GREen&quot; &quot;MAGenta&quot; &quot;CYAn&quot; colors&lt;-str_to_lower(colors) colors ## [1] &quot;red&quot; &quot;yellow&quot; &quot;blue&quot; &quot;green&quot; &quot;magenta&quot; &quot;cyan&quot; Example: Filter down to all of the tweets from Mayor Lyda Krewson in our data Find the mean number of words in her tweets. Find the total. Take all of the words she has used and reduce them down to only their first five letters. Repeat (2) and compare. Question 2 hertweets &lt;- filter(tweets, ScreenName == &quot;lydakrewson&quot;)[&quot;Text&quot;] numWords &lt;- hertweets %&gt;% rowwise() %&gt;% transmute(numWords= length(unlist(str_split(Text, &quot; &quot;)))) numWords ## Source: local data frame [3,191 x 1] ## Groups: &lt;by row&gt; ## ## # A tibble: 3,191 x 1 ## numWords ## &lt;int&gt; ## 1 20 ## 2 25 ## 3 20 ## 4 20 ## 5 17 ## 6 21 ## 7 8 ## 8 11 ## 9 19 ## 10 13 ## # ... with 3,181 more rows mean(numWords$numWords) ## [1] 16.58602 length(unique(unlist(str_split(hertweets$Text, &quot; &quot;)))) ## [1] 15960 Question 3 length(unique(str_sub(unlist(str_split(hertweets$Text, &quot; &quot;)), 1, 5))) ## [1] 9831 7.5 Pipes and maps Download: https://www.voterstudygroup.org/publication/2019-voter-survey-full-data-set Codebook: https://www.voterstudygroup.org/publication/2019-voter-survey-full-data-set library(tidyverse) VSG&lt;-read_csv(&quot;C:/Users/maria/OneDrive/WUSTL/2019-20/PDS/VOTER_Survey_Jan217_Release1-csv.csv&quot;, col_types=cols(weight_18_24_2018=&quot;d&quot;)) Question: Is there a lane? We are going to: Subset the data to just favorability raitings for Elizabeth Warren and Bernie Sanders Recode these variables into “approve” and “not approve” Find the proportion of respondents who either approve or disapprove of both One strategy is just to make new datsets for each step VSG.two &lt;- select(VSG, fav_sanders_2019, fav_warren_2019) VSG.three&lt;-mutate(VSG.two, fav_sanders_binary = (fav_sanders_2019&lt;=2)) VSG.four&lt;-mutate(VSG.three, fav_sanders_binary= na_if(fav_sanders_2019, fav_sanders_2019&gt;4)) This is bad because we’re wasting a lot of memory in our environment that we’ll never use again. Another strategy is just to overwrite the same dataset VSG &lt;- select(VSG, fav_sanders_2019, fav_warren_2019) VSG &lt; -mutate(VSG, fav_sanders_binary = (fav_sanders_2019&lt;=2)*1) VSG &lt;- mutate(VSG, fav_sanders_binary= na_if(fav_sanders_2019, fav_sanders_2019&gt;4)) This still wastes a lot of memory because of the way memory is managed in R. It also would be terrible to debug if something goes wrong. An even more difficult way would be write a function where the output of each stage are passed onto an outer layer. Or we can use the pipes VSG %&gt;% select(fav_sanders_2019, fav_warren_2019) %&gt;% mutate(fav_sanders_binary= na_if(fav_sanders_2019, fav_sanders_2019&gt;4)) %&gt;% mutate(fav_sanders_binary = (fav_sanders_2019&lt;=2)*1) 7.5.1 Limitations of Pipes Piping works by creating a new function where object manipulations are passed from one to another This means that piping won’t work in cases where: The function uses the current environment such as assign, load, or get Functions that use lazy evaluation such as tryCatch, try, or supressMessages Pipes are not good in all situations If you do more than 4 or 5 pipes, go ahead and make in intermediate object. Otherwise debugging is a pain. If you are not actually working on just one object but instead combinig multiple objects, this is just not worth it. Where ther are interdepencies (e.g., complex recoding based on multiple variables) The magrittr package comes with some other tools for using in specific situations The %T&gt;% pipe works by calling the function to the right, but returning the function to the left library(magrittr) VSG&lt;-read_csv(&quot;C:/Users/maria/OneDrive/WUSTL/2019-20/PDS/VOTER_Survey_Jan217_Release1-csv.csv&quot;, col_types=cols(weight_18_24_2018=&quot;d&quot;)) VSG %&gt;% select(fav_sanders_2019, fav_warren_2019) %&gt;% mutate(fav_sanders_binary= na_if(fav_sanders_2019, fav_sanders_2019&gt;4)) %&gt;% mutate(fav_sanders_binary = (fav_sanders_2019&lt;=2)*1) %T&gt;% plot() ## # A tibble: 9,548 x 3 ## fav_sanders_2019 fav_warren_2019 fav_sanders_binary ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 1 ## 2 NA NA NA ## 3 2 1 1 ## 4 4 3 0 ## 5 3 4 0 ## 6 3 1 0 ## 7 3 2 0 ## 8 NA NA NA ## 9 NA NA NA ## 10 2 1 1 ## # ... with 9,538 more rows We may also want to use specific elements from a dataframe using the %$% operator VSG&lt;- VSG %&gt;% select(fav_sanders_2019, fav_warren_2019) %&gt;% mutate(fav_sanders_binary= na_if(fav_sanders_2019, fav_sanders_2019&gt;4)) %&gt;% mutate(fav_sanders_binary = (fav_sanders_2019&lt;=2)*1) %&gt;% mutate(fav_warren_binary= na_if(fav_warren_2019, fav_warren_2019&gt;4)) %&gt;% mutate(fav_warren_binary = (fav_warren_2019&lt;=2)*1) library(magrittr) VSG&lt;- VSG %$% plot(table(fav_sanders_binary, fav_warren_binary)) 7.6 map VSG&lt;-read_csv(&quot;C:/Users/maria/OneDrive/WUSTL/2019-20/PDS/VOTER_Survey_Jan217_Release1-csv.csv&quot;, col_types=cols(weight_18_24_2018=&quot;d&quot;)) VSG.fav&lt;-VSG %&gt;% select(starts_with(&quot;fav&quot;)) We want to loop over these data and recode all of the columns according to our rules Anything above a 4 gets moved to NA Then we turn them into a binary based on whether they are 2 and less or not output&lt;-as.data.frame(matrix(NA, nrow(VSG.fav), ncol(VSG.fav))) for(i in seq_along(VSG.fav)){ output[,i]&lt;-(VSG.fav[,i]&lt;=2)*1 } We could do this without making a new object for(i in seq_along(VSG.fav)){ VSG.fav[,i]= na_if(VSG.fav[[i]],VSG.fav[[i]]&gt;4) VSG.fav[,i]&lt;-(VSG.fav[,i]&lt;=2)*1 } head(VSG.fav) ## # A tibble: 6 x 68 ## fav_trump_2019[~ fav_obama_2019[~ fav_hrc_2019[,&quot;~ fav_sanders_201~ ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 1 1 1 ## 2 NA NA NA NA ## 3 0 1 1 1 ## 4 0 1 0 0 ## 5 1 1 0 0 ## 6 0 1 1 0 ## # ... with 64 more variables: fav_putin_2019[,&quot;fav_putin_2019&quot;] &lt;dbl&gt;, ## # fav_schumer_2019[,&quot;fav_schumer_2019&quot;] &lt;dbl&gt;, ## # fav_pelosi_2019[,&quot;fav_pelosi_2019&quot;] &lt;dbl&gt;, ## # fav_comey_2019[,&quot;fav_comey_2019&quot;] &lt;dbl&gt;, ## # fav_mueller_2019[,&quot;fav_mueller_2019&quot;] &lt;dbl&gt;, ## # fav_mcconnell_2019[,&quot;fav_mcconnell_2019&quot;] &lt;dbl&gt;, ## # fav_kavanaugh_2019[,&quot;fav_kavanaugh_2019&quot;] &lt;dbl&gt;, ## # fav_biden_2019[,&quot;fav_biden_2019&quot;] &lt;dbl&gt;, ## # fav_warren_2019[,&quot;fav_warren_2019&quot;] &lt;dbl&gt;, ## # fav_harris_2019[,&quot;fav_harris_2019&quot;] &lt;dbl&gt;, ## # fav_gillibrand_2019[,&quot;fav_gillibrand_2019&quot;] &lt;dbl&gt;, ## # fav_patrick_2019[,&quot;fav_patrick_2019&quot;] &lt;dbl&gt;, ## # fav_booker_2019[,&quot;fav_booker_2019&quot;] &lt;dbl&gt;, ## # fav_garcetti_2019[,&quot;fav_garcetti_2019&quot;] &lt;dbl&gt;, ## # fav_klobuchar_2019[,&quot;fav_klobuchar_2019&quot;] &lt;dbl&gt;, ## # fav_gorsuch_2019[,&quot;fav_gorsuch_2019&quot;] &lt;dbl&gt;, ## # fav_kasich_2019[,&quot;fav_kasich_2019&quot;] &lt;dbl&gt;, ## # fav_haley_2019[,&quot;fav_haley_2019&quot;] &lt;dbl&gt;, ## # fav_bloomberg_2019[,&quot;fav_bloomberg_2019&quot;] &lt;dbl&gt;, ## # fav_holder_2019[,&quot;fav_holder_2019&quot;] &lt;dbl&gt;, ## # fav_avenatti_2019[,&quot;fav_avenatti_2019&quot;] &lt;dbl&gt;, ## # fav_castro_2019[,&quot;fav_castro_2019&quot;] &lt;dbl&gt;, ## # fav_landrieu_2019[,&quot;fav_landrieu_2019&quot;] &lt;dbl&gt;, ## # fav_orourke_2019[,&quot;fav_orourke_2019&quot;] &lt;dbl&gt;, ## # fav_hickenlooper_2019[,&quot;fav_hickenlooper_2019&quot;] &lt;dbl&gt;, ## # fav_pence_2019[,&quot;fav_pence_2019&quot;] &lt;dbl&gt;, ## # favorhealth_2019[,&quot;favorhealth_2019&quot;] &lt;dbl&gt;, ## # fav_trump_2018[,&quot;fav_trump_2018&quot;] &lt;dbl&gt;, ## # fav_ryan_2018[,&quot;fav_ryan_2018&quot;] &lt;dbl&gt;, ## # fav_obama_2018[,&quot;fav_obama_2018&quot;] &lt;dbl&gt;, ## # fav_hrc_2018[,&quot;fav_hrc_2018&quot;] &lt;dbl&gt;, ## # fav_sanders_2018[,&quot;fav_sanders_2018&quot;] &lt;dbl&gt;, ## # fav_putin_2018[,&quot;fav_putin_2018&quot;] &lt;dbl&gt;, ## # fav_schumer_2018[,&quot;fav_schumer_2018&quot;] &lt;dbl&gt;, ## # fav_pelosi_2018[,&quot;fav_pelosi_2018&quot;] &lt;dbl&gt;, ## # fav_comey_2018[,&quot;fav_comey_2018&quot;] &lt;dbl&gt;, ## # fav_mueller_2018[,&quot;fav_mueller_2018&quot;] &lt;dbl&gt;, ## # fav_mcconnell_2018[,&quot;fav_mcconnell_2018&quot;] &lt;dbl&gt;, ## # fav_trump_2017[,&quot;fav_trump_2017&quot;] &lt;dbl&gt;, ## # fav_ryan_2017[,&quot;fav_ryan_2017&quot;] &lt;dbl&gt;, ## # fav_obama_2017[,&quot;fav_obama_2017&quot;] &lt;dbl&gt;, ## # fav_hrc_2017[,&quot;fav_hrc_2017&quot;] &lt;dbl&gt;, ## # fav_sanders_2017[,&quot;fav_sanders_2017&quot;] &lt;dbl&gt;, ## # fav_putin_2017[,&quot;fav_putin_2017&quot;] &lt;dbl&gt;, ## # fav_trump_2016[,&quot;fav_trump_2016&quot;] &lt;dbl&gt;, ## # fav_cruz_2016[,&quot;fav_cruz_2016&quot;] &lt;dbl&gt;, ## # fav_ryan_2016[,&quot;fav_ryan_2016&quot;] &lt;dbl&gt;, ## # fav_romn_2016[,&quot;fav_romn_2016&quot;] &lt;dbl&gt;, ## # fav_obama_2016[,&quot;fav_obama_2016&quot;] &lt;dbl&gt;, ## # fav_hrc_2016[,&quot;fav_hrc_2016&quot;] &lt;dbl&gt;, ## # fav_sanders_2016[,&quot;fav_sanders_2016&quot;] &lt;dbl&gt;, ## # fav_rubio_2016[,&quot;fav_rubio_2016&quot;] &lt;dbl&gt;, ## # fav_grid_row_rnd_2016[,&quot;fav_grid_row_rnd_2016&quot;] &lt;dbl&gt;, ## # fav_grid_col_rnd_2016[,&quot;fav_grid_col_rnd_2016&quot;] &lt;dbl&gt;, ## # fav_romn_baseline[,&quot;fav_romn_baseline&quot;] &lt;dbl&gt;, ## # fav_ging_baseline[,&quot;fav_ging_baseline&quot;] &lt;dbl&gt;, ## # fav_hunt_baseline[,&quot;fav_hunt_baseline&quot;] &lt;dbl&gt;, ## # fav_bach_baseline[,&quot;fav_bach_baseline&quot;] &lt;dbl&gt;, ## # fav_ronp_baseline[,&quot;fav_ronp_baseline&quot;] &lt;dbl&gt;, ## # fav_sant_baseline[,&quot;fav_sant_baseline&quot;] &lt;dbl&gt;, ## # fav_perr_baseline[,&quot;fav_perr_baseline&quot;] &lt;dbl&gt;, ## # fav_obama_baseline[,&quot;fav_obama_baseline&quot;] &lt;dbl&gt;, ## # fav_hrc_baseline[,&quot;fav_hrc_baseline&quot;] &lt;dbl&gt;, ## # fav_biden_baseline[,&quot;fav_biden_baseline&quot;] &lt;dbl&gt; We can also loop where we aren’t sure how long the final output is This can be done by adding each element to the end of a vector as we did in some previous lectures This is computationally expensive A better solution is to add all of them to a list and then combine them back at the end. See Chapter 23.3.3 in the book for more Or Chapter 23.3.4 for while loops (which we have already covered) Looping is such a pervasive task, that there are functions to make it easier The map family will do this, and you can carefully control the output map makes a list map_lgl makes a logical vector map_int makes an integer map_dbl makes a double vector map_chr makes a character These functions takes in a vector as an input and applies that function Let’s say that we want to find the mean level of favorability in our dataset This is very similar to lapply in base R For a comparison, check this link out map(VSG.fav, mean, na.rm=TRUE) ## $fav_trump_2019 ## [1] 0.4214486 ## ## $fav_obama_2019 ## [1] 0.5311993 ## ## $fav_hrc_2019 ## [1] 0.3907656 ## ## $fav_sanders_2019 ## [1] 0.4724886 ## ## $fav_putin_2019 ## [1] 0.08172297 ## ## $fav_schumer_2019 ## [1] 0.3249742 ## ## $fav_pelosi_2019 ## [1] 0.3808821 ## ## $fav_comey_2019 ## [1] 0.2996017 ## ## $fav_mueller_2019 ## [1] 0.4549344 ## ## $fav_mcconnell_2019 ## [1] 0.2793922 ## ## $fav_kavanaugh_2019 ## [1] 0.4047795 ## ## $fav_biden_2019 ## [1] 0.5340021 ## ## $fav_warren_2019 ## [1] 0.4173182 ## ## $fav_harris_2019 ## [1] 0.322909 ## ## $fav_gillibrand_2019 ## [1] 0.2838177 ## ## $fav_patrick_2019 ## [1] 0.1606432 ## ## $fav_booker_2019 ## [1] 0.3462163 ## ## $fav_garcetti_2019 ## [1] 0.1048827 ## ## $fav_klobuchar_2019 ## [1] 0.2283523 ## ## $fav_gorsuch_2019 ## [1] 0.354182 ## ## $fav_kasich_2019 ## [1] 0.3192211 ## ## $fav_haley_2019 ## [1] 0.420416 ## ## $fav_bloomberg_2019 ## [1] 0.3218764 ## ## $fav_holder_2019 ## [1] 0.3221714 ## ## $fav_avenatti_2019 ## [1] 0.1737719 ## ## $fav_castro_2019 ## [1] 0.2015046 ## ## $fav_landrieu_2019 ## [1] 0.1274524 ## ## $fav_orourke_2019 ## [1] 0.364213 ## ## $fav_hickenlooper_2019 ## [1] 0.1295176 ## ## $fav_pence_2019 ## [1] 0.4437233 ## ## $favorhealth_2019 ## [1] 0.476914 ## ## $fav_trump_2018 ## [1] 0.3953372 ## ## $fav_ryan_2018 ## [1] 0.2812656 ## ## $fav_obama_2018 ## [1] 0.5322231 ## ## $fav_hrc_2018 ## [1] 0.3900083 ## ## $fav_sanders_2018 ## [1] 0.4814321 ## ## $fav_putin_2018 ## [1] 0.07693589 ## ## $fav_schumer_2018 ## [1] 0.3080766 ## ## $fav_pelosi_2018 ## [1] 0.3233972 ## ## $fav_comey_2018 ## [1] 0.3172356 ## ## $fav_mueller_2018 ## [1] 0.4066611 ## ## $fav_mcconnell_2018 ## [1] 0.1567027 ## ## $fav_trump_2017 ## [1] 0.43642 ## ## $fav_ryan_2017 ## [1] 0.2748614 ## ## $fav_obama_2017 ## [1] 0.4928269 ## ## $fav_hrc_2017 ## [1] 0.4029997 ## ## $fav_sanders_2017 ## [1] 0.4768503 ## ## $fav_putin_2017 ## [1] 0.1092273 ## ## $fav_trump_2016 ## [1] 0.4416231 ## ## $fav_cruz_2016 ## [1] 0.3446602 ## ## $fav_ryan_2016 ## [1] 0.3635798 ## ## $fav_romn_2016 ## [1] 0.3480209 ## ## $fav_obama_2016 ## [1] 0.4887976 ## ## $fav_hrc_2016 ## [1] 0.418347 ## ## $fav_sanders_2016 ## [1] 0.5373413 ## ## $fav_rubio_2016 ## [1] 0.4218322 ## ## $fav_grid_row_rnd_2016 ## [1] 0 ## ## $fav_grid_col_rnd_2016 ## [1] 0 ## ## $fav_romn_baseline ## [1] 0.4337814 ## ## $fav_ging_baseline ## [1] 0.3297237 ## ## $fav_hunt_baseline ## [1] 0.3512572 ## ## $fav_bach_baseline ## [1] 0.3188947 ## ## $fav_ronp_baseline ## [1] 0.3409261 ## ## $fav_sant_baseline ## [1] 0.377645 ## ## $fav_perr_baseline ## [1] 0.3066965 ## ## $fav_obama_baseline ## [1] 0.4814538 ## ## $fav_hrc_baseline ## [1] 0.5892457 ## ## $fav_biden_baseline ## [1] 0.4600448 map_dbl(VSG.fav, mean, na.rm=TRUE) ## fav_trump_2019 fav_obama_2019 fav_hrc_2019 ## 0.42144859 0.53119929 0.39076560 ## fav_sanders_2019 fav_putin_2019 fav_schumer_2019 ## 0.47248857 0.08172297 0.32497418 ## fav_pelosi_2019 fav_comey_2019 fav_mueller_2019 ## 0.38088214 0.29960171 0.45493436 ## fav_mcconnell_2019 fav_kavanaugh_2019 fav_biden_2019 ## 0.27939224 0.40477947 0.53400207 ## fav_warren_2019 fav_harris_2019 fav_gillibrand_2019 ## 0.41731819 0.32290898 0.28381767 ## fav_patrick_2019 fav_booker_2019 fav_garcetti_2019 ## 0.16064316 0.34621626 0.10488273 ## fav_klobuchar_2019 fav_gorsuch_2019 fav_kasich_2019 ## 0.22835226 0.35418203 0.31922112 ## fav_haley_2019 fav_bloomberg_2019 fav_holder_2019 ## 0.42041599 0.32187638 0.32217141 ## fav_avenatti_2019 fav_castro_2019 fav_landrieu_2019 ## 0.17377194 0.20150465 0.12745243 ## fav_orourke_2019 fav_hickenlooper_2019 fav_pence_2019 ## 0.36421301 0.12951763 0.44372326 ## favorhealth_2019 fav_trump_2018 fav_ryan_2018 ## 0.47691400 0.39533722 0.28126561 ## fav_obama_2018 fav_hrc_2018 fav_sanders_2018 ## 0.53222315 0.39000833 0.48143214 ## fav_putin_2018 fav_schumer_2018 fav_pelosi_2018 ## 0.07693589 0.30807660 0.32339717 ## fav_comey_2018 fav_mueller_2018 fav_mcconnell_2018 ## 0.31723564 0.40666112 0.15670275 ## fav_trump_2017 fav_ryan_2017 fav_obama_2017 ## 0.43641995 0.27486143 0.49282687 ## fav_hrc_2017 fav_sanders_2017 fav_putin_2017 ## 0.40299967 0.47685034 0.10922726 ## fav_trump_2016 fav_cruz_2016 fav_ryan_2016 ## 0.44162310 0.34466019 0.36357979 ## fav_romn_2016 fav_obama_2016 fav_hrc_2016 ## 0.34802091 0.48879761 0.41834703 ## fav_sanders_2016 fav_rubio_2016 fav_grid_row_rnd_2016 ## 0.53734130 0.42183221 0.00000000 ## fav_grid_col_rnd_2016 fav_romn_baseline fav_ging_baseline ## 0.00000000 0.43378143 0.32972367 ## fav_hunt_baseline fav_bach_baseline fav_ronp_baseline ## 0.35125716 0.31889470 0.34092606 ## fav_sant_baseline fav_perr_baseline fav_obama_baseline ## 0.37764501 0.30669654 0.48145382 ## fav_hrc_baseline fav_biden_baseline ## 0.58924571 0.46004481 map_chr(VSG.fav, mean, na.rm=TRUE) ## fav_trump_2019 fav_obama_2019 fav_hrc_2019 ## &quot;0.421449&quot; &quot;0.531199&quot; &quot;0.390766&quot; ## fav_sanders_2019 fav_putin_2019 fav_schumer_2019 ## &quot;0.472489&quot; &quot;0.081723&quot; &quot;0.324974&quot; ## fav_pelosi_2019 fav_comey_2019 fav_mueller_2019 ## &quot;0.380882&quot; &quot;0.299602&quot; &quot;0.454934&quot; ## fav_mcconnell_2019 fav_kavanaugh_2019 fav_biden_2019 ## &quot;0.279392&quot; &quot;0.404779&quot; &quot;0.534002&quot; ## fav_warren_2019 fav_harris_2019 fav_gillibrand_2019 ## &quot;0.417318&quot; &quot;0.322909&quot; &quot;0.283818&quot; ## fav_patrick_2019 fav_booker_2019 fav_garcetti_2019 ## &quot;0.160643&quot; &quot;0.346216&quot; &quot;0.104883&quot; ## fav_klobuchar_2019 fav_gorsuch_2019 fav_kasich_2019 ## &quot;0.228352&quot; &quot;0.354182&quot; &quot;0.319221&quot; ## fav_haley_2019 fav_bloomberg_2019 fav_holder_2019 ## &quot;0.420416&quot; &quot;0.321876&quot; &quot;0.322171&quot; ## fav_avenatti_2019 fav_castro_2019 fav_landrieu_2019 ## &quot;0.173772&quot; &quot;0.201505&quot; &quot;0.127452&quot; ## fav_orourke_2019 fav_hickenlooper_2019 fav_pence_2019 ## &quot;0.364213&quot; &quot;0.129518&quot; &quot;0.443723&quot; ## favorhealth_2019 fav_trump_2018 fav_ryan_2018 ## &quot;0.476914&quot; &quot;0.395337&quot; &quot;0.281266&quot; ## fav_obama_2018 fav_hrc_2018 fav_sanders_2018 ## &quot;0.532223&quot; &quot;0.390008&quot; &quot;0.481432&quot; ## fav_putin_2018 fav_schumer_2018 fav_pelosi_2018 ## &quot;0.076936&quot; &quot;0.308077&quot; &quot;0.323397&quot; ## fav_comey_2018 fav_mueller_2018 fav_mcconnell_2018 ## &quot;0.317236&quot; &quot;0.406661&quot; &quot;0.156703&quot; ## fav_trump_2017 fav_ryan_2017 fav_obama_2017 ## &quot;0.436420&quot; &quot;0.274861&quot; &quot;0.492827&quot; ## fav_hrc_2017 fav_sanders_2017 fav_putin_2017 ## &quot;0.403000&quot; &quot;0.476850&quot; &quot;0.109227&quot; ## fav_trump_2016 fav_cruz_2016 fav_ryan_2016 ## &quot;0.441623&quot; &quot;0.344660&quot; &quot;0.363580&quot; ## fav_romn_2016 fav_obama_2016 fav_hrc_2016 ## &quot;0.348021&quot; &quot;0.488798&quot; &quot;0.418347&quot; ## fav_sanders_2016 fav_rubio_2016 fav_grid_row_rnd_2016 ## &quot;0.537341&quot; &quot;0.421832&quot; &quot;0.000000&quot; ## fav_grid_col_rnd_2016 fav_romn_baseline fav_ging_baseline ## &quot;0.000000&quot; &quot;0.433781&quot; &quot;0.329724&quot; ## fav_hunt_baseline fav_bach_baseline fav_ronp_baseline ## &quot;0.351257&quot; &quot;0.318895&quot; &quot;0.340926&quot; ## fav_sant_baseline fav_perr_baseline fav_obama_baseline ## &quot;0.377645&quot; &quot;0.306697&quot; &quot;0.481454&quot; ## fav_hrc_baseline fav_biden_baseline ## &quot;0.589246&quot; &quot;0.460045&quot; 7.7 walk, purrr, and more See Chapter 21.8 for a discussion of walk Main idea here is when you want to use a function for its side operations (e.g., plot) rather than to manipulate the data See also Chapter 21.9.1 for some additional functionality that is occasionally useful: keep discard some every See Chapter 21.9.2 for even more advanced approaches to extracting data "],
["functions-and-packages.html", "8 Functions and Packages 8.1 apply and its friends 8.2 plyr", " 8 Functions and Packages 8.1 apply and its friends 8.1.1 apply apply is a fundamental function in R and this family can be dead useful in many situations apply(array, margin, function , ...) An array (including potentially a matrix) The margin argument controls how each matrix is analyzed. Should the function execute on each row (margin = 1) or each column (margin = 2)? The function is what you want done on each row/column/whatever. IMPORTANTLY, the … refers to any arguments you want to pass to the function mat1 &lt;- matrix(rep(seq(4), 4), ncol = 4) mat1 ## [,1] [,2] [,3] [,4] ## [1,] 1 1 1 1 ## [2,] 2 2 2 2 ## [3,] 3 3 3 3 ## [4,] 4 4 4 4 Let’s calculate the sum of each row apply(mat1, 1, sum) ## [1] 4 8 12 16 Now the sum of each column apply(mat1, 2, sum) ## [1] 10 10 10 10 Usefully, we are not constrained to the functions that already exist in R. We can write our own functions. #using a user defined function sum.plus.2 &lt;- function(x){ sum(x) + 2 } Now we can use that function on the rows of our matrix apply(mat1, 1, sum.plus.2) ## [1] 6 10 14 18 We can generalize this to add some generic number to our sum. And we can also create anonymous functions that are never assigned into memory What’s going on here? apply(mat1, 1, function(x, y) sum(x) + y, y=3) ## [1] 7 11 15 19 And here? apply(mat1, 2, function(x, y) sum(x) + y, y=5) ## [1] 15 15 15 15 8.1.2 lapply There are several related functions in R that work the same but with different inputs. lapply(list, function, ...) Many functions in R produce lists and even dataframes are related to lists. mat1.df &lt;- data.frame(mat1) mat1.df ## X1 X2 X3 X4 ## 1 1 1 1 1 ## 2 2 2 2 2 ## 3 3 3 3 3 ## 4 4 4 4 4 is.list(mat1.df) ## [1] TRUE So lapply can help you work withs lists and data.frames lapply(mat1.df, sum) ## $X1 ## [1] 10 ## ## $X2 ## [1] 10 ## ## $X3 ## [1] 10 ## ## $X4 ## [1] 10 Note that the output of this is a list Another useful application of the lapply function is with a “dummy sequence”. The list argument is the dummy sequence and it is only used to specify how many iterations we would like to have the function executed. When the lapply functions is used in this way it can replace a for loop very easily, although often the map functions discussed last class are better for this. unlist(lapply(1:5, function(i) 5+i )) ## [1] 6 7 8 9 10 8.1.3 sapply This is a “simplified” version of lapply The key difference is that it changes hat kind of object is returned depending on what the outcomes look like. If the output is a scalar, the result is a vector If the output is all vectors of the same length, it will return a matrix sapply(list, function, ..., simplify) sapply(mat1.df, function(x, y) sum(x) + y, y = 5) ## X1 X2 X3 X4 ## 15 15 15 15 This is a vector, not a list 8.1.4 tapply This is less intuitive, but can be very useful for recoding tasks, handling data, etc. The key here is to understand that the “indices” here are the values of some other object. tapply(array, indicies, function, ..., simplify) x1 &lt;- runif(16) x1 ## [1] 0.4981744 0.3050966 0.6288863 0.8193574 0.4438434 0.9291112 0.1573815 ## [8] 0.4316274 0.1942658 0.4888260 0.7559946 0.4411301 0.3513798 0.8786220 ## [15] 0.5532509 0.3996468 cat1 &lt;- rep(1:4, 4) cat1 ## [1] 1 2 3 4 1 2 3 4 1 2 3 4 1 2 3 4 cat2 &lt;- c(rep(1, 8), rep(2, 8)) cat2 ## [1] 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 mat2.df &lt;- data.frame(x1) names(mat2.df) &lt;- c(&quot;x1&quot;) mat2.df$cat1 &lt;- cat1 mat2.df$cat2 &lt;- cat2 mat2.df ## x1 cat1 cat2 ## 1 0.4981744 1 1 ## 2 0.3050966 2 1 ## 3 0.6288863 3 1 ## 4 0.8193574 4 1 ## 5 0.4438434 1 1 ## 6 0.9291112 2 1 ## 7 0.1573815 3 1 ## 8 0.4316274 4 1 ## 9 0.1942658 1 2 ## 10 0.4888260 2 2 ## 11 0.7559946 3 2 ## 12 0.4411301 4 2 ## 13 0.3513798 1 2 ## 14 0.8786220 2 2 ## 15 0.5532509 3 2 ## 16 0.3996468 4 2 tapply(mat2.df$x1, INDEX = mat2.df$cat1, FUN=mean) ## 1 2 3 4 ## 0.3719159 0.6504140 0.5238783 0.5229404 And you can do this for combinations of values of variables tapply(mat2.df$x1, list(mat2.df$cat1, mat2.df$cat2), mean) ## 1 2 ## 1 0.4710089 0.2728228 ## 2 0.6171039 0.6837240 ## 3 0.3931339 0.6546227 ## 4 0.6254924 0.4203884 The first cell here is equivalent to: mean(mat2.df$x1[mat2.df$cat1==1 &amp; mat2.df$cat2==1]) ## [1] 0.4710089 8.1.5 sweep sweep(array, margin, stats, function, ...) This is used if you want, for instance, mean center your variables The name is horrible, but the idea is that you can alter each variable as a function of the variable. Easiest to understand by example. a &lt;- matrix(runif(100, 1, 2),20) a.df &lt;- data.frame(a) a ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1.180744 1.694369 1.028179 1.258807 1.668355 ## [2,] 1.533352 1.522119 1.774463 1.720662 1.765292 ## [3,] 1.649200 1.188339 1.667821 1.760558 1.093636 ## [4,] 1.732612 1.707955 1.043029 1.404081 1.628322 ## [5,] 1.572652 1.154991 1.507236 1.712866 1.454518 ## [6,] 1.809665 1.086564 1.129115 1.889710 1.020716 ## [7,] 1.990070 1.144357 1.124464 1.015507 1.529987 ## [8,] 1.418620 1.177627 1.478483 1.295910 1.719649 ## [9,] 1.003479 1.235215 1.174157 1.833613 1.865289 ## [10,] 1.026970 1.293818 1.194909 1.320459 1.122995 ## [11,] 1.657856 1.119568 1.862517 1.356757 1.074128 ## [12,] 1.347867 1.571377 1.382291 1.129286 1.242680 ## [13,] 1.238952 1.192071 1.521784 1.077970 1.168065 ## [14,] 1.255797 1.657592 1.117688 1.702415 1.626153 ## [15,] 1.592264 1.083194 1.268314 1.370975 1.100264 ## [16,] 1.644480 1.486643 1.100082 1.646423 1.937141 ## [17,] 1.020452 1.416914 1.695062 1.722857 1.359959 ## [18,] 1.691675 1.958630 1.665584 1.540231 1.577239 ## [19,] 1.508073 1.236801 1.079541 1.746260 1.140773 ## [20,] 1.208763 1.596122 1.847638 1.517179 1.080568 Now let’s subtract the mean from each column a1 &lt;- sweep(a, 2, colMeans(a), &quot;-&quot;) a1[1:5,] ## [,1] [,2] [,3] [,4] [,5] ## [1,] -0.27343288 0.3181555 -0.3549390 -0.24231902 0.25956823 ## [2,] 0.07917495 0.1459062 0.3913453 0.21953554 0.35650565 ## [3,] 0.19502223 -0.1878742 0.2847031 0.25943141 -0.31515032 ## [4,] 0.27843430 0.3317413 -0.3400891 -0.09704477 0.21953578 ## [5,] 0.11847457 -0.2212223 0.1241187 0.21173972 0.04573122 colMeans(a1) ## column means are all now about zero ## [1] -8.881784e-17 0.000000e+00 8.881784e-17 -8.881784e-17 -8.881784e-17 8.1.6 by by(data, INDICES, FUN, ..., simplify = TRUE) by is a wrapper for tapply that is supposed to make it easier to use tapply(mat2.df$x1, INDEX = mat2.df$cat1, FUN=mean) ## 1 2 3 4 ## 0.3719159 0.6504140 0.5238783 0.5229404 byOut &lt;- by(data=mat2.df$x1, INDICES=mat2.df$cat1, mean) byOut ## mat2.df$cat1: 1 ## [1] 0.3719159 ## ------------------------------------------------------------ ## mat2.df$cat1: 2 ## [1] 0.650414 ## ------------------------------------------------------------ ## mat2.df$cat1: 3 ## [1] 0.5238783 ## ------------------------------------------------------------ ## mat2.df$cat1: 4 ## [1] 0.5229404 class(byOut) ## [1] &quot;by&quot; 8.1.7 vapply And more Base R comes with a variety of related functions that are a variety on a theme vapply is mucht the same except The argument FUN.VALUE provides a template for what the output should look like vapply(X, FUN, FUN.VALUE, ..., USE.NAMES = TRUE) l &lt;- list(a = 1:10, b = 11:20) l ## $a ## [1] 1 2 3 4 5 6 7 8 9 10 ## ## $b ## [1] 11 12 13 14 15 16 17 18 19 20 l.fivenum &lt;- vapply(X=l, FUN=fivenum, FUN.VALUE=c(Min.=0, &quot;1st Qu.&quot;=0, Median=0, &quot;3rd Qu.&quot;=0, Max.=0)) class(l.fivenum) ## [1] &quot;matrix&quot; l.fivenum ## a b ## Min. 1.0 11.0 ## 1st Qu. 3.0 13.0 ## Median 5.5 15.5 ## 3rd Qu. 8.0 18.0 ## Max. 10.0 20.0 Other options include: - replicate, which executes the same function multiple times - mapply, which is a multivariate version of sapply - rapply, which allows for final handling of outputs - And more, including: + ave + colMeans + rowSums + aggregate + eapply 8.2 plyr The plyr package is designed to make all of this a bit easier to handle by adding the followign features Consistent naming protocols for functions in terms of what is going in and coming out Easy to make parallel Built-in error recovery Better handling of labels Flesible handling of all basic data types This content taken from: https://www.r-bloggers.com/a-fast-intro-to-plyr-for-r/ library(plyr) ## ------------------------------------------------------------------------------ ## You have loaded plyr after dplyr - this is likely to cause problems. ## If you need functions from both plyr and dplyr, please load plyr first, then dplyr: ## library(plyr); library(dplyr) ## ------------------------------------------------------------------------------ ## ## Attaching package: &#39;plyr&#39; ## The following objects are masked from &#39;package:dplyr&#39;: ## ## arrange, count, desc, failwith, id, mutate, rename, summarise, ## summarize ## The following object is masked from &#39;package:purrr&#39;: ## ## compact Let’s make some example data dd&lt;-data.frame(matrix(rnorm(216),72,3),c(rep(&quot;A&quot;,24),rep(&quot;B&quot;,24),rep(&quot;C&quot;,24)),c(rep(&quot;J&quot;,36),rep(&quot;K&quot;,36))) colnames(dd) &lt;- c(&quot;v1&quot;, &quot;v2&quot;, &quot;v3&quot;, &quot;dim1&quot;, &quot;dim2&quot;) head(dd) ## v1 v2 v3 dim1 dim2 ## 1 0.26039717 0.9699362 0.48700740 A J ## 2 -0.36260406 -1.7763540 0.98193361 A J ## 3 -0.05732943 -0.2266565 -0.05733289 A J ## 4 0.07050933 -0.4970105 -1.33668279 A J ## 5 1.11471229 -1.2991371 1.48533679 A J ## 6 0.86341048 0.5036200 -1.53516378 A J dd ## v1 v2 v3 dim1 dim2 ## 1 0.260397174 0.96993619 0.487007402 A J ## 2 -0.362604060 -1.77635400 0.981933609 A J ## 3 -0.057329434 -0.22665652 -0.057332886 A J ## 4 0.070509335 -0.49701050 -1.336682794 A J ## 5 1.114712294 -1.29913710 1.485336791 A J ## 6 0.863410476 0.50362000 -1.535163781 A J ## 7 -0.015972552 -0.51622971 0.227870268 A J ## 8 -1.163043618 -0.35877385 -0.870024970 A J ## 9 0.126353094 0.21401712 -1.526170518 A J ## 10 -0.540576001 -0.12914613 -0.212028354 A J ## 11 -0.444324220 0.43571759 0.922281373 A J ## 12 -1.267665304 -0.41217837 -1.042590403 A J ## 13 0.676740106 1.21003449 0.511360502 A J ## 14 -1.211852512 -0.36886669 -1.392594172 A J ## 15 -1.281531614 0.15054084 0.030354748 A J ## 16 -0.735749202 0.04272541 -1.656743778 A J ## 17 -0.264662382 0.23589124 -1.052393111 A J ## 18 0.364347593 1.10273723 0.412733838 A J ## 19 0.513658651 0.14514998 0.073262253 A J ## 20 -0.252788920 0.64171362 0.589635398 A J ## 21 1.179497767 0.13677437 0.033481022 A J ## 22 -0.204027791 -0.25702059 -1.066211624 A J ## 23 0.226563263 -0.87917975 -0.635699682 A J ## 24 0.328736265 0.85951448 -1.344751616 A J ## 25 -1.143396512 -1.03256161 -0.468085089 B J ## 26 -0.334748465 -1.02210963 0.852596090 B J ## 27 -1.220369382 1.29063313 0.621062879 B J ## 28 -1.661396652 0.87527000 1.617524396 B J ## 29 2.045497234 1.81210103 -1.022509586 B J ## 30 0.922110296 0.28057452 0.656838012 B J ## 31 -0.091649052 0.60930241 0.317075453 B J ## 32 0.472791611 0.93265425 -1.111829708 B J ## 33 0.848743947 0.35432401 0.581149824 B J ## 34 -0.347099074 1.32280570 0.308245957 B J ## 35 -0.768903935 1.62972111 -0.708188543 B J ## 36 -0.008937695 -0.48560917 0.001527187 B J ## 37 -0.028744171 -0.87412910 -2.079219985 B K ## 38 1.007694298 -0.64593893 -2.293476612 B K ## 39 1.138968860 1.55892315 -0.277277815 B K ## 40 -0.695404051 0.52314878 0.107802806 B K ## 41 0.306644703 -0.05179365 -0.344424499 B K ## 42 -1.933721068 0.78694736 -0.075952545 B K ## 43 -0.524950079 0.69593160 0.322679660 B K ## 44 2.224715128 0.18636320 -0.079575165 B K ## 45 -0.523541890 -0.83699951 0.660906397 B K ## 46 0.535204761 0.17263874 1.131711103 B K ## 47 -0.915979991 -0.48970673 -0.425784287 B K ## 48 0.781904128 0.97340998 -1.036112655 B K ## 49 -0.995505977 0.35941546 -1.080915756 C K ## 50 -1.221710527 -0.37636889 -0.326209825 C K ## 51 -0.605953788 -1.92698626 -0.178350424 C K ## 52 1.359144006 1.26566455 -1.992940196 C K ## 53 1.138524697 -1.05500796 1.174013835 C K ## 54 -0.573496514 -1.90376752 -0.166334303 C K ## 55 0.240654235 1.46901280 0.845817167 C K ## 56 0.983923097 -0.43122415 -1.823562471 C K ## 57 -2.303479976 0.25993373 -0.694867215 C K ## 58 1.014622542 0.55235379 -0.069303051 C K ## 59 -0.493344814 -1.95435441 -0.649249123 C K ## 60 -0.676204230 -1.03836654 -0.255942706 C K ## 61 -2.325181351 -2.10134620 0.055839022 C K ## 62 -0.092625448 -0.49899695 -2.079337545 C K ## 63 -1.054879313 -2.19955646 -0.390649490 C K ## 64 1.395323878 1.03261524 0.745450488 C K ## 65 -0.790192409 0.93721440 -0.444076719 C K ## 66 -0.283956096 -0.29568473 0.029150807 C K ## 67 -1.162900555 0.74088597 -0.528116253 C K ## 68 0.203648529 1.25398684 0.266913361 C K ## 69 0.390789401 0.69014708 -1.323239846 C K ## 70 -1.838227650 0.28221376 -0.548401897 C K ## 71 -1.481884731 0.29471590 -1.050305762 C K ## 72 0.921770430 0.76680813 0.094744127 C K The main functions we want to use are a_ply, aaply, adply, alply, d_ply, daply, ddply, dlply, l_ply, laply, llply, m_ply, maply, mdply, mlply The first letter for each tells us what kind of input we have a=array d = data.frame l=list m=matrix The second letter tells us what we want in terms of output a=array d=data.frame l=list m=matrix _=discard the results Example: ddply(.data=dd, .variables=c(&quot;dim1&quot;,&quot;dim2&quot;), .fun=function(df) mean(df$v1)) ## dim1 dim2 V1 ## 1 A J -0.08655007 ## 2 B J -0.10727981 ## 3 B K 0.11439922 ## 4 C K -0.34379761 daply(.data=dd, .variables=c(&quot;dim1&quot;,&quot;dim2&quot;), .fun=function(df)mean(df$v1)) ## dim2 ## dim1 J K ## A -0.08655007 NA ## B -0.10727981 0.1143992 ## C NA -0.3437976 Most combinations we want are here l_ply(1:100, identity) llply(1:100, identity) ## [[1]] ## [1] 1 ## ## [[2]] ## [1] 2 ## ## [[3]] ## [1] 3 ## ## [[4]] ## [1] 4 ## ## [[5]] ## [1] 5 ## ## [[6]] ## [1] 6 ## ## [[7]] ## [1] 7 ## ## [[8]] ## [1] 8 ## ## [[9]] ## [1] 9 ## ## [[10]] ## [1] 10 ## ## [[11]] ## [1] 11 ## ## [[12]] ## [1] 12 ## ## [[13]] ## [1] 13 ## ## [[14]] ## [1] 14 ## ## [[15]] ## [1] 15 ## ## [[16]] ## [1] 16 ## ## [[17]] ## [1] 17 ## ## [[18]] ## [1] 18 ## ## [[19]] ## [1] 19 ## ## [[20]] ## [1] 20 ## ## [[21]] ## [1] 21 ## ## [[22]] ## [1] 22 ## ## [[23]] ## [1] 23 ## ## [[24]] ## [1] 24 ## ## [[25]] ## [1] 25 ## ## [[26]] ## [1] 26 ## ## [[27]] ## [1] 27 ## ## [[28]] ## [1] 28 ## ## [[29]] ## [1] 29 ## ## [[30]] ## [1] 30 ## ## [[31]] ## [1] 31 ## ## [[32]] ## [1] 32 ## ## [[33]] ## [1] 33 ## ## [[34]] ## [1] 34 ## ## [[35]] ## [1] 35 ## ## [[36]] ## [1] 36 ## ## [[37]] ## [1] 37 ## ## [[38]] ## [1] 38 ## ## [[39]] ## [1] 39 ## ## [[40]] ## [1] 40 ## ## [[41]] ## [1] 41 ## ## [[42]] ## [1] 42 ## ## [[43]] ## [1] 43 ## ## [[44]] ## [1] 44 ## ## [[45]] ## [1] 45 ## ## [[46]] ## [1] 46 ## ## [[47]] ## [1] 47 ## ## [[48]] ## [1] 48 ## ## [[49]] ## [1] 49 ## ## [[50]] ## [1] 50 ## ## [[51]] ## [1] 51 ## ## [[52]] ## [1] 52 ## ## [[53]] ## [1] 53 ## ## [[54]] ## [1] 54 ## ## [[55]] ## [1] 55 ## ## [[56]] ## [1] 56 ## ## [[57]] ## [1] 57 ## ## [[58]] ## [1] 58 ## ## [[59]] ## [1] 59 ## ## [[60]] ## [1] 60 ## ## [[61]] ## [1] 61 ## ## [[62]] ## [1] 62 ## ## [[63]] ## [1] 63 ## ## [[64]] ## [1] 64 ## ## [[65]] ## [1] 65 ## ## [[66]] ## [1] 66 ## ## [[67]] ## [1] 67 ## ## [[68]] ## [1] 68 ## ## [[69]] ## [1] 69 ## ## [[70]] ## [1] 70 ## ## [[71]] ## [1] 71 ## ## [[72]] ## [1] 72 ## ## [[73]] ## [1] 73 ## ## [[74]] ## [1] 74 ## ## [[75]] ## [1] 75 ## ## [[76]] ## [1] 76 ## ## [[77]] ## [1] 77 ## ## [[78]] ## [1] 78 ## ## [[79]] ## [1] 79 ## ## [[80]] ## [1] 80 ## ## [[81]] ## [1] 81 ## ## [[82]] ## [1] 82 ## ## [[83]] ## [1] 83 ## ## [[84]] ## [1] 84 ## ## [[85]] ## [1] 85 ## ## [[86]] ## [1] 86 ## ## [[87]] ## [1] 87 ## ## [[88]] ## [1] 88 ## ## [[89]] ## [1] 89 ## ## [[90]] ## [1] 90 ## ## [[91]] ## [1] 91 ## ## [[92]] ## [1] 92 ## ## [[93]] ## [1] 93 ## ## [[94]] ## [1] 94 ## ## [[95]] ## [1] 95 ## ## [[96]] ## [1] 96 ## ## [[97]] ## [1] 97 ## ## [[98]] ## [1] 98 ## ## [[99]] ## [1] 99 ## ## [[100]] ## [1] 100 laply(1:100, identity) ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ## [19] 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 ## [37] 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 ## [55] 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 ## [73] 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 ## [91] 91 92 93 94 95 96 97 98 99 100 ldply(1:100, identity) ## V1 ## 1 1 ## 2 2 ## 3 3 ## 4 4 ## 5 5 ## 6 6 ## 7 7 ## 8 8 ## 9 9 ## 10 10 ## 11 11 ## 12 12 ## 13 13 ## 14 14 ## 15 15 ## 16 16 ## 17 17 ## 18 18 ## 19 19 ## 20 20 ## 21 21 ## 22 22 ## 23 23 ## 24 24 ## 25 25 ## 26 26 ## 27 27 ## 28 28 ## 29 29 ## 30 30 ## 31 31 ## 32 32 ## 33 33 ## 34 34 ## 35 35 ## 36 36 ## 37 37 ## 38 38 ## 39 39 ## 40 40 ## 41 41 ## 42 42 ## 43 43 ## 44 44 ## 45 45 ## 46 46 ## 47 47 ## 48 48 ## 49 49 ## 50 50 ## 51 51 ## 52 52 ## 53 53 ## 54 54 ## 55 55 ## 56 56 ## 57 57 ## 58 58 ## 59 59 ## 60 60 ## 61 61 ## 62 62 ## 63 63 ## 64 64 ## 65 65 ## 66 66 ## 67 67 ## 68 68 ## 69 69 ## 70 70 ## 71 71 ## 72 72 ## 73 73 ## 74 74 ## 75 75 ## 76 76 ## 77 77 ## 78 78 ## 79 79 ## 80 80 ## 81 81 ## 82 82 ## 83 83 ## 84 84 ## 85 85 ## 86 86 ## 87 87 ## 88 88 ## 89 89 ## 90 90 ## 91 91 ## 92 92 ## 93 93 ## 94 94 ## 95 95 ## 96 96 ## 97 97 ## 98 98 ## 99 99 ## 100 100 "],
["using-sql-syntax-on-an-r-dataframe.html", "9 Using SQL syntax on an R dataframe 9.1 SQL 9.2 The sqldf package", " 9 Using SQL syntax on an R dataframe 9.1 SQL SQL (Structured Query Language) is the universally most widely used querying language for databases. There are variations of SQL, the most popular being MySQL and PostgreSQL. The syntax is very similar for all versions of SQL. Here’s a helpful tutorial for SQl commands, but a few basic examples of each keyword are shown below: 9.1.1 SELECT and FROM SELECT col1, col2, col3 FROM table1 SELECT * FROM table1 The first example selects the three columns specified from a table called table1. It will select all rows from table1 and return them in a new, temporary table unless the result is stored or used somewhere examples The second example selects all columns (and rows) from table1. 9.1.2 WHERE SELECT movie_title, user, rating FROM movies WHERE rating &gt; 4 AND user NOT NULL This will select all of the rating data (movie_title, user, and rating) from the movies table with a rating &gt; 4 and a not-null user 9.1.3 Functions We can use aggregate functions like sum, min, max, count, or average with group by to apply that function to each group. Remember that your group by variable must be included in your select statement! -- valid SELECT movie_title, AVG(rating) FROM movies GROUP BY movie_title -- invalid (we wouldn&#39;t know which avg goes with which movie!!) SELECT AVG(rating) FROM movies GROUP BY movie_title We can also specify what we want the resulting aggregate column to be called. The above example would give us nicer output with this code: SELECT movie_title, AVG(rating) AS rating_avg FROM movies GROUP BY movie_title We can limit the number of results returned, find only unique values, and sort our results as well. SELECT DISTINCT student_id, student_full_name FROM assignments ORDER BY student_full_name DESC LIMIT 100 This query will grab the first 100 distinct students (uniqueness determined by id and full name) sorted in reverse alphabetical order. 9.1.4 HAVING HAVING is the equivalent function of WHERE for aggregate conditions. For example, SELECT movie_title, AVG(rating) AS rating_avg FROM movies GROUP BY movie_title HAVING rating_avg &lt; 2 This pulls all the movies and their average ratings that had an average rating less than 2. 9.1.5 WITH/AS and Subqueries Subqueries are very powerful and come in two syntatical forms. They allow us to create temporary tables which only exist for that query then disappear. SELECT employee_id, first_name, last_name, salary FROM employees WHERE salary = ( SELECT MAX(salary) FROM employees ) ORDER BY first_name, last_name This syntax is equivalent to the following: WITH temp_table AS (SELECT MAX(salary) FROM employees) SELECT employee_id, first_name, last_name, salary ORDER BY first_name, last_name 9.1.6 Joins Joins work the same way as they did in the tidyverse. There are a few types of joins: “Inner joins” produce results only where the linking variable appears on both tables “Outer joins” produce results with all data, and fills in missing values as necessary Left join keeps only observations from the first specified data if their is no match. Right join keeps only observations from the second data Full join keeps everything Here’s an example SQL query using two tables (movies, users) SELECT users.*, count(movie_id) FROM users LEFT JOIN movies ON users.user_id = movies.viewer_id GROUP BY users.user_id LIMIT 10 This will select the first 10 users from the users table (users.*) and add a new column with the count of the number of movies they saw. If both tables had a field called user_id that we wanted to join on, we could say LEFT JOIN movies ON user_id instead of specifying what the column is called in each table. If the column name is ambiguous (because it’s present in both tables), a GROUP BY or ORDER BY or SELECT should specify which table to take the column from by saying table.column 9.2 The sqldf package The main package we’ll be using to convert SQL commands to R manipulations is sqldf. Here’s an example using the same data from the Tidy chapter. Data comes from fivethirtyeight.com library(dplyr) library(tidyr) library(readr) library(tidyverse) mayors&lt;-read_csv(file=&quot;https://raw.githubusercontent.com/jmontgomery/jmontgomery.github.io/master/PDS/Datasets/Mayors.csv&quot;) tweets&lt;-read_csv(&quot;C:/Users/maria/OneDrive/WUSTL/2019-20/PDS/Tweets.csv&quot;) mayors and tweets are tibbles, but we want to operate our SQL queries on data frames mayorsDF &lt;- as.data.frame(mayors) tweetsDF &lt;- as.data.frame(tweets) Now we can start using our newfound SQL powers to truly explore our data. For a warm-up, let’s count how many mayors are present in our dataset. library(sqldf) sqldf( &quot;SELECT COUNT(DISTINCT FullName) FROM mayorsDF&quot; ) ## COUNT(DISTINCT FullName) ## 1 1406 We can confirm this with our tidy skills: mayors %&gt;% select(&quot;FullName&quot;) %&gt;% filter(!is.na(FullName)) %&gt;% n_distinct() ## [1] 1406 Note that we need to filter out NA/null values from the dataset before taking unique values in tidy. Tidy counts null as a unique value. How about adding a column to the mayors dataset that counts the number of tweets they have made? With SQL: mayors_newDF &lt;- sqldf( &quot;SELECT mayorsDF.*, COUNT(TweetID) AS nTweets FROM mayorsDF INNER JOIN tweetsDF ON mayorsDF.TwitterHandle = tweetsDF.ScreenName GROUP BY MayorID ORDER BY nTweets DESC, FullName ASC&quot; ) head(mayors_newDF[c(&quot;MayorID&quot;, &quot;FullName&quot;, &quot;TwitterHandle&quot;, &quot;nTweets&quot;)], n=10) ## MayorID FullName TwitterHandle nTweets ## 1 902 Derek Armstead derek_armstead 3200 ## 2 1143 Ed Pawlowski ed_pawlowski 3200 ## 3 778 Emily Larson larsonforduluth 3200 ## 4 1071 Greg Peterson dublinohio 3200 ## 5 812 Jason L. Shelton tupmayorsoffice 3200 ## 6 1141 Jim Kenney phillymayor 3200 ## 7 498 Rahm Emmanuel chicagosmayor 3200 ## 8 443 Thomas A. Masters mayormasters 3200 ## 9 11 William Stimpson mayorstimpson 3200 ## 10 715 Andy Schor andyschor 3199 With tidy: tweetCounts &lt;- tweets %&gt;% filter(!is.na(ScreenName)) %&gt;% group_by(ScreenName) %&gt;% tally() mayors_new &lt;- mayors %&gt;% inner_join(tweetCounts, by=c(&quot;TwitterHandle&quot;=&quot;ScreenName&quot;)) %&gt;% group_by(MayorID) %&gt;% arrange(FullName) %&gt;% arrange(desc(n)) %&gt;% select(&quot;MayorID&quot;, &quot;FullName&quot;, &quot;TwitterHandle&quot;, &quot;n&quot;) mayors_new ## # A tibble: 572 x 4 ## # Groups: MayorID [572] ## MayorID FullName TwitterHandle n ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 902 Derek Armstead derek_armstead 3200 ## 2 1143 Ed Pawlowski ed_pawlowski 3200 ## 3 778 Emily Larson larsonforduluth 3200 ## 4 1071 Greg Peterson dublinohio 3200 ## 5 812 Jason L. Shelton tupmayorsoffice 3200 ## 6 1141 Jim Kenney phillymayor 3200 ## 7 498 Rahm Emmanuel chicagosmayor 3200 ## 8 443 Thomas A. Masters mayormasters 3200 ## 9 11 William Stimpson mayorstimpson 3200 ## 10 715 Andy Schor andyschor 3199 ## # ... with 562 more rows "]
]
